{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Orchestrix","text":"<p>A modular, event-driven architecture framework for Python with CloudEvents-compatible messages.</p> <p>\ud83c\udf89 Live-Demo! Diese Seite wird automatisch aktualisiert wenn du sie bearbeitest.</p> <p> </p>"},{"location":"#what-problem-does-orchestrix-solve","title":"What Problem Does Orchestrix Solve?","text":"<p>Traditional CRUD applications struggle with: - Lost Business Context - Database updates don't capture why changes happened - Difficult Auditing - No automatic audit trail of state changes - Complex Workflows - Hard to coordinate multi-step business processes across services - Scalability Limits - Tight coupling makes it hard to scale components independently - Debugging Nightmares - Hard to reproduce production issues without event history</p> <p>Orchestrix provides: - Event Sourcing - Store every state change as an immutable event, never lose context - CQRS - Separate read and write models for optimal performance - Sagas - Reliable distributed transactions with automatic compensation - Time-Travel Debugging - Replay events to any point in time - Built-in Observability - Metrics, tracing, and audit logs out of the box</p>"},{"location":"#when-to-use-orchestrix","title":"When to Use Orchestrix","text":"<p>\u2705 Perfect for: - Financial systems requiring full audit trails (banking, payments, trading) - E-commerce with complex order workflows (inventory, payments, shipping) - Collaborative applications needing conflict resolution (booking systems, reservations) - Domain-Driven Design implementations with rich domain logic - Microservices architectures requiring event-driven communication - Systems where understanding how you got to current state matters</p> <p>\u26a0\ufe0f Consider alternatives if: - Simple CRUD with no complex business logic - Performance is critical and eventual consistency is unacceptable - Team lacks experience with event-driven patterns - Small projects where event sourcing overhead isn't justified</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83c\udfaf Modular Design - Encapsulate domain logic in independent modules</li> <li>\ud83d\udce6 Event Sourcing - First-class support for event-sourced aggregates with optimistic locking</li> <li>\u2601\ufe0f CloudEvents Compatible - Immutable, metadata-rich messages</li> <li>\ud83d\udd0c Pluggable Infrastructure - Swap bus/store implementations easily</li> <li>\ud83e\uddea Type-Safe - Full type annotations with <code>py.typed</code></li> <li>\ud83d\ude80 Simple API - Minimal boilerplate, maximum productivity</li> <li>\ud83d\udd04 Sagas - Long-running business processes with compensation logic</li> <li>\ud83d\udcca Projections - Build read models from event streams</li> <li>\ud83d\udcc8 Observability - Built-in Prometheus metrics and OpenTelemetry tracing</li> <li>\ud83d\udd22 Event Versioning - Upcasters for evolving event schemas</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Basic installation\npip install orchestrix\n\n# With PostgreSQL support\npip install orchestrix[postgres]\n\n# With observability (Prometheus + Tracing)\npip install orchestrix[observability]\n</code></pre> <p>Or with uv:</p> <pre><code>uv add orchestrix\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code>from orchestrix.infrastructure import InMemoryMessageBus, InMemoryEventStore\nfrom examples.order_module import OrderModule, CreateOrder\n\n# Setup infrastructure\nbus = InMemoryMessageBus()\nstore = InMemoryEventStore()\n\n# Register module\nmodule = OrderModule()\nmodule.register(bus, store)\n\n# Execute command\nbus.publish(CreateOrder(\n    order_id=\"ORD-001\",\n    customer_name=\"Alice\",\n    total_amount=149.99\n))\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Full documentation is available at orchestrix.readthedocs.io</p>"},{"location":"#example","title":"Example","text":"<p>Create a simple order management system in minutes:</p> <pre><code>from dataclasses import dataclass\nfrom orchestrix import Command, Event, Module\n\n@dataclass(frozen=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_name: str\n    total_amount: float\n\n@dataclass(frozen=True)\nclass OrderCreated(Event):\n    order_id: str\n    customer_name: str\n    total_amount: float\n\n# Full example in examples/order_module.py\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<p>Orchestrix follows Domain-Driven Design and CQRS/ES principles:</p> <ul> <li>Commands represent intentions to change state</li> <li>Events represent facts that have occurred</li> <li>Aggregates enforce business rules and emit events</li> <li>Message Bus routes commands and events to handlers</li> <li>Event Store persists event streams for reconstruction</li> </ul> <p>Learn more in the Architecture Guide.</p>"},{"location":"#examples","title":"Examples","text":"<p>Explore production-ready examples demonstrating real-world patterns:</p> <ul> <li>\ud83c\udfe6 Banking - Account management with event sourcing</li> <li>\ud83d\uded2 E-Commerce - Order processing with saga pattern</li> <li>\ud83c\udfe2 Lakehouse Platform - GDPR-compliant data lake</li> <li>\ud83d\udd14 Notifications - Resilient notification system</li> </ul> <p>Browse All Examples \u2192</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please read our Contributing Guide for details.</p>"},{"location":"#license","title":"License","text":"<p>MIT License - see LICENSE for details.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>\ud83d\udcd6 Documentation</li> <li>\ud83d\udc1b Issue Tracker</li> <li>\ud83d\udcac Discussions</li> </ul>"},{"location":"markdown-demo/","title":"Markdown Demo","text":""},{"location":"markdown-demo/#code-blocks-mit-syntax-highlighting","title":"Code Blocks mit Syntax Highlighting","text":"<pre><code>from orchestrix import Command, Event\n\n@dataclass(frozen=True, kw_only=True)\nclass CreateUser(Command):\n    user_id: str\n    email: str\n</code></pre>"},{"location":"markdown-demo/#admonitions-info-boxen","title":"Admonitions (Info-Boxen)","text":"<p>Hinweis</p> <p>Dies ist eine Info-Box f\u00fcr zus\u00e4tzliche Informationen.</p> <p>Tipp</p> <p>Nutze <code>just docs</code> um die Dokumentation zu starten!</p> <p>Warnung</p> <p>Achte darauf, dass alle Commands immutable sind.</p> <p>Achtung</p> <p>Event Store kann nicht r\u00fcckw\u00e4rts laufen!</p>"},{"location":"markdown-demo/#tabs","title":"Tabs","text":"PythonJavaScriptTypeScript <pre><code>bus = InMemoryMessageBus()\n</code></pre> <pre><code>const bus = new InMemoryMessageBus();\n</code></pre> <pre><code>const bus: MessageBus = new InMemoryMessageBus();\n</code></pre>"},{"location":"markdown-demo/#tabellen","title":"Tabellen","text":"Feature Status Beschreibung Commands \u2705 Implementiert Events \u2705 Implementiert Async Bus \u23f3 Geplant Postgres Store \u23f3 Geplant"},{"location":"markdown-demo/#task-lists","title":"Task Lists","text":"<ul> <li>[x] Core Framework implementieren</li> <li>[x] InMemory Infrastructure</li> <li>[x] Tests mit 100% Coverage</li> <li>[ ] Async MessageBus</li> <li>[ ] PostgreSQL EventStore</li> <li>[ ] Redis MessageBus</li> </ul>"},{"location":"markdown-demo/#footnotes","title":"Footnotes","text":"<p>Orchestrix nutzt CloudEvents[^1] f\u00fcr Message-Kompatibilit\u00e4t.</p> <p>[^1]: CloudEvents Specification</p>"},{"location":"markdown-demo/#emojis","title":"Emojis","text":"<p>\ud83c\udfaf Modular Design \ud83d\udce6 Event Sourcing \u2601\ufe0f CloudEvents Compatible \ud83d\udd0c Pluggable Infrastructure \ud83e\uddea Type-Safe \ud83d\ude80 Simple API</p>"},{"location":"api/core/","title":"Core API Reference","text":""},{"location":"api/core/#messages","title":"Messages","text":""},{"location":"api/core/#message","title":"<code>Message</code>","text":"<p>Base class for all messages in Orchestrix.</p> <pre><code>@dataclass(frozen=True, kw_only=True)\nclass Message:\n    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    type: str = field(default=\"\")\n    source: str = field(default=\"orchestrix\")\n    timestamp: str = field(default_factory=lambda: datetime.utcnow().isoformat())\n</code></pre> <p>Attributes:</p> <ul> <li><code>id</code> (str): Unique message identifier (UUID by default)</li> <li><code>type</code> (str): Message type (auto-derived from class name)</li> <li><code>source</code> (str): Message source identifier</li> <li><code>timestamp</code> (str): ISO 8601 timestamp when message was created</li> </ul> <p>Example:</p> <pre><code>from orchestrix import Message\n\n@dataclass(frozen=True, kw_only=True)\nclass UserLoggedIn(Message):\n    user_id: str\n    ip_address: str\n</code></pre>"},{"location":"api/core/#command","title":"<code>Command</code>","text":"<p>Subclass of <code>Message</code> representing an intention to change state.</p> <pre><code>class Command(Message):\n    \"\"\"A command message that represents an intention.\"\"\"\n    pass\n</code></pre> <p>Usage:</p> <pre><code>from orchestrix import Command\n\n@dataclass(frozen=True, kw_only=True)\nclass CreateUser(Command):\n    user_id: str\n    email: str\n    name: str\n</code></pre>"},{"location":"api/core/#event","title":"<code>Event</code>","text":"<p>Subclass of <code>Message</code> representing a fact that occurred.</p> <pre><code>class Event(Message):\n    \"\"\"An event message that represents a fact.\"\"\"\n    pass\n</code></pre> <p>Usage:</p> <pre><code>from orchestrix import Event\n\n@dataclass(frozen=True, kw_only=True)\nclass UserCreated(Event):\n    user_id: str\n    email: str\n    name: str\n</code></pre>"},{"location":"api/core/#message-bus","title":"Message Bus","text":""},{"location":"api/core/#messagebus-protocol","title":"<code>MessageBus</code> (Protocol)","text":"<p>Protocol defining the message bus interface.</p> <pre><code>class MessageBus(Protocol):\n    def subscribe(self, message_type: type[Message], handler: Callable[[Message], None]) -&gt; None:\n        \"\"\"Subscribe a handler to a message type.\"\"\"\n        ...\n\n    def publish(self, message: Message) -&gt; None:\n        \"\"\"Publish a message to all subscribers.\"\"\"\n        ...\n</code></pre> <p>Methods:</p>"},{"location":"api/core/#subscribemessage_type-handler","title":"<code>subscribe(message_type, handler)</code>","text":"<p>Register a handler for a specific message type.</p> <p>Parameters:</p> <ul> <li><code>message_type</code> (type[Message]): The message class to handle</li> <li><code>handler</code> (Callable): Function or handler instance with <code>handle()</code> method</li> </ul> <p>Example:</p> <pre><code>bus.subscribe(CreateUser, create_user_handler)\nbus.subscribe(UserCreated, lambda event: print(f\"User created: {event.email}\"))\n</code></pre>"},{"location":"api/core/#publishmessage","title":"<code>publish(message)</code>","text":"<p>Publish a message to all registered handlers.</p> <p>Parameters:</p> <ul> <li><code>message</code> (Message): The message instance to publish</li> </ul> <p>Example:</p> <pre><code>bus.publish(CreateUser(\n    user_id=\"USR-001\",\n    email=\"alice@example.com\",\n    name=\"Alice\"\n))\n</code></pre>"},{"location":"api/core/#event-store","title":"Event Store","text":""},{"location":"api/core/#eventstore-protocol","title":"<code>EventStore</code> (Protocol)","text":"<p>Protocol defining the event store interface.</p> <pre><code>class EventStore(Protocol):\n    def save(self, aggregate_id: str, events: list[Event]) -&gt; None:\n        \"\"\"Save events for an aggregate.\"\"\"\n        ...\n\n    def load(self, aggregate_id: str) -&gt; list[Event]:\n        \"\"\"Load all events for an aggregate.\"\"\"\n        ...\n</code></pre> <p>Methods:</p>"},{"location":"api/core/#saveaggregate_id-events","title":"<code>save(aggregate_id, events)</code>","text":"<p>Persist events for an aggregate.</p> <p>Parameters:</p> <ul> <li><code>aggregate_id</code> (str): Unique identifier for the aggregate</li> <li><code>events</code> (list[Event]): Events to persist</li> </ul> <p>Example:</p> <pre><code>events = [\n    UserCreated(user_id=\"USR-001\", email=\"alice@example.com\", name=\"Alice\"),\n    UserEmailVerified(user_id=\"USR-001\")\n]\nstore.save(\"USR-001\", events)\n</code></pre>"},{"location":"api/core/#loadaggregate_id","title":"<code>load(aggregate_id)</code>","text":"<p>Retrieve all events for an aggregate.</p> <p>Parameters:</p> <ul> <li><code>aggregate_id</code> (str): Unique identifier for the aggregate</li> </ul> <p>Returns:</p> <ul> <li><code>list[Event]</code>: All events in chronological order</li> </ul> <p>Example:</p> <pre><code>events = store.load(\"USR-001\")\nuser = reconstruct_user(events)\n</code></pre>"},{"location":"api/core/#command-handler","title":"Command Handler","text":""},{"location":"api/core/#commandhandler-protocol","title":"<code>CommandHandler</code> (Protocol)","text":"<p>Protocol defining command handler interface.</p> <pre><code>class CommandHandler(Protocol[CommandT]):\n    def handle(self, command: CommandT) -&gt; None:\n        \"\"\"Handle a command.\"\"\"\n        ...\n</code></pre> <p>Type Parameters:</p> <ul> <li><code>CommandT</code>: The specific command type this handler processes</li> </ul> <p>Example:</p> <pre><code>from orchestrix import CommandHandler, Command, MessageBus, EventStore\n\nclass CreateUserHandler(CommandHandler[CreateUser]):\n    def __init__(self, bus: MessageBus, store: EventStore) -&gt; None:\n        self.bus = bus\n        self.store = store\n\n    def handle(self, command: CreateUser) -&gt; None:\n        # Create user aggregate\n        user = User.create(command.user_id, command.email, command.name)\n\n        # Save and publish events\n        events = user.collect_events()\n        self.store.save(command.user_id, events)\n        for event in events:\n            self.bus.publish(event)\n</code></pre>"},{"location":"api/core/#module","title":"Module","text":""},{"location":"api/core/#module-protocol","title":"<code>Module</code> (Protocol)","text":"<p>Protocol defining module interface.</p> <pre><code>class Module(Protocol):\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        \"\"\"Register the module's handlers with the bus and store.\"\"\"\n        ...\n</code></pre> <p>Methods:</p>"},{"location":"api/core/#registerbus-store","title":"<code>register(bus, store)</code>","text":"<p>Wire up module handlers with infrastructure.</p> <p>Parameters:</p> <ul> <li><code>bus</code> (MessageBus): Message bus instance</li> <li><code>store</code> (EventStore): Event store instance</li> </ul> <p>Example:</p> <pre><code>from orchestrix import Module, MessageBus, EventStore\n\nclass UserModule(Module):\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        # Register command handlers\n        bus.subscribe(CreateUser, CreateUserHandler(bus, store))\n        bus.subscribe(VerifyUserEmail, VerifyUserEmailHandler(bus, store))\n\n        # Register event handlers\n        bus.subscribe(UserCreated, send_welcome_email)\n        bus.subscribe(UserEmailVerified, log_verification)\n</code></pre>"},{"location":"api/core/#complete-example","title":"Complete Example","text":"<pre><code>from dataclasses import dataclass, field\nfrom orchestrix import (\n    Command, Event, CommandHandler, Module,\n    MessageBus, EventStore,\n    InMemoryMessageBus, InMemoryEventStore\n)\n\n# Messages\n@dataclass(frozen=True, kw_only=True)\nclass RegisterUser(Command):\n    user_id: str\n    email: str\n\n@dataclass(frozen=True, kw_only=True)\nclass UserRegistered(Event):\n    user_id: str\n    email: str\n\n# Aggregate\n@dataclass\nclass User:\n    user_id: str\n    email: str\n    _events: list[Event] = field(default_factory=list, repr=False)\n\n    @classmethod\n    def register(cls, user_id: str, email: str):\n        user = cls(user_id, email)\n        user._events.append(UserRegistered(user_id=user_id, email=email))\n        return user\n\n    def collect_events(self) -&gt; list[Event]:\n        events = self._events.copy()\n        self._events.clear()\n        return events\n\n# Handler\nclass RegisterUserHandler(CommandHandler[RegisterUser]):\n    def __init__(self, bus: MessageBus, store: EventStore) -&gt; None:\n        self.bus = bus\n        self.store = store\n\n    def handle(self, command: RegisterUser) -&gt; None:\n        user = User.register(command.user_id, command.email)\n        events = user.collect_events()\n        self.store.save(command.user_id, events)\n        for event in events:\n            self.bus.publish(event)\n\n# Module\nclass UserModule(Module):\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        bus.subscribe(RegisterUser, RegisterUserHandler(bus, store))\n\n# Application\nbus = InMemoryMessageBus()\nstore = InMemoryEventStore()\nUserModule().register(bus, store)\n\nbus.publish(RegisterUser(user_id=\"USR-001\", email=\"alice@example.com\"))\n</code></pre>"},{"location":"api/infrastructure/","title":"Infrastructure API Reference","text":""},{"location":"api/infrastructure/#inmemorymessagebus","title":"InMemoryMessageBus","text":"<p>In-memory implementation of the MessageBus protocol.</p> <pre><code>from orchestrix import InMemoryMessageBus\n\nbus = InMemoryMessageBus()\n</code></pre>"},{"location":"api/infrastructure/#class-definition","title":"Class Definition","text":"<pre><code>class InMemoryMessageBus:\n    \"\"\"Synchronous in-memory message bus.\n\n    Suitable for:\n    - Development and testing\n    - Single-process applications\n    - Monolithic architectures\n\n    Characteristics:\n    - Synchronous handler execution\n    - Handlers called in subscription order\n    - No persistence between restarts\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize empty message bus.\"\"\"\n</code></pre>"},{"location":"api/infrastructure/#methods","title":"Methods","text":""},{"location":"api/infrastructure/#subscribemessage_type-handler","title":"<code>subscribe(message_type, handler)</code>","text":"<p>Register a handler for a message type.</p> <p>Parameters:</p> <ul> <li><code>message_type</code> (type[Message]): The message class to handle</li> <li><code>handler</code> (Callable | CommandHandler): Function or handler with <code>handle()</code> method</li> </ul> <p>Returns: None</p> <p>Example:</p> <pre><code># Function handler\ndef handle_order(event: OrderCreated) -&gt; None:\n    print(f\"Order created: {event.order_id}\")\n\nbus.subscribe(OrderCreated, handle_order)\n\n# Class-based handler\nclass CreateOrderHandler(CommandHandler[CreateOrder]):\n    def handle(self, command: CreateOrder) -&gt; None:\n        # Implementation\n        pass\n\nbus.subscribe(CreateOrder, CreateOrderHandler(bus, store))\n\n# Lambda handler\nbus.subscribe(OrderCreated, lambda e: print(f\"Order: {e.order_id}\"))\n\n# Method handler\nclass OrderService:\n    def on_order_created(self, event: OrderCreated) -&gt; None:\n        self.process(event)\n\nservice = OrderService()\nbus.subscribe(OrderCreated, service.on_order_created)\n</code></pre>"},{"location":"api/infrastructure/#publishmessage","title":"<code>publish(message)</code>","text":"<p>Publish a message to all registered handlers.</p> <p>Parameters:</p> <ul> <li><code>message</code> (Message): The message to publish</li> </ul> <p>Returns: None</p> <p>Raises:</p> <ul> <li>Any exception from handlers (no built-in error handling)</li> </ul> <p>Example:</p> <pre><code># Publish command\nbus.publish(CreateOrder(\n    order_id=\"ORD-001\",\n    customer_id=\"CUST-123\"\n))\n\n# Publish event\nbus.publish(OrderCreated(\n    order_id=\"ORD-001\",\n    customer_id=\"CUST-123\"\n))\n</code></pre>"},{"location":"api/infrastructure/#behavior","title":"Behavior","text":"<p>Handler Execution:</p> <ul> <li>Handlers are called synchronously in order of subscription</li> <li>If a handler raises an exception, subsequent handlers are not called</li> <li>No transaction management or error recovery</li> </ul> <pre><code>bus.subscribe(OrderCreated, handler1)  # Called first\nbus.subscribe(OrderCreated, handler2)  # Called second\nbus.subscribe(OrderCreated, handler3)  # Called third\n\nbus.publish(OrderCreated(...))  # Calls in order: 1, 2, 3\n</code></pre> <p>Error Handling:</p> <pre><code>def failing_handler(event):\n    raise ValueError(\"Oops!\")\n\ndef working_handler(event):\n    print(\"This won't be called!\")\n\nbus.subscribe(OrderCreated, failing_handler)\nbus.subscribe(OrderCreated, working_handler)  # Never reached!\n\nbus.publish(OrderCreated(...))  # Raises ValueError\n</code></pre>"},{"location":"api/infrastructure/#thread-safety","title":"Thread Safety","text":"<p>\u26a0\ufe0f Not thread-safe! Don't share across threads without synchronization.</p> <pre><code># \u274c Don't do this\nimport threading\n\ndef worker():\n    bus.publish(CreateOrder(...))  # Race condition!\n\nthreading.Thread(target=worker).start()\nthreading.Thread(target=worker).start()\n</code></pre>"},{"location":"api/infrastructure/#performance","title":"Performance","text":"<ul> <li>Subscribe: O(1)</li> <li>Publish: O(n) where n = handlers for message type</li> <li>Memory: O(m) where m = total subscriptions</li> </ul>"},{"location":"api/infrastructure/#inmemoryeventstore","title":"InMemoryEventStore","text":"<p>In-memory implementation of the EventStore protocol.</p> <pre><code>from orchestrix import InMemoryEventStore\n\nstore = InMemoryEventStore()\n</code></pre>"},{"location":"api/infrastructure/#class-definition_1","title":"Class Definition","text":"<pre><code>class InMemoryEventStore:\n    \"\"\"In-memory event store using defaultdict.\n\n    Suitable for:\n    - Development and testing\n    - Proof of concepts\n    - Single-process applications\n\n    Characteristics:\n    - Events stored in memory only\n    - No persistence between restarts\n    - Append-only semantics\n    - Events returned in insertion order\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize empty event store.\"\"\"\n</code></pre>"},{"location":"api/infrastructure/#methods_1","title":"Methods","text":""},{"location":"api/infrastructure/#saveaggregate_id-events","title":"<code>save(aggregate_id, events)</code>","text":"<p>Append events to aggregate's event stream.</p> <p>Parameters:</p> <ul> <li><code>aggregate_id</code> (str): Unique identifier for the aggregate</li> <li><code>events</code> (list[Event]): Events to append</li> </ul> <p>Returns: None</p> <p>Example:</p> <pre><code>events = [\n    OrderCreated(order_id=\"ORD-001\", customer_id=\"CUST-123\"),\n    ItemAdded(order_id=\"ORD-001\", item={\"sku\": \"A\", \"qty\": 2}),\n    OrderPaid(order_id=\"ORD-001\", payment_id=\"PAY-001\")\n]\n\nstore.save(\"ORD-001\", events)\n</code></pre> <p>Append-Only:</p> <pre><code># First save\nstore.save(\"ORD-001\", [OrderCreated(...)])\n\n# Second save - appends, doesn't replace\nstore.save(\"ORD-001\", [OrderPaid(...)])\n\n# Load returns both\nevents = store.load(\"ORD-001\")\n# \u2192 [OrderCreated, OrderPaid]\n</code></pre>"},{"location":"api/infrastructure/#loadaggregate_id","title":"<code>load(aggregate_id)</code>","text":"<p>Load all events for an aggregate in chronological order.</p> <p>Parameters:</p> <ul> <li><code>aggregate_id</code> (str): Unique identifier for the aggregate</li> </ul> <p>Returns: list[Event]</p> <p>Example:</p> <pre><code># Load all events\nevents = store.load(\"ORD-001\")\n\nfor event in events:\n    print(f\"{event.timestamp}: {event.__class__.__name__}\")\n\n# Reconstruct aggregate\norder = Order.from_events(events)\n</code></pre> <p>Empty Stream:</p> <pre><code># Load non-existent aggregate\nevents = store.load(\"DOES-NOT-EXIST\")\n# \u2192 [] (empty list, not error)\n</code></pre>"},{"location":"api/infrastructure/#behavior_1","title":"Behavior","text":"<p>Event Order:</p> <p>Events are returned in the order they were saved:</p> <pre><code>store.save(\"ORD-001\", [event1, event2])\nstore.save(\"ORD-001\", [event3])\n\nevents = store.load(\"ORD-001\")\n# \u2192 [event1, event2, event3]  # Chronological order\n</code></pre> <p>Isolation:</p> <p>Each aggregate has independent event stream:</p> <pre><code>store.save(\"ORD-001\", [event1, event2])\nstore.save(\"ORD-002\", [event3, event4])\n\nload(\"ORD-001\")  # \u2192 [event1, event2]\nload(\"ORD-002\")  # \u2192 [event3, event4]\n</code></pre>"},{"location":"api/infrastructure/#memory-management","title":"Memory Management","text":"<p>\u26a0\ufe0f All events kept in memory! Consider for production:</p> <pre><code># \u274c Bad for production\nfor i in range(1_000_000):\n    store.save(f\"ORD-{i}\", [OrderCreated(...)])\n# Will use lots of memory!\n\n# \u2705 Use persistent store for production\nstore = PostgreSQLEventStore(connection_string)\n</code></pre>"},{"location":"api/infrastructure/#thread-safety_1","title":"Thread Safety","text":"<p>\u26a0\ufe0f Not thread-safe! Don't share across threads.</p>"},{"location":"api/infrastructure/#performance_1","title":"Performance","text":"<ul> <li>Save: O(1) append</li> <li>Load: O(n) where n = events for aggregate</li> <li>Memory: O(e) where e = total events stored</li> </ul>"},{"location":"api/infrastructure/#limitations","title":"Limitations","text":"<p>\u274c No persistence - data lost on restart \u274c No concurrent access control \u274c No event versioning \u274c No optimistic locking \u274c No snapshots  </p> <p>For production, use: - PostgreSQLEventStore - SQLiteEventStore - MongoDBEventStore</p>"},{"location":"api/infrastructure/#usage-example","title":"Usage Example","text":"<p>Complete example with both components:</p> <pre><code>from orchestrix import (\n    Command,\n    Event,\n    CommandHandler,\n    Module,\n    InMemoryMessageBus,\n    InMemoryEventStore,\n)\nfrom dataclasses import dataclass\n\n# Messages\n@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_id: str\n\n@dataclass(frozen=True, kw_only=True)\nclass OrderCreated(Event):\n    order_id: str\n    customer_id: str\n\n# Handler\nclass CreateOrderHandler(CommandHandler[CreateOrder]):\n    def __init__(self, bus, store):\n        self.bus = bus\n        self.store = store\n\n    def handle(self, command: CreateOrder) -&gt; None:\n        # Create event\n        event = OrderCreated(\n            order_id=command.order_id,\n            customer_id=command.customer_id\n        )\n\n        # Save\n        self.store.save(command.order_id, [event])\n\n        # Publish\n        self.bus.publish(event)\n\n# Module\nclass OrderModule(Module):\n    def register(self, bus, store) -&gt; None:\n        bus.subscribe(CreateOrder, CreateOrderHandler(bus, store))\n        bus.subscribe(OrderCreated, lambda e: print(f\"\ud83d\udce6 Order {e.order_id} created\"))\n\n# Application\nbus = InMemoryMessageBus()\nstore = InMemoryEventStore()\n\nmodule = OrderModule()\nmodule.register(bus, store)\n\n# Execute\nbus.publish(CreateOrder(order_id=\"ORD-001\", customer_id=\"CUST-123\"))\n\n# Verify\nevents = store.load(\"ORD-001\")\nassert len(events) == 1\nassert isinstance(events[0], OrderCreated)\n</code></pre>"},{"location":"api/infrastructure/#next-steps","title":"Next Steps","text":"<ul> <li>Core API - Core abstractions</li> <li>Message Bus Guide - Detailed patterns</li> <li>Event Store Guide - Persistence patterns</li> </ul>"},{"location":"architecture/ASYNC_DESIGN/","title":"Orchestrix Async API Design","text":"<p>Version: 1.0 Date: 2026-01-03 Status: Design Phase Authors: Stefan Poss</p>"},{"location":"architecture/ASYNC_DESIGN/#executive-summary","title":"Executive Summary","text":"<p>This document outlines the design for adding async/await support to Orchestrix while maintaining backward compatibility with existing synchronous code. The async implementation will be fully non-blocking, supporting modern Python async frameworks like FastAPI, Starlette, and Quart.</p>"},{"location":"architecture/ASYNC_DESIGN/#motivation","title":"Motivation","text":"<p>Current State: Orchestrix is synchronous-only - \u274c Blocks threads on I/O operations - \u274c Cannot be used in FastAPI/async web frameworks without thread pool - \u274c No true concurrency, limits scalability - \u274c Missing modern Python ecosystem integration</p> <p>Goals: - \u2705 First-class async support - \u2705 Zero-copy API (both sync and async coexist) - \u2705 Minimal breaking changes - \u2705 Drop-in replacement patterns - \u2705 Full type safety with async/await</p>"},{"location":"architecture/ASYNC_DESIGN/#design-principles","title":"Design Principles","text":"<ol> <li>Coexistence: Sync and async APIs live side-by-side</li> <li>Users can mix sync and async in same application</li> <li> <p>No forced migration path</p> </li> <li> <p>Parallel Execution: Async handlers run concurrently via <code>asyncio.gather()</code></p> </li> <li>Multiple handlers for same message type execute in parallel</li> <li> <p>Better resource utilization than sync</p> </li> <li> <p>Pure Python: No new external dependencies for async support</p> </li> <li>Uses <code>asyncio</code> (stdlib)</li> <li> <p>Uses <code>typing.Protocol</code> for abstraction</p> </li> <li> <p>Type Safe: Full type hints for both sync and async</p> </li> <li>Clear distinction between sync and async paths</li> </ol>"},{"location":"architecture/ASYNC_DESIGN/#async-message-bus-design","title":"Async Message Bus Design","text":""},{"location":"architecture/ASYNC_DESIGN/#protocol-definition","title":"Protocol Definition","text":"<pre><code># components/orchestrix/infrastructure/async_inmemory_bus.py\nfrom typing import Callable, Protocol\n\nAsyncMessageHandler = Callable[[\"Message\"], Coroutine[Any, Any, None]]\n\nclass AsyncMessageBus(Protocol):\n    \"\"\"Async message bus for non-blocking command/event routing.\"\"\"\n\n    async def publish(self, message: Message) -&gt; None:\n        \"\"\"Publish a message to all registered async handlers.\n\n        Handlers execute concurrently via asyncio.gather().\n        If any handler fails, raises HandlerError.\n        \"\"\"\n        ...\n\n    def subscribe(\n        self, \n        message_type: type[Message], \n        handler: AsyncMessageHandler\n    ) -&gt; None:\n        \"\"\"Subscribe an async handler to a message type.\"\"\"\n        ...\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#concrete-implementation","title":"Concrete Implementation","text":"<pre><code>class InMemoryAsyncMessageBus:\n    \"\"\"In-memory async message bus.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self._handlers: dict[\n            type[Message], \n            list[AsyncMessageHandler]\n        ] = defaultdict(list)\n\n    async def publish(self, message: Message) -&gt; None:\n        \"\"\"Publish message with concurrent handler execution.\"\"\"\n        handlers = self._handlers.get(type(message), [])\n\n        logger.info(\n            \"Publishing message (async)\",\n            message_type=type(message).__name__,\n            message_id=message.id,\n            handler_count=len(handlers),\n        )\n\n        # Run all handlers concurrently\n        try:\n            await asyncio.gather(\n                *[handler(message) for handler in handlers]\n            )\n        except Exception as e:\n            logger.error(\"Async handler failed\", error=str(e))\n            raise HandlerError(...)\n\n    def subscribe(\n        self, \n        message_type: type[Message],\n        handler: AsyncMessageHandler\n    ) -&gt; None:\n        \"\"\"Subscribe handler.\"\"\"\n        self._handlers[message_type].append(handler)\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#async-event-store-design","title":"Async Event Store Design","text":""},{"location":"architecture/ASYNC_DESIGN/#protocol-definition_1","title":"Protocol Definition","text":"<pre><code>class AsyncEventStore(Protocol):\n    \"\"\"Async event store for non-blocking persistence.\"\"\"\n\n    async def save(\n        self, \n        aggregate_id: str, \n        events: list[Event]\n    ) -&gt; None:\n        \"\"\"Persist events asynchronously.\"\"\"\n        ...\n\n    async def load(\n        self, \n        aggregate_id: str,\n        from_version: int = 0\n    ) -&gt; list[Event]:\n        \"\"\"Load event stream asynchronously.\"\"\"\n        ...\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#concrete-implementation_1","title":"Concrete Implementation","text":"<pre><code>class InMemoryAsyncEventStore:\n    \"\"\"In-memory async event store.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self._events: dict[str, list[Event]] = defaultdict(list)\n\n    async def save(\n        self, \n        aggregate_id: str, \n        events: list[Event]\n    ) -&gt; None:\n        \"\"\"Persist events (async no-op in memory).\"\"\"\n        self._events[aggregate_id].extend(events)\n        logger.info(\n            \"Events saved (async)\",\n            aggregate_id=aggregate_id,\n            event_count=len(events),\n        )\n\n    async def load(\n        self,\n        aggregate_id: str,\n        from_version: int = 0\n    ) -&gt; list[Event]:\n        \"\"\"Load event stream.\"\"\"\n        events = list(self._events.get(aggregate_id, []))\n        return events[from_version:]\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#async-command-handler-design","title":"Async Command Handler Design","text":""},{"location":"architecture/ASYNC_DESIGN/#pattern","title":"Pattern","text":"<p>Command handlers become async functions:</p> <pre><code>async def handle_create_order(\n    command: CreateOrder,\n    bus: AsyncMessageBus,\n    store: AsyncEventStore\n) -&gt; None:\n    \"\"\"Handle async command execution.\"\"\"\n\n    # Create aggregate\n    order = Order(command.order_id)\n    order.create(command.customer_name)\n\n    # Persist and publish (concurrent)\n    events = order.get_changes()\n    await asyncio.gather(\n        store.save(command.order_id, events),\n        *[bus.publish(event) for event in events]\n    )\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#module-registration-async","title":"Module Registration (Async)","text":"<pre><code>class AsyncOrderModule:\n    \"\"\"Async module implementation.\"\"\"\n\n    def register(\n        self, \n        bus: AsyncMessageBus, \n        store: AsyncEventStore\n    ) -&gt; None:\n        \"\"\"Register async handlers.\"\"\"\n        handler = CreateOrderHandler(bus, store)\n        bus.subscribe(CreateOrder, handler.handle)\n\n\nclass CreateOrderHandler:\n    def __init__(\n        self,\n        bus: AsyncMessageBus,\n        store: AsyncEventStore\n    ):\n        self.bus = bus\n        self.store = store\n\n    async def handle(self, command: CreateOrder) -&gt; None:\n        \"\"\"Async command handler.\"\"\"\n        ...\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#migration-path","title":"Migration Path","text":""},{"location":"architecture/ASYNC_DESIGN/#phase-1-parallel-apis-v10-v11","title":"Phase 1: Parallel APIs (v1.0 \u2192 v1.1)","text":"<p>Both sync and async APIs available:</p> <pre><code># Sync (existing)\nfrom orchestrix.infrastructure import InMemoryMessageBus\nbus = InMemoryMessageBus()\nbus.publish(command)\n\n# Async (new)\nfrom orchestrix.infrastructure.async_inmemory_bus import InMemoryAsyncMessageBus\nasync_bus = InMemoryAsyncMessageBus()\nawait async_bus.publish(command)\n</code></pre> <p>No breaking changes. Users choose path independently.</p>"},{"location":"architecture/ASYNC_DESIGN/#phase-2-mixing-sync-async-v11","title":"Phase 2: Mixing Sync + Async (v1.1)","text":"<p>Support adapters for mixing:</p> <pre><code># Async handler calling sync bus\nclass AsyncToSyncAdapter:\n    def __init__(self, sync_bus: MessageBus):\n        self.sync_bus = sync_bus\n\n    async def publish(self, message: Message) -&gt; None:\n        \"\"\"Publish to sync bus from async context.\"\"\"\n        # Run sync operation in executor to avoid blocking\n        loop = asyncio.get_event_loop()\n        await loop.run_in_executor(\n            None,\n            self.sync_bus.publish,\n            message\n        )\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#phase-3-unified-api-v20","title":"Phase 3: Unified API (v2.0)","text":"<p>Optional: Provide single <code>MessageBus</code> that detects sync vs async context.</p> <p>Not planned for v1.x - Requires significant complexity.</p>"},{"location":"architecture/ASYNC_DESIGN/#breaking-changes","title":"Breaking Changes","text":"<p>None in v1.x!</p> <ul> <li>Sync API remains 100% compatible</li> <li>Async API is purely additive</li> <li>Both can coexist in same application</li> </ul> <p>Future v2.0 might unify APIs, but users will have deprecation warnings.</p>"},{"location":"architecture/ASYNC_DESIGN/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"architecture/ASYNC_DESIGN/#task-8-asyncmessagebus-4-6-hours","title":"Task 8: AsyncMessageBus (4-6 hours)","text":"<pre><code>components/orchestrix/infrastructure/async_inmemory_bus.py  # Protocol + InMemory impl\ntests/components/infrastructure/test_async_bus.py           # Concurrent handler tests\n</code></pre> <p>Tests to cover: - \u2705 Async publish with single handler - \u2705 Async publish with multiple handlers (concurrent execution) - \u2705 Handlers run in parallel (timing test) - \u2705 Handler exception handling - \u2705 Large message volume (1000+ messages) - \u2705 Interleaved publishes (stress test)</p>"},{"location":"architecture/ASYNC_DESIGN/#task-9-asynceventstore-2-3-hours","title":"Task 9: AsyncEventStore (2-3 hours)","text":"<pre><code>components/orchestrix/infrastructure/async_inmemory_store.py    # Protocol + InMemory impl\ntests/components/infrastructure/test_async_store.py             # Concurrent persistence tests\n</code></pre> <p>Tests to cover: - \u2705 Async save - \u2705 Async load - \u2705 Concurrent saves to different aggregates - \u2705 Concurrent save + load race conditions - \u2705 Event ordering preservation</p>"},{"location":"architecture/ASYNC_DESIGN/#task-10-async-integration-tests-2-3-hours","title":"Task 10: Async Integration Tests (2-3 hours)","text":"<pre><code>tests/integration/test_async_order_flow.py  # Full async workflow\n</code></pre> <p>Test scenarios: - \u2705 Full async Order creation flow - \u2705 Async command \u2192 async handler \u2192 event persistence - \u2705 Concurrent order creations - \u2705 Performance comparison vs sync</p>"},{"location":"architecture/ASYNC_DESIGN/#performance-expectations","title":"Performance Expectations","text":""},{"location":"architecture/ASYNC_DESIGN/#sync-vs-async-benchmarks","title":"Sync vs Async Benchmarks","text":"<p>Scenario: 100 messages published, 5 handlers per message</p> Approach Time Notes Sync (sequential) 100ms 1 + 1 + 1... Sync (5 threads) 20ms Threaded, GIL contention Async (concurrent) 1ms True concurrency, no GIL <p>Async advantage: ~100x faster for I/O bound handlers</p>"},{"location":"architecture/ASYNC_DESIGN/#api-reference","title":"API Reference","text":""},{"location":"architecture/ASYNC_DESIGN/#sync-current","title":"Sync (Current)","text":"<pre><code>from orchestrix.infrastructure import InMemoryMessageBus\n\nbus = InMemoryMessageBus()\nbus.subscribe(CreateOrder, handler)\nbus.publish(command)  # Blocking\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#async-new","title":"Async (New)","text":"<pre><code>from orchestrix.infrastructure.async_inmemory_bus import InMemoryAsyncMessageBus\n\nbus = InMemoryAsyncMessageBus()\nbus.subscribe(CreateOrder, async_handler)\nawait bus.publish(command)  # Non-blocking\n</code></pre>"},{"location":"architecture/ASYNC_DESIGN/#testing-strategy","title":"Testing Strategy","text":""},{"location":"architecture/ASYNC_DESIGN/#unit-tests","title":"Unit Tests","text":"<ul> <li>Protocol compliance tests</li> <li>Handler execution tests</li> <li>Error path tests</li> <li>Concurrent execution tests</li> </ul>"},{"location":"architecture/ASYNC_DESIGN/#integration-tests","title":"Integration Tests","text":"<ul> <li>Full async workflows</li> <li>Mixed sync/async patterns</li> <li>Performance under load</li> </ul>"},{"location":"architecture/ASYNC_DESIGN/#benchmarks","title":"Benchmarks","text":"<ul> <li>Message throughput (msgs/sec)</li> <li>Handler concurrency efficiency</li> <li>Memory usage</li> </ul>"},{"location":"architecture/ASYNC_DESIGN/#open-questions","title":"Open Questions","text":"<ol> <li>Backward Compatibility: Should v1.x keep sync API \"as-is\"?</li> <li> <p>Answer: YES - coexistence strategy</p> </li> <li> <p>Performance: Will async overhead be worth it?</p> </li> <li> <p>Answer: Yes for I/O bound (network, DB), neutral for CPU bound</p> </li> <li> <p>When to deprecate sync API?</p> </li> <li>Answer: v2.0 only - users have 2+ years migration window</li> </ol>"},{"location":"architecture/ASYNC_DESIGN/#success-criteria","title":"Success Criteria","text":"<ul> <li>\u2705 AsyncMessageBus passes all tests</li> <li>\u2705 AsyncEventStore passes all tests</li> <li>\u2705 Async integration test shows concurrent execution</li> <li>\u2705 Performance benchmark shows &gt;10x improvement for I/O workloads</li> <li>\u2705 No sync API changes (100% backward compatible)</li> <li>\u2705 Documentation updated with async examples</li> </ul>"},{"location":"architecture/ASYNC_DESIGN/#timeline","title":"Timeline","text":"<ul> <li>Task 8 (AsyncMessageBus): 1 day</li> <li>Task 9 (AsyncEventStore): 4 hours</li> <li>Task 10 (Integration tests): 4 hours</li> <li>Total: ~2 days of focused development</li> </ul>"},{"location":"architecture/ASYNC_DESIGN/#next-steps","title":"Next Steps","text":"<ol> <li>\u2705 Design review (THIS DOCUMENT)</li> <li>\u2192 Implement Task 8: AsyncMessageBus</li> <li>\u2192 Implement Task 9: AsyncEventStore</li> <li>\u2192 Write Task 10: Integration tests</li> <li>\u2192 Performance benchmarks</li> <li>\u2192 Documentation + examples</li> <li>\u2192 Release v1.1.0</li> </ol> <p>Document Status: READY FOR IMPLEMENTATION \u2705</p>"},{"location":"development/architecture/","title":"Architecture","text":"<p>Technical architecture and design decisions behind Orchestrix.</p>"},{"location":"development/architecture/#core-principles","title":"Core Principles","text":""},{"location":"development/architecture/#1-protocol-based-design","title":"1. Protocol-based Design","text":"<p>Orchestrix nutzt <code>typing.Protocol</code> statt Abstract Base Classes:</p> <pre><code>from typing import Protocol\n\nclass MessageBus(Protocol):\n    \"\"\"Message bus interface - no inheritance required!\"\"\"\n\n    def subscribe(self, message_type: type[Message], handler) -&gt; None: ...\n    def publish(self, message: Message) -&gt; None: ...\n</code></pre> <p>Vorteile:</p> <ul> <li>\u2705 Duck Typing - Pythonic!</li> <li>\u2705 Keine Vererbung n\u00f6tig</li> <li>\u2705 Bessere IDE-Unterst\u00fctzung</li> <li>\u2705 Einfacher zu mocken in Tests</li> </ul>"},{"location":"development/architecture/#2-immutable-messages","title":"2. Immutable Messages","text":"<p>Alle Messages sind <code>frozen</code> dataclasses:</p> <pre><code>@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_id: str\n</code></pre> <p>Vorteile:</p> <ul> <li>\u2705 Thread-safe</li> <li>\u2705 Hashable (can use in sets/dicts)</li> <li>\u2705 Verhindert unerwartete Mutations</li> <li>\u2705 CloudEvents-kompatibel</li> </ul>"},{"location":"development/architecture/#3-event-sourcing-first","title":"3. Event Sourcing First","text":"<p>Events sind die Single Source of Truth:</p> <pre><code># State = fold(events)\ndef from_events(events: list[Event]) -&gt; Order:\n    order = None\n    for event in events:\n        order = apply(order, event)\n    return order\n</code></pre> <p>Vorteile:</p> <ul> <li>\u2705 Vollst\u00e4ndige Audit Trail</li> <li>\u2705 Time Travel (State zu jedem Zeitpunkt)</li> <li>\u2705 Event Replay f\u00fcr Projections</li> <li>\u2705 Debugging &amp; Fehleranalyse</li> </ul>"},{"location":"development/architecture/#architecture-layers","title":"Architecture Layers","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Application Layer                 \u2502\n\u2502  (Modules, Command Handlers, Use Cases)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Domain Layer                      \u2502\n\u2502  (Aggregates, Commands, Events)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Infrastructure Layer                \u2502\n\u2502  (MessageBus, EventStore Implementations)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"development/architecture/#application-layer","title":"Application Layer","text":"<p>Responsibility: Orchestration &amp; Use Cases</p> <pre><code>class OrderModule(Module):\n    \"\"\"Application-level orchestration.\"\"\"\n\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        # Wire domain to infrastructure\n        bus.subscribe(CreateOrder, CreateOrderHandler(bus, store))\n        bus.subscribe(OrderCreated, self._send_email)\n</code></pre>"},{"location":"development/architecture/#domain-layer","title":"Domain Layer","text":"<p>Responsibility: Business Logic &amp; Rules</p> <pre><code>@dataclass\nclass Order:\n    \"\"\"Domain aggregate.\"\"\"\n\n    def cancel(self) -&gt; None:\n        \"\"\"Business rule: Can only cancel pending orders.\"\"\"\n        if self.status != \"pending\":\n            raise ValueError(\"Can only cancel pending orders\")\n        self.status = \"cancelled\"\n        self._events.append(OrderCancelled(order_id=self.order_id))\n</code></pre>"},{"location":"development/architecture/#infrastructure-layer","title":"Infrastructure Layer","text":"<p>Responsibility: Technical Implementation</p> <pre><code>class InMemoryMessageBus(MessageBus):\n    \"\"\"Technical implementation of message routing.\"\"\"\n\n    def publish(self, message: Message) -&gt; None:\n        for handler in self._handlers[type(message)]:\n            handler(message)\n</code></pre>"},{"location":"development/architecture/#design-patterns","title":"Design Patterns","text":""},{"location":"development/architecture/#command-pattern","title":"Command Pattern","text":"<p>Commands encapsulate requests:</p> <pre><code>@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    \"\"\"Command = Request to do something.\"\"\"\n    order_id: str\n    customer_id: str\n\n# Execute via handler\nhandler.handle(CreateOrder(...))\n</code></pre>"},{"location":"development/architecture/#observer-pattern","title":"Observer Pattern","text":"<p>MessageBus implements observer:</p> <pre><code># Subscribe observers\nbus.subscribe(OrderCreated, send_email)\nbus.subscribe(OrderCreated, update_inventory)\nbus.subscribe(OrderCreated, log_event)\n\n# Notify all observers\nbus.publish(OrderCreated(...))\n</code></pre>"},{"location":"development/architecture/#repository-pattern","title":"Repository Pattern","text":"<p>EventStore is a repository:</p> <pre><code># Save aggregate state (as events)\nstore.save(aggregate_id, events)\n\n# Load aggregate state (from events)\nevents = store.load(aggregate_id)\naggregate = reconstruct(events)\n</code></pre>"},{"location":"development/architecture/#strategy-pattern","title":"Strategy Pattern","text":"<p>Pluggable infrastructure:</p> <pre><code># Strategy 1: In-Memory\nbus = InMemoryMessageBus()\n\n# Strategy 2: Redis (future)\nbus = RedisMessageBus(url)\n\n# Strategy 3: RabbitMQ (future)\nbus = RabbitMQMessageBus(url)\n\n# Same interface, different implementation!\n</code></pre>"},{"location":"development/architecture/#event-flow","title":"Event Flow","text":"<pre><code>1. Client\n   \u2502\n   \u251c\u2500\u25ba publish(Command)\n   \u2502\n2. MessageBus\n   \u2502\n   \u251c\u2500\u25ba route to CommandHandler\n   \u2502\n3. CommandHandler\n   \u2502\n   \u251c\u2500\u25ba load Events from EventStore\n   \u251c\u2500\u25ba reconstruct Aggregate\n   \u251c\u2500\u25ba execute business logic\n   \u251c\u2500\u25ba collect new Events\n   \u251c\u2500\u25ba save Events to EventStore\n   \u2502\n   \u2514\u2500\u25ba publish Events to MessageBus\n       \u2502\n4. MessageBus\n   \u2502\n   \u2514\u2500\u25ba notify all Event Handlers\n       \u2502\n       \u251c\u2500\u25ba Projection Handler\n       \u251c\u2500\u25ba Email Handler\n       \u251c\u2500\u25ba Analytics Handler\n       \u2514\u2500\u25ba ...\n</code></pre>"},{"location":"development/architecture/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"development/architecture/#current-v010","title":"Current (v0.1.0)","text":"<ul> <li>\u2705 Single process</li> <li>\u2705 Synchronous</li> <li>\u2705 In-memory storage</li> <li>\u2705 Perfect for: Monoliths, testing, development</li> </ul>"},{"location":"development/architecture/#future-scaling","title":"Future Scaling","text":""},{"location":"development/architecture/#horizontal-scaling","title":"Horizontal Scaling","text":"<pre><code># Distributed message bus\nbus = RedisMessageBus(\"redis://...\")\n\n# Multiple instances can publish/subscribe\n# Events are distributed across workers\n</code></pre>"},{"location":"development/architecture/#async-processing","title":"Async Processing","text":"<pre><code>class AsyncMessageBus(MessageBus):\n    async def publish(self, message: Message) -&gt; None:\n        \"\"\"Non-blocking event publishing.\"\"\"\n        tasks = [handler(message) for handler in handlers]\n        await asyncio.gather(*tasks)\n</code></pre>"},{"location":"development/architecture/#event-streaming","title":"Event Streaming","text":"<pre><code># Kafka for high-throughput events\nbus = KafkaMessageBus(\"kafka://...\")\n\n# Process millions of events/sec\n</code></pre>"},{"location":"development/architecture/#cqrs-separation","title":"CQRS Separation","text":"<pre><code>Commands \u2500\u2500\u25ba Write Model (Event Store)\n                  \u2502\n                  \u2502 Events\n                  \u2502\n                  \u25bc\n             Event Handlers\n                  \u2502\n                  \u25bc\n            Read Models (PostgreSQL, Elasticsearch, ...)\n                  \u2502\n                  \u25bc\n             Queries \u25c4\u2500\u2500 Clients\n</code></pre>"},{"location":"development/architecture/#technology-choices","title":"Technology Choices","text":""},{"location":"development/architecture/#why-python","title":"Why Python?","text":"<ul> <li>\u2705 Type hints f\u00fcr Type Safety</li> <li>\u2705 Dataclasses f\u00fcr Value Objects</li> <li>\u2705 Protocols f\u00fcr Interfaces</li> <li>\u2705 Rich ecosystem</li> <li>\u2705 Widely adopted</li> </ul>"},{"location":"development/architecture/#why-protocols-over-abc","title":"Why Protocols over ABC?","text":"<pre><code># \u274c Abstract Base Class - requires inheritance\nclass MessageBus(ABC):\n    @abstractmethod\n    def publish(self, message: Message) -&gt; None:\n        pass\n\nclass MyBus(MessageBus):  # Must inherit!\n    def publish(self, message: Message) -&gt; None:\n        pass\n\n# \u2705 Protocol - duck typing\nclass MessageBus(Protocol):\n    def publish(self, message: Message) -&gt; None: ...\n\nclass MyBus:  # No inheritance needed!\n    def publish(self, message: Message) -&gt; None:\n        pass\n</code></pre>"},{"location":"development/architecture/#why-dataclasses","title":"Why Dataclasses?","text":"<pre><code># \u2705 Immutable, type-safe, clean\n@dataclass(frozen=True, kw_only=True)\nclass Order(Command):\n    order_id: str\n    customer_id: str\n\n# Automatically generates:\n# - __init__\n# - __repr__\n# - __eq__\n# - __hash__ (because frozen)\n</code></pre>"},{"location":"development/architecture/#why-event-sourcing","title":"Why Event Sourcing?","text":"<pre><code># Traditional: Current state only\norder = db.query(Order).get(order_id)\n# Lost: How did we get here? Who made changes? When?\n\n# Event Sourcing: Complete history\nevents = store.load(order_id)\n# Have: Every change, every reason, complete audit trail\n</code></pre>"},{"location":"development/architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"development/architecture/#inmemorymessagebus","title":"InMemoryMessageBus","text":"<ul> <li>Subscribe: O(1)</li> <li>Publish: O(n) where n = handlers for message type</li> <li>Memory: O(m) where m = total subscriptions</li> </ul>"},{"location":"development/architecture/#inmemoryeventstore","title":"InMemoryEventStore","text":"<ul> <li>Save: O(1) append</li> <li>Load: O(n) where n = events for aggregate</li> <li>Memory: O(e) where e = total events</li> </ul>"},{"location":"development/architecture/#optimization-snapshots","title":"Optimization: Snapshots","text":"<p>For aggregates with many events (&gt; 1000):</p> <pre><code># Without snapshot: Load 10,000 events\nevents = store.load(aggregate_id)  # Slow!\norder = Order.from_events(events)\n\n# With snapshot: Load snapshot + recent events\nsnapshot = snapshot_store.load(aggregate_id)\nrecent_events = store.load_after_version(aggregate_id, snapshot.version)\norder = snapshot.aggregate\nfor event in recent_events:\n    order.apply(event)\n</code></pre>"},{"location":"development/architecture/#extensibility-points","title":"Extensibility Points","text":"<p>Orchestrix is designed to be extended:</p>"},{"location":"development/architecture/#1-custom-message-types","title":"1. Custom Message Types","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass Query(Message):\n    \"\"\"New message type for queries.\"\"\"\n    pass\n\nclass GetOrder(Query):\n    order_id: str\n</code></pre>"},{"location":"development/architecture/#2-custom-bus-implementations","title":"2. Custom Bus Implementations","text":"<pre><code>class RateLimitedBus(MessageBus):\n    \"\"\"Bus with rate limiting.\"\"\"\n\n    def publish(self, message: Message) -&gt; None:\n        if self._rate_limiter.allow():\n            self._inner_bus.publish(message)\n        else:\n            raise RateLimitExceeded()\n</code></pre>"},{"location":"development/architecture/#3-custom-store-implementations","title":"3. Custom Store Implementations","text":"<pre><code>class PostgreSQLEventStore(EventStore):\n    \"\"\"Production-grade PostgreSQL store.\"\"\"\n\n    def save(self, aggregate_id: str, events: list[Event]) -&gt; None:\n        # Implement with psycopg2/asyncpg\n        pass\n</code></pre>"},{"location":"development/architecture/#4-middlewaredecorators","title":"4. Middleware/Decorators","text":"<pre><code>def logged(handler):\n    \"\"\"Decorator for logging handlers.\"\"\"\n    def wrapper(message):\n        logger.info(f\"Handling {type(message).__name__}\")\n        result = handler(message)\n        logger.info(f\"Handled {type(message).__name__}\")\n        return result\n    return wrapper\n\n@logged\ndef handle_create_order(command: CreateOrder):\n    # Implementation\n    pass\n</code></pre>"},{"location":"development/architecture/#testing-architecture","title":"Testing Architecture","text":"<p>Testable by design:</p> <pre><code># Production\nbus = RedisMessageBus(\"redis://prod\")\nstore = PostgreSQLEventStore(\"postgresql://prod\")\n\n# Testing\nbus = InMemoryMessageBus()\nstore = InMemoryEventStore()\n\n# Same interface - tests pass!\n</code></pre>"},{"location":"development/architecture/#future-roadmap","title":"Future Roadmap","text":""},{"location":"development/architecture/#v020-async-support","title":"v0.2.0 - Async Support","text":"<ul> <li>AsyncMessageBus</li> <li>AsyncEventStore</li> <li>Async handlers</li> </ul>"},{"location":"development/architecture/#v030-persistence","title":"v0.3.0 - Persistence","text":"<ul> <li>PostgreSQL EventStore</li> <li>MongoDB EventStore</li> <li>SQLite EventStore</li> </ul>"},{"location":"development/architecture/#v040-distributed","title":"v0.4.0 - Distributed","text":"<ul> <li>Redis MessageBus</li> <li>RabbitMQ MessageBus</li> <li>Kafka Integration</li> </ul>"},{"location":"development/architecture/#v100-production-ready","title":"v1.0.0 - Production Ready","text":"<ul> <li>Saga Support</li> <li>Process Managers</li> <li>Outbox Pattern</li> <li>Event Versioning</li> </ul>"},{"location":"development/architecture/#architecture-decisions","title":"Architecture Decisions","text":"<p>See ADR (Architecture Decision Records) in <code>/assets/adr/</code>:</p> <ul> <li>ADR-001: Use Protocols over ABC</li> <li>ADR-002: Immutable Messages with Dataclasses</li> <li>ADR-003: Event Sourcing by Default</li> <li>ADR-004: CloudEvents Compatibility</li> </ul>"},{"location":"development/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Contributing - How to contribute</li> <li>Testing - Test strategies</li> <li>Best Practices - Production guidelines</li> </ul>"},{"location":"development/contributing/","title":"Contributing","text":""},{"location":"development/contributing/#integration-tests-with-testcontainers","title":"Integration Tests with testcontainers","text":"<p>Integration tests for PostgreSQL and EventSourcingDB use testcontainers-python. This ensures tests run in isolated, real containers for reproducibility and reliability.</p>"},{"location":"development/contributing/#container-version-management","title":"Container Version Management","text":"<ul> <li>Container image versions are defined centrally in <code>.container-versions.json</code> at the repo root.</li> <li> <p>Example:</p> <pre><code>{\n    \"postgres\": \"16-alpine\",\n    \"eventsourcingdb\": \"latest\"\n}\n</code></pre> </li> <li> <p>Test fixtures read this file to determine which image version to use.</p> </li> </ul>"},{"location":"development/contributing/#dependency-monitoring","title":"Dependency Monitoring","text":"<ul> <li>Dependabot is configured to monitor <code>.container-versions.json</code> for new container image versions and will open PRs for updates.</li> <li>Python and GitHub Actions dependencies are also monitored.</li> </ul>"},{"location":"development/contributing/#how-to-update-container-versions","title":"How to update container versions","text":"<ol> <li>Edit <code>.container-versions.json</code> and set the desired image tag.</li> <li>Run the tests locally to verify compatibility.</li> <li>Commit and push your changes.</li> <li>Dependabot will propose updates automatically when new versions are available.</li> </ol>"},{"location":"development/contributing/#contributing","title":"Contributing","text":"<p>Beitr\u00e4ge zu Orchestrix sind willkommen! Hier erf\u00e4hrst du, wie du mitmachen kannst.</p>"},{"location":"development/contributing/#setup-development-environment","title":"Setup Development Environment","text":""},{"location":"development/contributing/#1-repository-klonen","title":"1. Repository klonen","text":"<pre><code>git clone https://github.com/stefanposs/orchestrix.git\ncd orchestrix\n</code></pre>"},{"location":"development/contributing/#2-development-setup","title":"2. Development Setup","text":"<p>Mit <code>just</code> (empfohlen):</p> <pre><code>just setup\n</code></pre> <p>Oder manuell mit <code>uv</code>:</p> <pre><code>uv sync --all-extras --dev\n</code></pre>"},{"location":"development/contributing/#3-verify-installation","title":"3. Verify Installation","text":"<pre><code>just test\n</code></pre>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#available-commands","title":"Available Commands","text":"<pre><code># Setup\njust setup              # Initial setup\njust install PKG        # Install package\n\n# Development\njust fix                # Format and auto-fix code\njust qa                 # Run all quality checks\njust check              # Quick check (lint + typecheck)\n\n# Testing\njust test               # Run tests\njust test-cov           # Run tests with coverage\njust test-watch         # Watch mode\n\n# Build\njust build              # Build package\njust clean              # Clean build artifacts\n\n# Documentation\njust docs               # Serve documentation\njust docs-build         # Build documentation\njust docs-deploy        # Deploy to GitHub Pages\n\n# CI/CD\njust ci                 # Full CI pipeline\n</code></pre>"},{"location":"development/contributing/#code-quality-standards","title":"Code Quality Standards","text":"<p>Wir verwenden moderne Tools f\u00fcr hohe Code-Qualit\u00e4t:</p> <ul> <li>ruff - Linting &amp; Formatting (replaces black, isort, flake8, pylint)</li> <li>pytest - Testing Framework</li> <li>pytest-cov - Code Coverage (100% required)</li> </ul>"},{"location":"development/contributing/#before-committing","title":"Before Committing","text":"<pre><code># 1. Format code\njust fix\n\n# 2. Run quality checks\njust qa\n\n# 3. Verify tests pass\njust test-cov\n</code></pre> <p>Alle Checks m\u00fcssen bestehen! \u2705</p>"},{"location":"development/contributing/#coding-guidelines","title":"Coding Guidelines","text":""},{"location":"development/contributing/#messages","title":"Messages","text":"<pre><code># Commands: Imperativ\n@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_id: str\n\n# Events: Vergangenheit\n@dataclass(frozen=True, kw_only=True)\nclass OrderCreated(Event):\n    order_id: str\n    customer_id: str\n</code></pre>"},{"location":"development/contributing/#type-annotations","title":"Type Annotations","text":"<p>Immer vollst\u00e4ndige Type Hints verwenden:</p> <pre><code># \u2705 Gut\ndef handle(self, command: CreateOrder) -&gt; None:\n    events: list[Event] = []\n    order: Order = Order.create(command.order_id)\n\n# \u274c Schlecht\ndef handle(self, command):  # No types!\n    events = []\n    order = Order.create(command.order_id)\n</code></pre>"},{"location":"development/contributing/#docstrings","title":"Docstrings","text":"<p>Google-style Docstrings f\u00fcr \u00f6ffentliche APIs:</p> <pre><code>def subscribe(self, message_type: type[Message], handler: Callable) -&gt; None:\n    \"\"\"Subscribe a handler to a message type.\n\n    Args:\n        message_type: The message class to handle\n        handler: Callable or handler instance with handle() method\n\n    Example:\n        &gt;&gt;&gt; bus.subscribe(CreateOrder, create_order_handler)\n    \"\"\"\n</code></pre>"},{"location":"development/contributing/#tests","title":"Tests","text":"<p>Jede neue Funktion braucht Tests:</p> <pre><code>def test_message_bus_subscription():\n    \"\"\"Test that handlers are called when message is published.\"\"\"\n    # Arrange\n    bus = InMemoryMessageBus()\n    events_received = []\n    bus.subscribe(OrderCreated, lambda e: events_received.append(e))\n\n    # Act\n    event = OrderCreated(order_id=\"ORD-001\")\n    bus.publish(event)\n\n    # Assert\n    assert len(events_received) == 1\n    assert events_received[0].order_id == \"ORD-001\"\n</code></pre>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"development/contributing/#1-create-feature-branch","title":"1. Create Feature Branch","text":"<pre><code>git checkout -b feature/my-awesome-feature\n</code></pre>"},{"location":"development/contributing/#2-make-changes","title":"2. Make Changes","text":"<pre><code># Edit files (example)\nvim components/orchestrix.core.messaging.message_bus.py\n\n# Run tests continuously\njust test-watch\n</code></pre>"},{"location":"development/contributing/#3-commit-changes","title":"3. Commit Changes","text":"<p>Verwende Conventional Commits:</p> <pre><code>git add .\ngit commit -m \"feat: add async message bus implementation\"\n</code></pre> <p>Types: - <code>feat:</code> - Neue Features - <code>fix:</code> - Bug Fixes - <code>docs:</code> - Dokumentation - <code>test:</code> - Tests - <code>refactor:</code> - Code Refactoring - <code>perf:</code> - Performance Improvements - <code>ci:</code> - CI/CD Changes</p>"},{"location":"development/contributing/#4-run-final-checks","title":"4. Run Final Checks","text":"<pre><code>just ci\n</code></pre> <p>Alles muss gr\u00fcn sein! \u2705</p>"},{"location":"development/contributing/#5-push-create-pr","title":"5. Push &amp; Create PR","text":"<pre><code>git push origin feature/my-awesome-feature\n</code></pre> <p>Erstelle dann einen Pull Request auf GitHub mit:</p> <ul> <li>Beschreibung der \u00c4nderungen</li> <li>Warum die \u00c4nderung notwendig ist</li> <li>Tests die hinzugef\u00fcgt wurden</li> <li>Breaking Changes (falls vorhanden)</li> </ul>"},{"location":"development/contributing/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>Unsere GitHub Actions Pipeline testet:</p> <ul> <li>\u2705 Tests auf Python 3.9-3.13</li> <li>\u2705 Tests auf Linux, macOS, Windows</li> <li>\u2705 Ruff Linting</li> <li>\u2705 100% Code Coverage</li> </ul>"},{"location":"development/contributing/#architecture-decisions","title":"Architecture Decisions","text":""},{"location":"development/contributing/#adr-architecture-decision-records","title":"ADR (Architecture Decision Records)","text":"<p>Wichtige Design-Entscheidungen werden dokumentiert:</p> <pre><code># ADR-001: Use Protocols instead of Abstract Base Classes\n\n## Context\nNeed to define interfaces for MessageBus, EventStore, etc.\n\n## Decision\nUse typing.Protocol instead of ABC.\n\n## Rationale\n- More Pythonic (duck typing)\n- Better IDE support\n- No inheritance required\n- Easier to mock in tests\n\n## Consequences\nUsers can implement interfaces without inheriting from base classes.\n</code></pre>"},{"location":"development/contributing/#community","title":"Community","text":""},{"location":"development/contributing/#communication","title":"Communication","text":"<ul> <li>GitHub Issues - Bug Reports &amp; Feature Requests</li> <li>GitHub Discussions - Questions &amp; Ideas</li> <li>Pull Requests - Code Contributions</li> </ul>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Sei respektvoll und konstruktiv. Siehe CODE_OF_CONDUCT.md.</p>"},{"location":"development/contributing/#release-process","title":"Release Process","text":"<p>Releases werden automatisch erstellt:</p> <ol> <li>Update <code>CHANGELOG.md</code></li> <li>Tag version: <code>git tag v0.2.0</code></li> <li>Push tags: <code>git push --tags</code></li> <li>GitHub Actions publisht zu PyPI</li> </ol>"},{"location":"development/contributing/#questions","title":"Questions?","text":"<p>Erstelle ein GitHub Issue oder Discussion!</p>"},{"location":"development/contributing/#thank-you","title":"Thank You! \ud83c\udf89","text":"<p>Jeder Beitrag ist wertvoll - egal ob Code, Dokumentation, Bug Reports oder Feedback!</p>"},{"location":"development/testing/","title":"Testing","text":"<p>Comprehensive testing strategies f\u00fcr Orchestrix - von Unit bis Integration Tests.</p>"},{"location":"development/testing/#test-setup","title":"Test Setup","text":""},{"location":"development/testing/#installation","title":"Installation","text":"<pre><code># Install with test dependencies\nuv sync --all-extras --dev\n\n# Or with pip\npip install orchestrix[test]\n</code></pre>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py                 # Shared fixtures\n\u251c\u2500\u2500 unit/\n\u2502   \u251c\u2500\u2500 test_message.py        # Message tests\n\u2502   \u251c\u2500\u2500 test_aggregate.py      # Aggregate tests\n\u2502   \u2514\u2500\u2500 test_handlers.py       # Handler tests\n\u251c\u2500\u2500 integration/\n\u2502   \u251c\u2500\u2500 test_order_module.py   # Module integration tests\n\u2502   \u2514\u2500\u2500 test_event_flow.py     # End-to-end flows\n\u2514\u2500\u2500 performance/\n    \u2514\u2500\u2500 test_event_store.py    # Performance tests\n</code></pre>"},{"location":"development/testing/#unit-tests","title":"Unit Tests","text":""},{"location":"development/testing/#testing-messages","title":"Testing Messages","text":"<pre><code>def test_command_creation():\n    \"\"\"Test command with valid data.\"\"\"\n    command = CreateOrder(\n        order_id=\"ORD-001\",\n        customer_id=\"CUST-123\",\n        items=[{\"sku\": \"A\", \"qty\": 2}]\n    )\n\n    assert command.order_id == \"ORD-001\"\n    assert command.customer_id == \"CUST-123\"\n    assert len(command.items) == 1\n    assert command.type == \"CreateOrder\"\n    assert command.id  # Auto-generated UUID\n\ndef test_command_validation():\n    \"\"\"Test command validation in __post_init__.\"\"\"\n    with pytest.raises(ValueError, match=\"Order must have items\"):\n        CreateOrder(\n            order_id=\"ORD-001\",\n            customer_id=\"CUST-123\",\n            items=[]  # Invalid!\n        )\n</code></pre>"},{"location":"development/testing/#testing-aggregates","title":"Testing Aggregates","text":"<pre><code>def test_order_creation():\n    \"\"\"Test aggregate creation.\"\"\"\n    order = Order.create(\n        order_id=\"ORD-001\",\n        customer_id=\"CUST-123\",\n        items=[{\"sku\": \"A\", \"qty\": 2}]\n    )\n\n    assert order.order_id == \"ORD-001\"\n    assert order.status == \"pending\"\n\n    # Check events\n    events = order.collect_events()\n    assert len(events) == 1\n    assert isinstance(events[0], OrderCreated)\n\ndef test_order_cancellation():\n    \"\"\"Test aggregate business logic.\"\"\"\n    order = Order.create(\"ORD-001\", \"CUST-123\", [])\n    order.cancel()\n\n    assert order.status == \"cancelled\"\n\n    events = order.collect_events()\n    assert any(isinstance(e, OrderCancelled) for e in events)\n\ndef test_order_cannot_cancel_if_shipped():\n    \"\"\"Test business rule enforcement.\"\"\"\n    order = Order.create(\"ORD-001\", \"CUST-123\", [])\n    order.status = \"shipped\"  # Simulate shipping\n\n    with pytest.raises(ValueError, match=\"Cannot cancel shipped order\"):\n        order.cancel()\n</code></pre>"},{"location":"development/testing/#testing-event-reconstruction","title":"Testing Event Reconstruction","text":"<pre><code>def test_aggregate_reconstruction():\n    \"\"\"Test rebuilding aggregate from events.\"\"\"\n    events = [\n        OrderCreated(order_id=\"ORD-001\", customer_id=\"CUST-123\"),\n        ItemAdded(order_id=\"ORD-001\", item={\"sku\": \"A\"}),\n        ItemAdded(order_id=\"ORD-001\", item={\"sku\": \"B\"}),\n        OrderPaid(order_id=\"ORD-001\", payment_id=\"PAY-001\")\n    ]\n\n    order = Order.from_events(events)\n\n    assert order.order_id == \"ORD-001\"\n    assert len(order.items) == 2\n    assert order.status == \"paid\"\n</code></pre>"},{"location":"development/testing/#integration-tests","title":"Integration Tests","text":""},{"location":"development/testing/#testing-with-messagebus","title":"Testing with MessageBus","text":"<pre><code>@pytest.fixture\ndef bus():\n    \"\"\"Provide clean message bus.\"\"\"\n    return InMemoryMessageBus()\n\n@pytest.fixture\ndef store():\n    \"\"\"Provide clean event store.\"\"\"\n    return InMemoryEventStore()\n\ndef test_command_handler_integration(bus, store):\n    \"\"\"Test command handler with infrastructure.\"\"\"\n    # Register handler\n    handler = CreateOrderHandler(bus, store)\n    bus.subscribe(CreateOrder, handler)\n\n    # Execute command\n    command = CreateOrder(\n        order_id=\"ORD-001\",\n        customer_id=\"CUST-123\",\n        items=[{\"sku\": \"A\", \"qty\": 2}]\n    )\n    bus.publish(command)\n\n    # Verify events stored\n    events = store.load(\"ORD-001\")\n    assert len(events) == 1\n    assert isinstance(events[0], OrderCreated)\n</code></pre>"},{"location":"development/testing/#testing-event-handlers","title":"Testing Event Handlers","text":"<pre><code>def test_event_handler_called(bus):\n    \"\"\"Test that event handlers are invoked.\"\"\"\n    events_received = []\n\n    # Subscribe event handler\n    bus.subscribe(OrderCreated, lambda e: events_received.append(e))\n\n    # Publish event\n    event = OrderCreated(order_id=\"ORD-001\", customer_id=\"CUST-123\")\n    bus.publish(event)\n\n    # Verify handler was called\n    assert len(events_received) == 1\n    assert events_received[0].order_id == \"ORD-001\"\n\ndef test_multiple_event_handlers(bus):\n    \"\"\"Test multiple handlers for same event.\"\"\"\n    handler1_called = []\n    handler2_called = []\n\n    bus.subscribe(OrderCreated, lambda e: handler1_called.append(e))\n    bus.subscribe(OrderCreated, lambda e: handler2_called.append(e))\n\n    event = OrderCreated(order_id=\"ORD-001\", customer_id=\"CUST-123\")\n    bus.publish(event)\n\n    assert len(handler1_called) == 1\n    assert len(handler2_called) == 1\n</code></pre>"},{"location":"development/testing/#testing-complete-modules","title":"Testing Complete Modules","text":"<pre><code>def test_order_module(bus, store):\n    \"\"\"Test complete module registration and execution.\"\"\"\n    # Register module\n    module = OrderModule()\n    module.register(bus, store)\n\n    # Execute command\n    bus.publish(CreateOrder(\n        order_id=\"ORD-001\",\n        customer_id=\"CUST-123\",\n        items=[{\"sku\": \"A\", \"qty\": 2}]\n    ))\n\n    # Verify events\n    events = store.load(\"ORD-001\")\n    assert len(events) == 1\n    assert isinstance(events[0], OrderCreated)\n\n    # Execute another command\n    bus.publish(CancelOrder(order_id=\"ORD-001\"))\n\n    # Verify new events\n    events = store.load(\"ORD-001\")\n    assert len(events) == 2\n    assert isinstance(events[1], OrderCancelled)\n</code></pre>"},{"location":"development/testing/#test-patterns","title":"Test Patterns","text":""},{"location":"development/testing/#message-spy-pattern","title":"Message Spy Pattern","text":"<p>Collect all messages for assertions:</p> <pre><code>class MessageSpy:\n    \"\"\"Spy to collect published messages.\"\"\"\n\n    def __init__(self):\n        self.messages = []\n\n    def record(self, message):\n        self.messages.append(message)\n\n    def get_by_type(self, message_type):\n        return [m for m in self.messages if isinstance(m, message_type)]\n\n    def count(self, message_type):\n        return len(self.get_by_type(message_type))\n\n@pytest.fixture\ndef message_spy(bus):\n    \"\"\"Provide message spy.\"\"\"\n    spy = MessageSpy()\n    # Subscribe to all message types\n    bus.subscribe(OrderCreated, spy.record)\n    bus.subscribe(OrderCancelled, spy.record)\n    return spy\n\ndef test_with_spy(bus, message_spy):\n    \"\"\"Test using message spy.\"\"\"\n    bus.publish(OrderCreated(order_id=\"ORD-001\", ...))\n\n    assert message_spy.count(OrderCreated) == 1\n    assert message_spy.count(OrderCancelled) == 0\n</code></pre>"},{"location":"development/testing/#fakemock-pattern","title":"Fake/Mock Pattern","text":"<pre><code>class FakeEventStore(EventStore):\n    \"\"\"Fake event store for testing.\"\"\"\n\n    def __init__(self):\n        self.saved_events = {}\n        self.load_calls = []\n\n    def save(self, aggregate_id: str, events: list[Event]) -&gt; None:\n        if aggregate_id not in self.saved_events:\n            self.saved_events[aggregate_id] = []\n        self.saved_events[aggregate_id].extend(events)\n\n    def load(self, aggregate_id: str) -&gt; list[Event]:\n        self.load_calls.append(aggregate_id)\n        return self.saved_events.get(aggregate_id, [])\n\ndef test_with_fake_store():\n    \"\"\"Test using fake store.\"\"\"\n    store = FakeEventStore()\n\n    # Use fake in test\n    handler = CreateOrderHandler(bus, store)\n    handler.handle(CreateOrder(...))\n\n    # Assert on fake\n    assert \"ORD-001\" in store.saved_events\n    assert len(store.load_calls) == 0\n</code></pre>"},{"location":"development/testing/#parameterized-tests","title":"Parameterized Tests","text":"<pre><code>@pytest.mark.parametrize(\"status,can_cancel\", [\n    (\"pending\", True),\n    (\"paid\", True),\n    (\"shipped\", False),\n    (\"cancelled\", False),\n])\ndef test_order_cancellation_rules(status, can_cancel):\n    \"\"\"Test cancellation rules for different statuses.\"\"\"\n    order = Order.create(\"ORD-001\", \"CUST-123\", [])\n    order.status = status\n\n    if can_cancel:\n        order.cancel()\n        assert order.status == \"cancelled\"\n    else:\n        with pytest.raises(ValueError):\n            order.cancel()\n</code></pre>"},{"location":"development/testing/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"development/testing/#aaa-pattern","title":"AAA Pattern","text":"<p>Arrange-Act-Assert:</p> <pre><code>def test_order_creation():\n    # Arrange\n    bus = InMemoryMessageBus()\n    store = InMemoryEventStore()\n    handler = CreateOrderHandler(bus, store)\n    bus.subscribe(CreateOrder, handler)\n\n    # Act\n    bus.publish(CreateOrder(order_id=\"ORD-001\", ...))\n\n    # Assert\n    events = store.load(\"ORD-001\")\n    assert len(events) == 1\n</code></pre>"},{"location":"development/testing/#test-isolation","title":"Test Isolation","text":"<pre><code>@pytest.fixture\ndef clean_bus():\n    \"\"\"Each test gets fresh bus.\"\"\"\n    return InMemoryMessageBus()\n\ndef test_1(clean_bus):\n    # Test 1 doesn't affect test 2\n    pass\n\ndef test_2(clean_bus):\n    # Fresh bus, no state from test 1\n    pass\n</code></pre>"},{"location":"development/testing/#descriptive-names","title":"Descriptive Names","text":"<pre><code># \u2705 Gut\ndef test_order_cannot_be_cancelled_after_shipping():\n    pass\n\ndef test_aggregate_emits_correct_events_on_creation():\n    pass\n\n# \u274c Schlecht\ndef test_order_1():\n    pass\n\ndef test_stuff():\n    pass\n</code></pre>"},{"location":"development/testing/#coverage","title":"Coverage","text":""},{"location":"development/testing/#run-with-coverage","title":"Run with Coverage","text":"<pre><code>just test-cov\n</code></pre>"},{"location":"development/testing/#view-html-report","title":"View HTML Report","text":"<pre><code>just test-cov\nopen htmlcov/index.html\n</code></pre>"},{"location":"development/testing/#coverage-requirements","title":"Coverage Requirements","text":"<p>Orchestrix requires 100% code coverage:</p> <pre><code>[tool.pytest.ini_options]\naddopts = \"--cov=orchestrix --cov-report=term --cov-report=html --cov-report=xml --cov-fail-under=100\"\n</code></pre>"},{"location":"development/testing/#exclude-from-coverage","title":"Exclude from Coverage","text":"<p>Nur in Ausnahmef\u00e4llen:</p> <pre><code>def __repr__(self):  # pragma: no cover\n    return f\"Order({self.order_id})\"\n</code></pre>"},{"location":"development/testing/#performance-tests","title":"Performance Tests","text":"<pre><code>import time\n\ndef test_event_store_performance():\n    \"\"\"Test event store can handle large event streams.\"\"\"\n    store = InMemoryEventStore()\n\n    # Create 10,000 events\n    events = [\n        OrderCreated(order_id=f\"ORD-{i}\", ...)\n        for i in range(10_000)\n    ]\n\n    # Measure save time\n    start = time.time()\n    store.save(\"ORD-001\", events)\n    duration = time.time() - start\n\n    assert duration &lt; 1.0  # Should be fast\n\n    # Measure load time\n    start = time.time()\n    loaded = store.load(\"ORD-001\")\n    duration = time.time() - start\n\n    assert len(loaded) == 10_000\n    assert duration &lt; 0.1  # Should be very fast\n</code></pre>"},{"location":"development/testing/#continuous-testing","title":"Continuous Testing","text":""},{"location":"development/testing/#watch-mode","title":"Watch Mode","text":"<pre><code>just test-watch\n</code></pre> <p>Tests laufen bei jeder \u00c4nderung automatisch!</p>"},{"location":"development/testing/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># Install hooks\nuv run pre-commit install\n\n# Runs automatically on git commit\ngit commit -m \"feat: add new feature\"\n</code></pre>"},{"location":"development/testing/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture - System Design</li> <li>Contributing - Contribution Guidelines</li> <li>Best Practices - Production Tips</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>Orchestrix comes with production-ready examples demonstrating real-world patterns and best practices for event-driven architectures.</p>"},{"location":"examples/#available-examples","title":"Available Examples","text":""},{"location":"examples/#banking","title":"\ud83c\udfe6 Banking","text":"<p>Account management system with event sourcing, including:</p> <ul> <li>Account creation and transactions</li> <li>Event-driven balance updates</li> <li>Transaction history and audit trail</li> <li>Domain-driven design patterns</li> </ul> <p>Key Concepts: Event Sourcing, Aggregates, Domain Events Source: <code>bases/orchestrix/banking/</code> Run: <code>uv run python -m orchestrix.banking.main</code></p>"},{"location":"examples/#e-commerce","title":"\ud83d\uded2 E-Commerce","text":"<p>Complete order processing system with:</p> <ul> <li>Order lifecycle management</li> <li>Saga pattern for distributed transactions</li> <li>Payment processing coordination</li> <li>Inventory management integration</li> </ul> <p>Key Concepts: Sagas, Process Managers, Event Choreography Source: <code>examples/ecommerce/</code> Run: <code>uv run python -m examples.ecommerce.example</code></p>"},{"location":"examples/#lakehouse-platform","title":"\ud83c\udfe2 Lakehouse Platform","text":"<p>Data lakehouse with GDPR compliance featuring:</p> <ul> <li>GDPR Compliance - Right-to-be-forgotten implementation</li> <li>Data Anonymization - 8 anonymization strategies</li> <li>Event sourcing for audit trails</li> <li>Snapshot optimization for large event streams</li> </ul> <p>Key Concepts: GDPR Compliance, Data Anonymization, Event Store, Snapshots Source: <code>examples/lakehouse/</code> Quick Start: - Anonymization: <code>uv run python -m examples.lakehouse.example</code> - GDPR Demo: <code>uv run python examples/lakehouse/gdpr_simple.py</code></p>"},{"location":"examples/#notifications","title":"\ud83d\udd14 Notifications","text":"<p>Resilient notification system with:</p> <ul> <li>Retry logic with exponential backoff</li> <li>Dead letter queue for failed messages</li> <li>Email, SMS, and push notification channels</li> <li>Circuit breaker pattern</li> </ul> <p>Key Concepts: Resilience Patterns, Dead Letter Queue, Retries Source: <code>examples/notifications/</code> Run: <code>uv run python -m examples.notifications.example</code></p>"},{"location":"examples/#sagas","title":"\ud83d\udd04 Sagas","text":"<p>Long-running business processes with compensation:</p> <ul> <li>Distributed transaction coordination</li> <li>Automatic rollback on failure</li> <li>State management and recovery</li> <li>Multi-aggregate workflows</li> </ul> <p>Key Concepts: Saga Pattern, Compensation, Process Managers Source: <code>examples/sagas/</code> Run: <code>uv run python examples/sagas/example.py</code></p>"},{"location":"examples/#projections","title":"\ud83d\udcca Projections","text":"<p>Building optimized read models:</p> <ul> <li>Event-driven projections</li> <li>Multiple backend support (InMemory, PostgreSQL)</li> <li>Automatic updates from event streams</li> <li>Query optimization</li> </ul> <p>Key Concepts: CQRS, Read Models, Denormalization Source: <code>examples/projections/</code> Run: <code>uv run python examples/projections/example.py</code></p>"},{"location":"examples/#distributed-tracing","title":"\ud83d\udd0d Distributed Tracing","text":"<p>OpenTelemetry integration with Jaeger:</p> <ul> <li>Automatic span creation</li> <li>Trace context propagation</li> <li>Service dependency mapping</li> <li>Performance analysis</li> </ul> <p>Key Concepts: Observability, OpenTelemetry, Jaeger Source: <code>examples/tracing/</code> Run: <code>uv run python examples/tracing/example.py</code></p>"},{"location":"examples/#prometheus-metrics","title":"\ud83d\udcc8 Prometheus Metrics","text":"<p>Production metrics collection:</p> <ul> <li>Message throughput tracking</li> <li>Handler latency histograms</li> <li>Error rate monitoring</li> <li>Event store performance</li> </ul> <p>Key Concepts: Metrics, Monitoring, Prometheus Source: <code>examples/prometheus/</code> Run: <code>uv run python examples/prometheus/example.py</code></p>"},{"location":"examples/#event-versioning","title":"\ud83d\udd22 Event Versioning","text":"<p>Schema evolution with upcasters:</p> <ul> <li>Event schema migration</li> <li>Backward compatibility</li> <li>Chained version transforms</li> <li>Type-safe versioning</li> </ul> <p>Key Concepts: Schema Evolution, Upcasters, Backward Compatibility Source: <code>examples/versioning/</code> Run: <code>uv run python examples/versioning/example.py</code></p>"},{"location":"examples/#running-examples","title":"Running Examples","text":"<p>All examples are located in the <code>examples/</code> directory and can be run directly:</p> <pre><code># Banking example\nuv run python -m examples.banking.example\n\n# E-Commerce example  \nuv run python -m examples.ecommerce.example\n\n# Lakehouse anonymization\nuv run python -m examples.lakehouse.example\n\n# Lakehouse GDPR compliance\nuv run python examples/lakehouse/gdpr_simple.py\n\n# Notifications example\nuv run python -m examples.notifications.example\n</code></pre>"},{"location":"examples/#example-structure","title":"Example Structure","text":"<p>Each example follows a consistent structure:</p> <pre><code>examples/\n\u251c\u2500\u2500 {domain}/\n\u2502   \u251c\u2500\u2500 README.md              # Overview and quick start\n\u2502   \u251c\u2500\u2500 __init__.py            # Module exports\n\u2502   \u251c\u2500\u2500 models.py              # Commands, Events, Domain models\n\u2502   \u251c\u2500\u2500 aggregate.py           # Aggregate root with business logic\n\u2502   \u251c\u2500\u2500 handlers.py            # Command and event handlers\n\u2502   \u251c\u2500\u2500 saga.py                # Saga orchestration (if applicable)\n\u2502   \u2514\u2500\u2500 example.py             # Runnable demo\n</code></pre>"},{"location":"examples/#learning-path","title":"Learning Path","text":""},{"location":"examples/#1-start-with-banking","title":"1. Start with Banking","text":"<p>Learn the fundamentals of event sourcing and aggregates with a simple domain.</p>"},{"location":"examples/#2-move-to-e-commerce","title":"2. Move to E-Commerce","text":"<p>Understand sagas and process managers for coordinating distributed transactions.</p>"},{"location":"examples/#3-study-lakehouse","title":"3. Study Lakehouse","text":"<p>See production patterns for compliance, data management, and advanced event sourcing.</p>"},{"location":"examples/#4-explore-notifications","title":"4. Explore Notifications","text":"<p>Master resilience patterns, retries, and error handling.</p>"},{"location":"examples/#common-patterns","title":"Common Patterns","text":"<p>All examples demonstrate these key patterns:</p>"},{"location":"examples/#event-sourcing","title":"Event Sourcing","text":"<pre><code>class OrderAggregate(AggregateRoot):\n    def handle_create_order(self, cmd: CreateOrder):\n        event = OrderCreated(order_id=cmd.order_id, ...)\n        self._apply_event(event)\n\n    def _when_order_created(self, event: OrderCreated):\n        self.order_id = event.order_id\n        self.status = OrderStatus.PENDING\n</code></pre>"},{"location":"examples/#commandevent-separation","title":"Command/Event Separation","text":"<pre><code># Command (intent)\n@dataclass(frozen=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_id: str\n\n# Event (fact)\n@dataclass(frozen=True)\nclass OrderCreated(Event):\n    order_id: str\n    customer_id: str\n    timestamp: datetime\n</code></pre>"},{"location":"examples/#saga-pattern","title":"Saga Pattern","text":"<pre><code>async def on_order_created(event: OrderCreated, bus: MessageBus):\n    # Step 1: Reserve inventory\n    await bus.send(ReserveInventory(order_id=event.order_id))\n\n    # Step 2: Process payment\n    await bus.send(ProcessPayment(order_id=event.order_id))\n</code></pre>"},{"location":"examples/#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started - Build your first module</li> <li>Core Concepts - Understand the framework</li> <li>API Reference - Detailed API documentation</li> <li>Best Practices - Production guidelines</li> </ul>"},{"location":"examples/#contributing-examples","title":"Contributing Examples","text":"<p>Have a great example? Contributions are welcome! See our Contributing Guide.</p> <p>Examples should:</p> <ul> <li>\u2705 Demonstrate a real-world use case</li> <li>\u2705 Follow consistent structure</li> <li>\u2705 Include comprehensive README</li> <li>\u2705 Be fully runnable</li> <li>\u2705 Show best practices</li> <li>\u2705 Include inline documentation</li> </ul>"},{"location":"examples/banking/","title":"Banking: Money Transfers with Compensation","text":"<p>This example demonstrates money transfers between accounts with automatic compensation when transfers fail, showcasing the Saga pattern and event sourcing.</p> <p>\ud83d\udcc2 Source Code: Complete Example: <code>bases/orchestrix/banking/</code> Main Demo: <code>bases/orchestrix/banking/main.py</code> Domain Models: <code>bases/orchestrix/banking/models.py</code></p>"},{"location":"examples/banking/#overview","title":"Overview","text":"<p>The banking example demonstrates:</p> <ul> <li>\u2705 Money Transfers - Between accounts with saga coordination</li> <li>\u2705 Automatic Compensation - Rollback on failure</li> <li>\u2705 Event-Sourced Balances - Balance calculated from events</li> <li>\u2705 Two-Phase Commit - Distributed transaction pattern</li> <li>\u2705 Transaction Audit Trail - Complete immutable history</li> </ul>"},{"location":"examples/banking/#quick-start","title":"Quick Start","text":"<pre><code># Run the banking example\nuv run python -m examples.banking.example\n</code></pre>"},{"location":"examples/banking/#architecture","title":"Architecture","text":"<p>The transfer saga coordinates a distributed transaction:</p> <pre><code>TransferMoney Command\n    \u2193\nTransferInitiated Event \u2192 TransferSaga\n    \u2193\nWithdrawMoney Command (Debit source)\n    \u2193\nTransferDebited Event \u2192 TransferSaga\n    \u2193\nDepositMoney Command (Credit destination)\n    \u2193\nTransferCompleted Event \u2705\n</code></pre>"},{"location":"examples/banking/#compensation-flow","title":"Compensation Flow","text":"<p>If the destination deposit fails, the saga automatically compensates:</p> <pre><code>DepositMoney fails (e.g., account closed)\n    \u2193\nDepositMoney Command (Re-credit source)\n    \u2193\nTransferReversed Event\n    \u2193\nTransferFailed Event \u274c\n</code></pre>"},{"location":"examples/banking/#domain-model","title":"Domain Model","text":""},{"location":"examples/banking/#commands","title":"Commands","text":""},{"location":"examples/banking/#openaccount","title":"OpenAccount","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass OpenAccount(Command):\n    account_id: str\n    owner_name: str\n    initial_balance: Decimal\n</code></pre>"},{"location":"examples/banking/#transfermoney","title":"TransferMoney","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass TransferMoney(Command):\n    transfer_id: str\n    from_account_id: str\n    to_account_id: str\n    amount: Decimal\n    description: str\n</code></pre>"},{"location":"examples/banking/#withdrawmoney-depositmoney","title":"WithdrawMoney / DepositMoney","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass WithdrawMoney(Command):\n    account_id: str\n    amount: Decimal\n    transaction_id: str\n    description: str\n\n@dataclass(frozen=True, kw_only=True)\nclass DepositMoney(Command):\n    account_id: str\n    amount: Decimal\n    transaction_id: str\n    description: str\n</code></pre>"},{"location":"examples/banking/#events","title":"Events","text":"<ul> <li><code>AccountOpened</code> - Account created with initial balance</li> <li><code>MoneyDeposited</code> - Funds added to account</li> <li><code>MoneyWithdrawn</code> - Funds removed from account</li> <li><code>TransferInitiated</code> - Transfer started by saga</li> <li><code>TransferDebited</code> - Source account debited</li> <li><code>TransferCompleted</code> - Transfer successful</li> <li><code>TransferReversed</code> - Compensation executed</li> <li><code>TransferFailed</code> - Transfer failed after compensation</li> </ul>"},{"location":"examples/banking/#aggregate","title":"Aggregate","text":""},{"location":"examples/banking/#account","title":"Account","text":"<pre><code>@dataclass\nclass Account:\n    account_id: str\n    owner_name: str\n    balance: Decimal\n    status: AccountStatus  # ACTIVE, SUSPENDED, CLOSED\n\n    def withdraw(self, amount: Decimal, txn_id: str, description: str):\n        if self.balance &lt; amount:\n            raise ValueError(\"Insufficient balance\")\n        # Emit MoneyWithdrawn event\n\n    def deposit(self, amount: Decimal, txn_id: str, description: str):\n        # Emit MoneyDeposited event\n</code></pre>"},{"location":"examples/banking/#key-patterns","title":"Key Patterns","text":""},{"location":"examples/banking/#1-two-phase-commit","title":"1. Two-Phase Commit","text":"<p>The transfer saga implements a distributed transaction:</p> <ol> <li> <p>Phase 1: Debit source account    <pre><code>await bus.send(WithdrawMoney(\n    account_id=from_account,\n    amount=amount,\n    ...\n))\n</code></pre></p> </li> <li> <p>Phase 2: Credit destination account    <pre><code>await bus.send(DepositMoney(\n    account_id=to_account,\n    amount=amount,\n    ...\n))\n</code></pre></p> </li> <li> <p>Compensation: If phase 2 fails, reverse phase 1    <pre><code>await bus.send(DepositMoney(\n    account_id=from_account,  # Refund\n    amount=amount,\n    ...\n))\n</code></pre></p> </li> </ol>"},{"location":"examples/banking/#2-event-sourced-balance","title":"2. Event-Sourced Balance","text":"<p>Account balance is calculated from events, not stored directly:</p> <pre><code>balance = Decimal(\"0\")\nfor event in events:\n    if isinstance(event, AccountOpened):\n        balance = event.initial_balance\n    elif isinstance(event, MoneyDeposited):\n        balance += event.amount\n    elif isinstance(event, MoneyWithdrawn):\n        balance -= event.amount\n</code></pre> <p>Benefits: - Complete audit trail - Temporal queries (\"balance at time X\") - Replay for debugging - No lost updates</p>"},{"location":"examples/banking/#3-saga-state-management","title":"3. Saga State Management","text":"<p>The saga stores state implicitly through events:</p> <pre><code>class TransferSaga:\n    def on_transfer_initiated(self, event: TransferInitiated):\n        # Start phase 1: debit source\n        self.send(WithdrawMoney(...))\n\n    def on_transfer_debited(self, event: TransferDebited):\n        # Phase 1 complete, start phase 2: credit destination\n        self.send(DepositMoney(...))\n\n    def on_money_deposited(self, event: MoneyDeposited):\n        # Phase 2 complete, transfer successful\n        self.send(CompleteTransfer(...))\n</code></pre>"},{"location":"examples/banking/#4-transaction-log","title":"4. Transaction Log","text":"<p>All balance changes are immutable events providing a complete transaction history:</p> <pre><code># Load transaction history\nevents = await event_store.load_async(\"account-123\")\n\nfor event in events:\n    if isinstance(event, MoneyWithdrawn):\n        print(f\"Debit:  ${event.amount} - {event.description}\")\n    elif isinstance(event, MoneyDeposited):\n        print(f\"Credit: ${event.amount} - {event.description}\")\n</code></pre>"},{"location":"examples/banking/#business-rules","title":"Business Rules","text":""},{"location":"examples/banking/#account-rules","title":"Account Rules","text":"<ul> <li>\u2705 Initial balance cannot be negative</li> <li>\u2705 Cannot withdraw more than balance (no overdraft)</li> <li>\u2705 Cannot operate on suspended/closed accounts</li> <li>\u2705 Cannot close account with non-zero balance</li> </ul>"},{"location":"examples/banking/#transfer-rules","title":"Transfer Rules","text":"<ul> <li>\u2705 Both accounts must be active</li> <li>\u2705 Source must have sufficient funds</li> <li>\u2705 If destination fails, source is automatically refunded</li> <li>\u2705 Transfer ID must be unique (idempotency)</li> </ul>"},{"location":"examples/banking/#usage-example","title":"Usage Example","text":"<pre><code>import asyncio\nfrom decimal import Decimal\n\nfrom orchestrix.core.eventsourcing.aggregate import AggregateRepository\nfrom orchestrix.infrastructure.memory import InMemoryEventStore, InMemoryMessageBus\n\nfrom examples.banking.aggregate import Account\nfrom examples.banking.handlers import register_handlers\nfrom examples.banking.models import OpenAccount, TransferMoney\nfrom examples.banking.saga import register_saga\n\n\nasync def main():\n    # Setup infrastructure\n    event_store = InMemoryEventStore()\n    message_bus = InMemoryMessageBus()\n    repository = AggregateRepository(event_store)\n\n    # Register handlers and saga\n    register_handlers(message_bus, repository)\n    register_saga(message_bus, repository)\n\n    # Open two accounts\n    await message_bus.publish_async(\n        OpenAccount(\n            account_id=\"acc-alice\",\n            owner_name=\"Alice\",\n            initial_balance=Decimal(\"1000.00\"),\n        )\n    )\n    await message_bus.publish_async(\n        OpenAccount(\n            account_id=\"acc-bob\",\n            owner_name=\"Bob\",\n            initial_balance=Decimal(\"500.00\"),\n        )\n    )\n\n    # Transfer money from Alice to Bob\n    await message_bus.publish_async(\n        TransferMoney(\n            transfer_id=\"txn-001\",\n            from_account_id=\"acc-alice\",\n            to_account_id=\"acc-bob\",\n            amount=Decimal(\"250.00\"),\n            description=\"Payment for services\",\n        )\n    )\n\n    # Wait for saga to complete\n    await asyncio.sleep(0.1)\n\n    # Check final balances\n    alice = await repository.load_async(Account, \"acc-alice\")\n    bob = await repository.load_async(Account, \"acc-bob\")\n\n    print(f\"Alice balance: ${alice.balance}\")  # $750.00\n    print(f\"Bob balance: ${bob.balance}\")      # $750.00\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/banking/#testing","title":"Testing","text":""},{"location":"examples/banking/#test-insufficient-funds","title":"Test Insufficient Funds","text":"<pre><code>async def test_insufficient_funds():\n    # Setup\n    account = Account()\n    account.open(\"test-1\", \"Test User\", Decimal(\"100.00\"))\n\n    # Try to withdraw more than balance\n    with pytest.raises(ValueError, match=\"Insufficient balance\"):\n        account.withdraw(Decimal(\"200.00\"), \"txn-1\", \"Test withdrawal\")\n</code></pre>"},{"location":"examples/banking/#test-transfer-compensation","title":"Test Transfer Compensation","text":"<pre><code>async def test_transfer_compensation():\n    # Setup: Alice has money, Bob's account is closed\n    alice = Account()\n    alice.open(\"alice\", \"Alice\", Decimal(\"1000.00\"))\n    await repository.save_async(alice)\n\n    bob = Account()\n    bob.open(\"bob\", \"Bob\", Decimal(\"0.00\"))\n    bob.close()  # Close Bob's account\n    await repository.save_async(bob)\n\n    # Try to transfer (will fail and compensate)\n    await message_bus.publish_async(\n        TransferMoney(\n            transfer_id=\"txn-1\",\n            from_account_id=\"alice\",\n            to_account_id=\"bob\",\n            amount=Decimal(\"100.00\"),\n            description=\"Test transfer\",\n        )\n    )\n\n    # Wait for compensation\n    await asyncio.sleep(0.1)\n\n    # Verify Alice's money was returned\n    alice_final = await repository.load_async(Account, \"alice\")\n    assert alice_final.balance == Decimal(\"1000.00\")\n</code></pre>"},{"location":"examples/banking/#projections","title":"Projections","text":"<p>Build account statement projection from events:</p> <pre><code>@dataclass\nclass AccountStatement:\n    account_id: str\n    transactions: list[dict]\n\n    @classmethod\n    async def build(cls, account_id: str, event_store):\n        events = await event_store.load_async(account_id)\n        transactions = []\n\n        for event in events:\n            if event.type == \"MoneyDeposited\":\n                transactions.append({\n                    \"type\": \"Credit\",\n                    \"amount\": event.data.amount,\n                    \"description\": event.data.description,\n                    \"timestamp\": event.data.deposited_at,\n                    \"balance_after\": calculate_balance_after(event),\n                })\n            elif event.type == \"MoneyWithdrawn\":\n                transactions.append({\n                    \"type\": \"Debit\",\n                    \"amount\": event.data.amount,\n                    \"description\": event.data.description,\n                    \"timestamp\": event.data.withdrawn_at,\n                    \"balance_after\": calculate_balance_after(event),\n                })\n\n        return cls(account_id=account_id, transactions=transactions)\n\n# Usage\nstatement = await AccountStatement.build(\"acc-alice\", event_store)\nfor txn in statement.transactions:\n    print(f\"{txn['type']}: ${txn['amount']} - {txn['description']}\")\n</code></pre>"},{"location":"examples/banking/#production-considerations","title":"Production Considerations","text":""},{"location":"examples/banking/#1-idempotency","title":"1. Idempotency","text":"<p>Track transfer IDs to prevent duplicate processing:</p> <pre><code>processed_transfers = set()\n\nasync def handle_transfer(command: TransferMoney):\n    if command.transfer_id in processed_transfers:\n        return  # Already processed\n\n    # Process transfer\n    await saga.initiate_transfer(command)\n\n    processed_transfers.add(command.transfer_id)\n</code></pre>"},{"location":"examples/banking/#2-timeout-handling","title":"2. Timeout Handling","text":"<p>Add saga timeout for stuck transfers:</p> <pre><code>class TransferSaga:\n    timeout: timedelta = timedelta(minutes=5)\n\n    async def check_timeouts(self):\n        for transfer_id, initiated_at in self.pending_transfers.items():\n            if datetime.now() - initiated_at &gt; self.timeout:\n                await self.cancel_transfer(transfer_id, \"Timeout\")\n</code></pre>"},{"location":"examples/banking/#3-retry-logic","title":"3. Retry Logic","text":"<p>Retry failed operations with exponential backoff:</p> <pre><code>@retry(\n    max_attempts=3,\n    backoff=exponential_backoff(initial=1.0, multiplier=2.0),\n    exceptions=(NetworkError, TimeoutError)\n)\nasync def send_deposit_command(command: DepositMoney):\n    await message_bus.send(command)\n</code></pre>"},{"location":"examples/banking/#4-concurrency-control","title":"4. Concurrency Control","text":"<p>Use optimistic locking to prevent race conditions:</p> <pre><code>class Account:\n    version: int = 0\n\n    async def save(self):\n        expected_version = self.version\n        # Save will fail if version doesn't match\n        await repository.save(self, expected_version=expected_version)\n</code></pre>"},{"location":"examples/banking/#5-monitoring","title":"5. Monitoring","text":"<p>Track transfer metrics:</p> <pre><code>metrics = {\n    \"transfers_initiated\": Counter(),\n    \"transfers_completed\": Counter(),\n    \"transfers_failed\": Counter(),\n    \"compensation_executed\": Counter(),\n    \"avg_transfer_duration\": Histogram(),\n}\n\n# Usage\nmetrics[\"transfers_initiated\"].inc()\nstart = time.time()\n# ... process transfer ...\nmetrics[\"avg_transfer_duration\"].observe(time.time() - start)\n</code></pre>"},{"location":"examples/banking/#related-examples","title":"Related Examples","text":"<ul> <li>E-Commerce - Multi-aggregate sagas for order processing</li> <li>Notifications - Retry logic and error handling</li> <li>Lakehouse GDPR - Event sourcing with compliance</li> </ul>"},{"location":"examples/banking/#learn-more","title":"Learn More","text":"<ul> <li>Saga Pattern Guide</li> <li>Event Sourcing</li> <li>Testing Strategies</li> </ul>"},{"location":"examples/banking/#source-code","title":"Source Code","text":"<ul> <li><code>aggregate.py</code> - Account aggregate</li> <li><code>saga.py</code> - Transfer saga coordinator</li> <li><code>handlers.py</code> - Command handlers</li> <li><code>models.py</code> - Commands and events</li> </ul> <p>Browse Complete Example \u2192</p>"},{"location":"examples/ecommerce/","title":"E-Commerce: Order Processing with Sagas","text":"<p>This example demonstrates a complete order processing workflow using multi-aggregate sagas, compensation logic, and async event handlers.</p> <p>\ud83d\udcc2 Source Code: Complete Example: <code>examples/ecommerce/</code> Main Demo: <code>examples/ecommerce/example.py</code> Domain Models: <code>examples/ecommerce/models.py</code></p>"},{"location":"examples/ecommerce/#overview","title":"Overview","text":"<p>The e-commerce example demonstrates:</p> <ul> <li>\u2705 Order State Machine - Manages order lifecycle</li> <li>\u2705 Multi-Aggregate Saga - Coordinates Order \u2192 Payment \u2192 Inventory</li> <li>\u2705 Compensation Logic - Automatic rollback on failure</li> <li>\u2705 Async Event Handlers - Notification processing</li> <li>\u2705 Distributed Transactions - Across multiple aggregates</li> </ul>"},{"location":"examples/ecommerce/#quick-start","title":"Quick Start","text":"<pre><code># Run the e-commerce example\nuv run python -m examples.ecommerce.example\n</code></pre>"},{"location":"examples/ecommerce/#architecture","title":"Architecture","text":"<p>The order saga coordinates a distributed workflow across multiple aggregates:</p> <pre><code>CreateOrder Command\n    \u2193\nOrderAggregate.create()\n    \u2193\nOrderCreated Event \u2192 OrderSaga\n    \u2193\nProcessPayment Command\n    \u2193\nPaymentCompleted Event \u2192 OrderSaga\n    \u2193\nReserveInventory Command\n    \u2193\nInventoryReserved Event \u2192 OrderSaga\n    \u2193\nConfirmOrder Command\n    \u2193\nOrderConfirmed Event \u2705\n</code></pre>"},{"location":"examples/ecommerce/#compensation-flow","title":"Compensation Flow","text":"<p>If any step fails, the saga automatically compensates:</p> <pre><code>InventoryReservationFailed Event \u2192 OrderSaga\n    \u2193\nRefundPayment Command\n    \u2193\nPaymentRefunded Event\n    \u2193\nCancelOrder Command\n    \u2193\nOrderCancelled Event \u2192 Release Inventory \u274c\n</code></pre>"},{"location":"examples/ecommerce/#domain-model","title":"Domain Model","text":""},{"location":"examples/ecommerce/#commands","title":"Commands","text":""},{"location":"examples/ecommerce/#createorder","title":"CreateOrder","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_id: str\n    items: list[OrderItem]\n    shipping_address: Address\n\n@dataclass\nclass OrderItem:\n    product_id: str\n    quantity: int\n    unit_price: Decimal\n\n@dataclass\nclass Address:\n    street: str\n    city: str\n    state: str\n    postal_code: str\n    country: str\n</code></pre>"},{"location":"examples/ecommerce/#processpayment","title":"ProcessPayment","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass ProcessPayment(Command):\n    order_id: str\n    amount: Decimal\n    payment_method: str  # \"credit_card\", \"paypal\", etc.\n</code></pre>"},{"location":"examples/ecommerce/#reserveinventory","title":"ReserveInventory","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass ReserveInventory(Command):\n    order_id: str\n    items: list[OrderItem]\n</code></pre>"},{"location":"examples/ecommerce/#events","title":"Events","text":"<p>Order Events: - <code>OrderCreated</code> - Order created by customer - <code>OrderConfirmed</code> - Payment and inventory successful - <code>OrderCancelled</code> - Order cancelled or compensation executed - <code>OrderShipped</code> - Order dispatched to customer</p> <p>Payment Events: - <code>PaymentProcessing</code> - Payment initiated - <code>PaymentCompleted</code> - Payment successful - <code>PaymentFailed</code> - Payment rejected - <code>PaymentRefunded</code> - Payment compensated</p> <p>Inventory Events: - <code>InventoryReserved</code> - Items reserved for order - <code>InventoryReservationFailed</code> - Not enough stock - <code>InventoryReleased</code> - Reservation cancelled</p>"},{"location":"examples/ecommerce/#aggregate","title":"Aggregate","text":""},{"location":"examples/ecommerce/#order","title":"Order","text":"<pre><code>@dataclass\nclass Order:\n    order_id: str\n    customer_id: str\n    items: list[OrderItem]\n    status: OrderStatus  # State machine\n    total_amount: Decimal\n    payment_id: Optional[str] = None\n    reservation_id: Optional[str] = None\n\n    def create(self, ...):\n        # Emit OrderCreated\n\n    def complete_payment(self, payment_id: str):\n        # Emit PaymentCompleted\n\n    def reserve_inventory(self, reservation_id: str):\n        # Emit InventoryReserved\n\n    def confirm(self):\n        # Emit OrderConfirmed\n</code></pre>"},{"location":"examples/ecommerce/#key-patterns","title":"Key Patterns","text":""},{"location":"examples/ecommerce/#1-state-machine","title":"1. State Machine","text":"<p>The Order aggregate uses a state machine to ensure valid transitions:</p> <pre><code>class OrderStatus(str, Enum):\n    PENDING = \"pending\"\n    PAYMENT_PROCESSING = \"payment_processing\"\n    PAYMENT_COMPLETED = \"payment_completed\"\n    INVENTORY_RESERVED = \"inventory_reserved\"\n    CONFIRMED = \"confirmed\"\n    CANCELLED = \"cancelled\"\n\n# Valid transitions\ntransitions = {\n    PENDING: [PAYMENT_PROCESSING, CANCELLED],\n    PAYMENT_PROCESSING: [PAYMENT_COMPLETED, CANCELLED],\n    PAYMENT_COMPLETED: [INVENTORY_RESERVED, CANCELLED],\n    INVENTORY_RESERVED: [CONFIRMED, CANCELLED],\n}\n</code></pre>"},{"location":"examples/ecommerce/#2-saga-coordinator","title":"2. Saga Coordinator","text":"<p>The OrderSaga listens to events and coordinates the workflow:</p> <pre><code>class OrderSaga:\n    async def on_order_created(self, event: OrderCreated):\n        # Step 1: Process payment\n        await self.bus.send(ProcessPayment(\n            order_id=event.order_id,\n            amount=event.total_amount,\n            payment_method=\"credit_card\",\n        ))\n\n    async def on_payment_completed(self, event: PaymentCompleted):\n        # Step 2: Reserve inventory\n        await self.bus.send(ReserveInventory(\n            order_id=event.order_id,\n            items=event.items,\n        ))\n\n    async def on_inventory_reserved(self, event: InventoryReserved):\n        # Step 3: Confirm order\n        await self.bus.send(ConfirmOrder(\n            order_id=event.order_id,\n        ))\n\n    async def on_inventory_failed(self, event: InventoryReservationFailed):\n        # Compensation: Refund payment\n        await self.bus.send(RefundPayment(\n            order_id=event.order_id,\n        ))\n</code></pre>"},{"location":"examples/ecommerce/#3-command-handlers","title":"3. Command Handlers","text":"<p>Separate command handlers isolate business logic:</p> <pre><code>async def handle_create_order(\n    command: CreateOrder,\n    repository: AggregateRepository,\n):\n    # Create order aggregate\n    order = Order()\n    order.create(\n        order_id=command.order_id,\n        customer_id=command.customer_id,\n        items=command.items,\n        shipping_address=command.shipping_address,\n    )\n\n    # Save and publish events\n    await repository.save_async(order)\n</code></pre>"},{"location":"examples/ecommerce/#4-compensation","title":"4. Compensation","text":"<p>Saga automatically handles failures with compensation:</p> <pre><code>async def on_payment_failed(self, event: PaymentFailed):\n    # Cancel order\n    await self.bus.send(CancelOrder(\n        order_id=event.order_id,\n        reason=\"Payment failed\",\n    ))\n\nasync def on_inventory_failed(self, event: InventoryReservationFailed):\n    # Step 1: Refund payment\n    await self.bus.send(RefundPayment(\n        order_id=event.order_id,\n    ))\n\n    # Step 2: Release inventory (if partially reserved)\n    await self.bus.send(ReleaseInventory(\n        order_id=event.order_id,\n    ))\n\n    # Step 3: Cancel order\n    await self.bus.send(CancelOrder(\n        order_id=event.order_id,\n        reason=\"Inventory unavailable\",\n    ))\n</code></pre>"},{"location":"examples/ecommerce/#usage-example","title":"Usage Example","text":"<pre><code>import asyncio\nfrom decimal import Decimal\n\nfrom orchestrix.core.eventsourcing.aggregate import AggregateRepository\nfrom orchestrix.infrastructure.memory import InMemoryEventStore, InMemoryMessageBus\n\nfrom examples.ecommerce.aggregate import Order\nfrom examples.ecommerce.handlers import register_handlers\nfrom examples.ecommerce.models import Address, CreateOrder, OrderItem\nfrom examples.ecommerce.saga import register_saga\n\n\nasync def main():\n    # Setup infrastructure\n    event_store = InMemoryEventStore()\n    message_bus = InMemoryMessageBus()\n    repository = AggregateRepository(event_store)\n\n    # Register handlers and saga\n    register_handlers(message_bus, repository)\n    register_saga(message_bus, repository)\n\n    # Create an order\n    order_id = \"order-123\"\n    await message_bus.publish_async(\n        CreateOrder(\n            order_id=order_id,\n            customer_id=\"customer-456\",\n            items=[\n                OrderItem(\n                    product_id=\"laptop-x1\",\n                    quantity=1,\n                    unit_price=Decimal(\"1299.99\"),\n                ),\n                OrderItem(\n                    product_id=\"mouse-m2\",\n                    quantity=2,\n                    unit_price=Decimal(\"29.99\"),\n                ),\n            ],\n            shipping_address=Address(\n                street=\"123 Main St\",\n                city=\"San Francisco\",\n                state=\"CA\",\n                postal_code=\"94102\",\n                country=\"USA\",\n            ),\n        )\n    )\n\n    # Wait for saga to complete\n    await asyncio.sleep(0.5)\n\n    # Load order to check final state\n    order = await repository.load_async(Order, order_id)\n    print(f\"Order Status: {order.status}\")\n    print(f\"Total Amount: ${order.total_amount}\")\n    print(f\"Payment ID: {order.payment_id}\")\n    print(f\"Reservation ID: {order.reservation_id}\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/ecommerce/#testing","title":"Testing","text":""},{"location":"examples/ecommerce/#test-successful-order","title":"Test Successful Order","text":"<pre><code>async def test_successful_order():\n    # Setup\n    event_store = InMemoryEventStore()\n    repository = AggregateRepository(event_store)\n\n    # Create order\n    order = Order()\n    order.create(\n        order_id=\"test-123\",\n        customer_id=\"customer-456\",\n        items=[...],\n        shipping_address=Address(...),\n    )\n\n    await repository.save_async(order)\n\n    # Verify initial state\n    loaded = await repository.load_async(Order, \"test-123\")\n    assert loaded.status == OrderStatus.PENDING\n    assert loaded.customer_id == \"customer-456\"\n</code></pre>"},{"location":"examples/ecommerce/#test-payment-failure","title":"Test Payment Failure","text":"<pre><code>async def test_payment_failure():\n    # Setup with failing payment\n    payment_service = MockPaymentService(should_fail=True)\n\n    # Create order\n    await message_bus.publish_async(CreateOrder(...))\n    await asyncio.sleep(0.1)\n\n    # Verify order was cancelled\n    order = await repository.load_async(Order, order_id)\n    assert order.status == OrderStatus.CANCELLED\n</code></pre>"},{"location":"examples/ecommerce/#test-inventory-failure","title":"Test Inventory Failure","text":"<pre><code>async def test_inventory_failure_compensation():\n    # Setup with insufficient stock\n    inventory_service = MockInventoryService(available_stock=0)\n\n    # Create order\n    await message_bus.publish_async(CreateOrder(...))\n    await asyncio.sleep(0.1)\n\n    # Verify compensation executed\n    order = await repository.load_async(Order, order_id)\n    assert order.status == OrderStatus.CANCELLED\n\n    # Verify payment was refunded\n    assert payment_service.refunded_payments[order_id]\n</code></pre>"},{"location":"examples/ecommerce/#extending-the-example","title":"Extending the Example","text":""},{"location":"examples/ecommerce/#add-payment-gateway-integration","title":"Add Payment Gateway Integration","text":"<pre><code>from payment_gateway import PaymentGateway\n\nclass RealPaymentHandler:\n    def __init__(self, gateway: PaymentGateway):\n        self.gateway = gateway\n\n    async def handle_process_payment(self, command: ProcessPayment):\n        order = await repository.load_async(Order, command.order_id)\n\n        try:\n            result = await self.gateway.charge(\n                amount=command.amount,\n                method=command.payment_method,\n                customer_id=order.customer_id,\n            )\n\n            order.complete_payment(payment_id=result.transaction_id)\n            await repository.save_async(order)\n\n        except PaymentGatewayError as e:\n            order.fail_payment(reason=str(e))\n            await repository.save_async(order)\n</code></pre>"},{"location":"examples/ecommerce/#add-inventory-service","title":"Add Inventory Service","text":"<pre><code>from inventory_service import InventoryClient\n\nclass RealInventoryHandler:\n    def __init__(self, client: InventoryClient):\n        self.client = client\n\n    async def handle_reserve_inventory(self, command: ReserveInventory):\n        order = await repository.load_async(Order, command.order_id)\n\n        try:\n            reservation = await self.client.reserve(\n                items=[(item.product_id, item.quantity) \n                       for item in command.items]\n            )\n\n            order.reserve_inventory(reservation_id=reservation.id)\n            await repository.save_async(order)\n\n        except OutOfStockError as e:\n            order.fail_inventory_reservation(reason=str(e))\n            await repository.save_async(order)\n</code></pre>"},{"location":"examples/ecommerce/#production-considerations","title":"Production Considerations","text":""},{"location":"examples/ecommerce/#1-idempotency","title":"1. Idempotency","text":"<p>Add command deduplication to prevent double-processing:</p> <pre><code>processed_commands = set()\n\nasync def handle_command(command: Command):\n    command_id = f\"{command.type}:{command.order_id}\"\n\n    if command_id in processed_commands:\n        return  # Already processed\n\n    # Process command\n    await process(command)\n\n    processed_commands.add(command_id)\n</code></pre>"},{"location":"examples/ecommerce/#2-timeouts","title":"2. Timeouts","text":"<p>Add saga timeout logic for hanging workflows:</p> <pre><code>class OrderSaga:\n    timeout: timedelta = timedelta(minutes=10)\n\n    async def check_timeouts(self):\n        for order_id, created_at in self.pending_orders.items():\n            if datetime.now() - created_at &gt; self.timeout:\n                await self.cancel_order(order_id, \"Timeout\")\n</code></pre>"},{"location":"examples/ecommerce/#3-monitoring","title":"3. Monitoring","text":"<p>Track saga progress and failure rates:</p> <pre><code>metrics = {\n    \"orders_created\": Counter(),\n    \"orders_confirmed\": Counter(),\n    \"orders_cancelled\": Counter(),\n    \"payment_failures\": Counter(),\n    \"inventory_failures\": Counter(),\n    \"avg_order_duration\": Histogram(),\n}\n</code></pre>"},{"location":"examples/ecommerce/#4-dead-letter-queue","title":"4. Dead Letter Queue","text":"<p>Handle permanent failures:</p> <pre><code>class OrderSaga:\n    dead_letter_queue: list = []\n    max_retries: int = 3\n\n    async def handle_permanent_failure(self, order_id: str, reason: str):\n        self.dead_letter_queue.append({\n            \"order_id\": order_id,\n            \"reason\": reason,\n            \"timestamp\": datetime.now(),\n        })\n\n        # Alert operations team\n        await send_alert(f\"Order {order_id} moved to DLQ: {reason}\")\n</code></pre>"},{"location":"examples/ecommerce/#5-compensation-limits","title":"5. Compensation Limits","text":"<p>Define max retry attempts for compensations:</p> <pre><code>async def compensate_payment(self, order_id: str, attempt: int = 1):\n    if attempt &gt; 3:\n        # Move to manual review\n        await self.escalate_to_manual_review(order_id)\n        return\n\n    try:\n        await self.bus.send(RefundPayment(order_id=order_id))\n    except RefundError:\n        # Retry with exponential backoff\n        await asyncio.sleep(2 ** attempt)\n        await self.compensate_payment(order_id, attempt + 1)\n</code></pre>"},{"location":"examples/ecommerce/#related-examples","title":"Related Examples","text":"<ul> <li>Banking - Saga pattern with money transfers</li> <li>Notifications - Async event handlers</li> <li>Lakehouse GDPR - Event sourcing patterns</li> </ul>"},{"location":"examples/ecommerce/#learn-more","title":"Learn More","text":"<ul> <li>Saga Pattern Guide</li> <li>State Machines</li> <li>Testing Sagas</li> </ul>"},{"location":"examples/ecommerce/#source-code","title":"Source Code","text":"<ul> <li><code>aggregate.py</code> - Order aggregate with state machine</li> <li><code>saga.py</code> - Order saga coordinator</li> <li><code>handlers.py</code> - Command and event handlers</li> <li><code>models.py</code> - Commands, events, and value objects</li> </ul> <p>Browse Complete Example \u2192</p>"},{"location":"examples/lakehouse-gdpr/","title":"GDPR Compliance","text":""},{"location":"examples/lakehouse-gdpr/#lakehouse-fastapi-demo-gdpr-compliance-event-sourcing","title":"Lakehouse FastAPI Demo: GDPR Compliance &amp; Event Sourcing","text":"<p>Dieses Beispiel zeigt eine moderne, GDPR-konforme Lakehouse-Plattform mit Event Sourcing, FastAPI und vollst\u00e4ndigem Audit-Trail.</p> <p>Source: - Demo-Base: bases/orchestrix/lakehouse_fastapi_demo/ - Code: gdpr.py</p>"},{"location":"examples/lakehouse-gdpr/#features-prozesse","title":"Features &amp; Prozesse","text":"<ul> <li>Dataset- und Contract-Registrierung</li> <li>Append-only Ingestion, Replay, Quarantine, Data Quality, Privacy, Publish, Consumption</li> <li>Event Sourcing: Jeder Schritt erzeugt Events, volle Auditierbarkeit</li> <li>GDPR-Deletion mit 30-Tage-Deadline</li> <li>Modular: Aggregates f\u00fcr Dataset, Contract, Batch, Lake</li> <li>FastAPI-Entrypoints f\u00fcr alle Kernprozesse</li> <li>Snapshots f\u00fcr Performance</li> </ul>"},{"location":"examples/lakehouse-gdpr/#end-to-end-api-demo","title":"End-to-End API-Demo","text":""},{"location":"examples/lakehouse-gdpr/#1-server-starten","title":"1. Server starten","text":"<pre><code>uv run main:start\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#2-beispiel-requests","title":"2. Beispiel-Requests","text":"<pre><code># Dataset registrieren\ncurl -X POST http://localhost:8000/datasets \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"sales\", \"schema\": {\"id\": \"int\", \"amount\": \"float\"}}'\n\n# Contract registrieren\ncurl -X POST http://localhost:8000/contracts \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"dataset\": \"sales\", \"retention_days\": 365}'\n\n# Upload-URL holen\ncurl -X POST http://localhost:8000/upload-url \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"filename\": \"sales_2024_01.csv\"}'\n\n# Daten hochladen\necho \"id,amount\\n1,100.0\\n2,200.0\" &gt; sales_2024_01.csv\ncurl -X PUT \"&lt;UPLOAD_URL&gt;\" --data-binary @sales_2024_01.csv\n\n# Batch anh\u00e4ngen\ncurl -X POST http://localhost:8000/append-batch \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"dataset\": \"sales\", \"contract_id\": \"contract1\", \"batch_id\": \"batch1\", \"file_url\": \"sales_2024_01.csv\"}'\n\n# GDPR-Deletion ansto\u00dfen\ncurl -X POST http://localhost:8000/run-privacy \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"batch_id\": \"batch1\", \"privacy_rules\": {\"id\": \"mask\"}}'\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#architektur","title":"Architektur","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   FastAPI    \u2502  REST-API f\u00fcr alle Prozesse\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Aggregates       \u2502  Lake, Dataset, Contract, Batch\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Events    \u2502  Audit, GDPR, Ingestion, DQ, Privacy\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Event Store \u2502  Vollst\u00e4ndiger Audit-Trail\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Snapshots   \u2502  Performance-Optimierung\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#domain-model-auszug","title":"Domain Model (Auszug)","text":"<pre><code>class ComplianceLevel(str, Enum):\n    STANDARD = \"standard\"\n    GDPR = \"gdpr\"\n    STRICT = \"strict\"\n\n@dataclass(frozen=True)\nclass CreateDataLakeCommand(Command):\n    lake_id: str\n    name: str\n    owner_id: str\n    region: str\n    compliance_level: str\n\n@dataclass(frozen=True)\nclass IngestDatasetCommand(Command):\n    lake_id: str\n    dataset_id: str\n    data_source: str\n    record_count: int\n    contains_pii: bool\n\n@dataclass(frozen=True)\nclass RequestGDPRDeletionCommand(Command):\n    lake_id: str\n    subject_id: str\n    reason: str\n    requested_by: str\n\n@dataclass(frozen=True)\nclass AuditAccessCommand(Command):\n    lake_id: str\n    accessor_id: str\n    dataset_id: str\n    action: str\n    purpose: str\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#key-features","title":"Key Features","text":""},{"location":"examples/lakehouse-gdpr/#gdpr-deletion-mit-deadline","title":"GDPR-Deletion mit Deadline","text":"<pre><code>lake.handle_gdpr_deletion(RequestGDPRDeletionCommand(\n    lake_id=\"lake-eu-prod-001\",\n    subject_id=\"customer-42\",\n    reason=\"User requested right to be forgotten\",\n    requested_by=\"support-agent-12\"\n))\n# Deadline automatisch: 30 Tage ab Request\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#pii-tracking-audit","title":"PII-Tracking &amp; Audit","text":"<pre><code>lake.handle_ingest_dataset(IngestDatasetCommand(\n    lake_id=\"lake-eu-prod-001\",\n    dataset_id=\"sales-2024\",\n    data_source=\"salesforce_sync\",\n    record_count=125000,\n    contains_pii=True\n))\n\nlake.handle_audit_access(AuditAccessCommand(\n    lake_id=\"lake-eu-prod-001\",\n    accessor_id=\"analyst-456\",\n    dataset_id=\"sales-2024\",\n    action=\"query\",\n    purpose=\"Q4 revenue analysis\"\n))\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#event-sourcing-snapshots","title":"Event Sourcing &amp; Snapshots","text":"<pre><code>event_store.save(lake_id, lake.uncommitted_events)\nsnapshot = Snapshot(\n    aggregate_id=lake_id,\n    version=len(events),\n    aggregate_type=\"DataLakeAggregate\",\n    state={...}\n)\nevent_store.save_snapshot(snapshot)\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#erweiterbarkeit-storage","title":"Erweiterbarkeit &amp; Storage","text":"<ul> <li>Upload/Download \u00fcber signierte URLs, Storage-Backend austauschbar (Local, S3, Azure, GCS)</li> <li>Alle Logik in bases/, keine Python-Logik in projects/</li> <li>Demo-Architektur: Einfach erweiterbar f\u00fcr neue Compliance- oder Storage-Anforderungen</li> </ul> <p>Hinweis: Die Demo-Base ist modular, prozessgetrieben und f\u00fcr Pr\u00e4sentation/Tests optimiert. Alle Kernprozesse sind als API und Event-Sourcing implementiert. Erweiterungen (z.B. neue Privacy-Strategien, Storage-Backends) sind mit minimalem Aufwand m\u00f6glich.</p> <p>Different rules based on compliance level:</p> <pre><code>def validate_compliance(self, dataset):\n    if self.compliance_level == ComplianceLevel.GDPR:\n        # GDPR requires PII flag\n        if dataset.contains_pii is None:\n            raise ValidationError(\"PII flag required for GDPR\")\n\n    if self.compliance_level == ComplianceLevel.STRICT:\n        # Strict mode: additional validations\n        if not dataset.encryption_enabled:\n            raise ValidationError(\"Encryption required\")\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#4-access-auditing","title":"4. Access Auditing","text":"<p>Every data access logged for compliance:</p> <pre><code>lake.handle_audit_access(AuditAccessCommand(\n    lake_id=\"lake-001\",\n    accessor_id=\"analyst-123\",\n    dataset_id=\"customer-data\",\n    action=\"query\",\n    purpose=\"Marketing campaign analysis\"\n))\n\n# Generate compliance report\nreport = {\n    \"lake\": lake.name,\n    \"compliance\": lake.compliance_level,\n    \"access_events\": len(lake.access_logs),\n    \"pending_deletions\": len([d for d in lake.deletions if d.status == \"pending\"])\n}\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#event-sourcing-benefits","title":"Event Sourcing Benefits","text":""},{"location":"examples/lakehouse-gdpr/#complete-audit-trail","title":"Complete Audit Trail","text":"<p>Every state change recorded as an event:</p> <pre><code>events = event_store.load(\"lake-001\")\n# \u2192 [\n#     DataLakeCreated(timestamp=\"2026-01-01T10:00:00Z\"),\n#     DatasetIngested(timestamp=\"2026-01-01T10:05:00Z\"),\n#     AccessAudited(timestamp=\"2026-01-01T11:00:00Z\"),\n#     GDPRDeletionRequested(timestamp=\"2026-01-01T14:00:00Z\")\n# ]\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#temporal-queries","title":"Temporal Queries","text":"<p>Answer \"what was the state at time X?\":</p> <pre><code># Reconstruct state at specific time\nevents = event_store.load(\"lake-001\", until=datetime(2026, 1, 1))\nlake = DataLakeAggregate.from_events(events)\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#compliance-reporting","title":"Compliance Reporting","text":"<p>Generate reports from event history:</p> <pre><code># Count deletions in last month\ndeletions = [e for e in events \n             if isinstance(e, GDPRDeletionRequested)\n             and e.timestamp &gt; last_month]\n\n# Track access patterns\naccess_by_user = defaultdict(int)\nfor event in events:\n    if isinstance(event, AccessAudited):\n        access_by_user[event.accessor_id] += 1\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#snapshot-optimization","title":"Snapshot Optimization","text":"<p>For large event streams (&gt;100 events):</p> <pre><code># Create snapshot at current state\nsnapshot = Snapshot(\n    aggregate_id=\"lake-001\",\n    version=1000,\n    state={\n        \"name\": lake.name,\n        \"compliance_level\": lake.compliance_level,\n        \"datasets\": lake.datasets,\n        \"deletions\": lake.deletions\n    }\n)\nevent_store.save_snapshot(snapshot)\n\n# Load optimized\nsnapshot = event_store.load_snapshot(\"lake-001\")\nremaining_events = event_store.load(\"lake-001\", from_version=snapshot.version)\nlake = DataLakeAggregate.from_snapshot(snapshot, remaining_events)\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#integration-guide","title":"Integration Guide","text":""},{"location":"examples/lakehouse-gdpr/#1-set-up-infrastructure","title":"1. Set Up Infrastructure","text":"<pre><code>from orchestrix.infrastructure import InMemoryEventStore, InMemoryMessageBus\nfrom orchestrix.core import AggregateRepository\n\n# Create infrastructure\nevent_store = InMemoryEventStore()\nmessage_bus = InMemoryMessageBus()\nrepository = AggregateRepository(event_store)\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#2-register-handlers","title":"2. Register Handlers","text":"<pre><code># Command handlers\n@message_bus.subscribe(CreateDataLakeCommand)\nasync def handle_create_lake(cmd: CreateDataLakeCommand):\n    lake = DataLakeAggregate()\n    lake.handle_create(cmd)\n    await repository.save(lake)\n\n# Event handlers (side effects)\n@message_bus.subscribe(GDPRDeletionRequested)\nasync def notify_deletion_requested(event: GDPRDeletionRequested):\n    # Send notification to ops team\n    await send_email(f\"Deletion requested for {event.subject_id}\")\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#3-process-commands","title":"3. Process Commands","text":"<pre><code># Create lake\nawait message_bus.send(CreateDataLakeCommand(\n    lake_id=\"lake-001\",\n    name=\"EU Customer Analytics\",\n    region=\"eu-west-1\",\n    compliance_level=\"gdpr\"\n))\n\n# Ingest data\nawait message_bus.send(IngestDatasetCommand(\n    lake_id=\"lake-001\",\n    dataset_id=\"customers-2024\",\n    source=\"crm_export\",\n    record_count=100000,\n    contains_pii=True\n))\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#best-practices","title":"Best Practices","text":""},{"location":"examples/lakehouse-gdpr/#do","title":"\u2705 DO","text":"<ul> <li>Always set PII flag when ingesting datasets</li> <li>Validate compliance before processing commands</li> <li>Track deadline status for deletion requests</li> <li>Use snapshots for aggregates with &gt;100 events</li> <li>Emit events for every state change</li> </ul>"},{"location":"examples/lakehouse-gdpr/#dont","title":"\u274c DON'T","text":"<ul> <li>Modify events after creation (immutable!)</li> <li>Skip audit logs even for internal access</li> <li>Hardcode deadlines (calculate from GDPR requirements)</li> <li>Bypass compliance checks in production</li> <li>Store PII in event metadata</li> </ul>"},{"location":"examples/lakehouse-gdpr/#testing","title":"Testing","text":"<pre><code>import pytest\nfrom examples.lakehouse.gdpr import DataLakeAggregate\n\ndef test_gdpr_deletion_sets_deadline():\n    lake = DataLakeAggregate()\n    lake.handle_create(CreateDataLakeCommand(\n        lake_id=\"lake-1\",\n        name=\"Test\",\n        region=\"eu\",\n        compliance_level=\"gdpr\"\n    ))\n\n    lake.handle_gdpr_deletion(RequestGDPRDeletionCommand(\n        lake_id=\"lake-1\",\n        subject_id=\"user-123\",\n        reason=\"GDPR request\",\n        requested_by=\"support\"\n    ))\n\n    # Verify 30-day deadline\n    deletion = lake.deletions[0]\n    assert deletion.status == \"pending\"\n    assert deletion.deadline &gt; datetime.now()\n    assert deletion.deadline &lt;= datetime.now() + timedelta(days=31)\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#production-considerations","title":"Production Considerations","text":""},{"location":"examples/lakehouse-gdpr/#event-store","title":"Event Store","text":"<p>Use persistent event store in production:</p> <pre><code>from orchestrix.infrastructure import PostgresEventStore\n\nevent_store = PostgresEventStore(\n    connection_string=\"postgresql://...\",\n    schema=\"events\"\n)\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#deadline-monitoring","title":"Deadline Monitoring","text":"<p>Schedule jobs to process deletions:</p> <pre><code># Daily job to check deadlines\nasync def check_deletion_deadlines():\n    pending = await query_pending_deletions()\n    for deletion in pending:\n        if deletion.deadline &lt; datetime.now():\n            await process_deletion(deletion)\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#compliance-reports","title":"Compliance Reports","text":"<p>Generate regular reports:</p> <pre><code>async def generate_monthly_report():\n    events = await event_store.load_all()\n    report = {\n        \"deletions_completed\": count_completed_deletions(events),\n        \"average_completion_time\": calculate_avg_time(events),\n        \"access_by_dataset\": group_access_by_dataset(events)\n    }\n    await send_to_compliance_team(report)\n</code></pre>"},{"location":"examples/lakehouse-gdpr/#related-examples","title":"Related Examples","text":"<ul> <li>Data Anonymization - Anonymize PII in datasets (see <code>bases/orchestrix/lakehouse/main.py</code>)</li> <li>E-Commerce - Order processing with sagas (see <code>bases/orchestrix/ecommerce/</code>)</li> <li>Banking - Account management basics (see <code>bases/orchestrix/banking/</code>)</li> </ul>"},{"location":"examples/lakehouse-gdpr/#learn-more","title":"Learn More","text":"<ul> <li>Event Sourcing Guide</li> <li>Aggregate Pattern</li> <li>Testing Strategies</li> </ul>"},{"location":"examples/lakehouse-gdpr/#source-code","title":"Source Code","text":"<p>Explore the complete implementation on GitHub:</p> <ul> <li><code>gdpr_simple.py</code> - Simple runnable demo (90 lines)</li> <li><code>gdpr.py</code> - Full implementation with aggregates (400 lines)</li> <li><code>models.py</code> - Domain model (Commands, Events, Enums)</li> <li><code>aggregate.py</code> - Business logic and state management</li> <li><code>example.py</code> - Data anonymization example</li> </ul> <p>Complete Lakehouse Examples: Browse on GitHub</p>"},{"location":"examples/metrics/","title":"Prometheus Metrics","text":"<p>Production-grade metrics collection for monitoring and alerting.</p>"},{"location":"examples/metrics/#overview","title":"Overview","text":"<p>Orchestrix automatically collects metrics for message throughput, handler latency, event store performance, and more using Prometheus.</p>"},{"location":"examples/metrics/#key-features","title":"Key Features","text":"<ul> <li>Automatic Collection - No manual instrumentation needed</li> <li>Rich Metrics - Throughput, latency, errors, event store ops</li> <li>Standard Format - Prometheus-compatible format</li> <li>Low Overhead - Minimal performance impact</li> </ul>"},{"location":"examples/metrics/#basic-example","title":"Basic Example","text":"<pre><code>from orchestrix.infrastructure.prometheus_metrics import init_metrics, MetricsConfig\nfrom orchestrix.infrastructure import InMemoryMessageBus\nfrom orchestrix.core.messaging.message import Command, Event\nfrom dataclasses import dataclass\nimport time\n\n# Initialize metrics\ninit_metrics(\n    MetricsConfig(\n        port=8000,\n        path=\"/metrics\",\n        enable_default_metrics=True\n    )\n)\n\n@dataclass(frozen=True)\nclass ProcessOrder(Command):\n    order_id: str\n\n@dataclass(frozen=True)\nclass OrderProcessed(Event):\n    order_id: str\n\n# Setup\nbus = InMemoryMessageBus()\n\ndef handle_process_order(cmd: ProcessOrder):\n    # Simulate work\n    time.sleep(0.1)\n    bus.publish(OrderProcessed(order_id=cmd.order_id))\n\ndef handle_order_processed(event: OrderProcessed):\n    print(f\"Order processed: {event.order_id}\")\n\nbus.subscribe(ProcessOrder, handle_process_order)\nbus.subscribe(OrderProcessed, handle_order_processed)\n\n# Process orders - metrics collected automatically\nfor i in range(100):\n    bus.publish(ProcessOrder(order_id=f\"ORD-{i:03d}\"))\n</code></pre>"},{"location":"examples/metrics/#running-the-example","title":"Running the Example","text":"<pre><code>cd examples/prometheus\nuv run example.py\n</code></pre> <p>Open http://localhost:8000/metrics to view metrics.</p>"},{"location":"examples/metrics/#available-metrics","title":"Available Metrics","text":""},{"location":"examples/metrics/#message-throughput","title":"Message Throughput","text":"<pre><code># HELP orchestrix_messages_total Total messages published\n# TYPE orchestrix_messages_total counter\norchestrix_messages_total{type=\"command\",name=\"ProcessOrder\"} 100\norchestrix_messages_total{type=\"event\",name=\"OrderProcessed\"} 100\n\n# HELP orchestrix_messages_per_second Messages published per second\n# TYPE orchestrix_messages_per_second gauge\norchestrix_messages_per_second 45.2\n</code></pre>"},{"location":"examples/metrics/#handler-latency","title":"Handler Latency","text":"<pre><code># HELP orchestrix_handler_duration_seconds Handler execution time\n# TYPE orchestrix_handler_duration_seconds histogram\norchestrix_handler_duration_seconds_bucket{handler=\"handle_process_order\",le=\"0.1\"} 95\norchestrix_handler_duration_seconds_bucket{handler=\"handle_process_order\",le=\"0.5\"} 100\norchestrix_handler_duration_seconds_sum{handler=\"handle_process_order\"} 10.234\norchestrix_handler_duration_seconds_count{handler=\"handle_process_order\"} 100\n</code></pre>"},{"location":"examples/metrics/#event-store-performance","title":"Event Store Performance","text":"<pre><code># HELP orchestrix_store_operations_total Event store operations\n# TYPE orchestrix_store_operations_total counter\norchestrix_store_operations_total{operation=\"save\",store=\"postgres\"} 1000\norchestrix_store_operations_total{operation=\"load\",store=\"postgres\"} 500\n\n# HELP orchestrix_store_duration_seconds Event store operation duration\n# TYPE orchestrix_store_duration_seconds histogram\norchestrix_store_duration_seconds_sum{operation=\"save\"} 5.432\norchestrix_store_duration_seconds_count{operation=\"save\"} 1000\n</code></pre>"},{"location":"examples/metrics/#error-rates","title":"Error Rates","text":"<pre><code># HELP orchestrix_errors_total Total errors\n# TYPE orchestrix_errors_total counter\norchestrix_errors_total{type=\"handler_error\",handler=\"handle_order\"} 3\norchestrix_errors_total{type=\"concurrency_error\",aggregate=\"order\"} 2\n</code></pre>"},{"location":"examples/metrics/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Import the included Grafana dashboard for visualization:</p> <pre><code># Located at: examples/prometheus/grafana_dashboard.json\n</code></pre> <p>Dashboard includes: - Message throughput over time - Handler latency percentiles (p50, p95, p99) - Error rates by type - Event store performance - Active handlers</p>"},{"location":"examples/metrics/#alerting-rules","title":"Alerting Rules","text":"<p>Example Prometheus alerting rules:</p> <pre><code>groups:\n  - name: orchestrix\n    rules:\n      - alert: HighErrorRate\n        expr: rate(orchestrix_errors_total[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High error rate detected\"\n\n      - alert: SlowHandlers\n        expr: histogram_quantile(0.95, orchestrix_handler_duration_seconds) &gt; 1.0\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Handler latency p95 &gt; 1s\"\n</code></pre>"},{"location":"examples/metrics/#configuration","title":"Configuration","text":"<pre><code>MetricsConfig(\n    port=8000,                          # Metrics endpoint port\n    path=\"/metrics\",                    # Metrics path\n    enable_default_metrics=True,        # Include Python runtime metrics\n    histogram_buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]  # Latency buckets\n)\n</code></pre>"},{"location":"examples/metrics/#best-practices","title":"Best Practices","text":"<ol> <li>Labels - Use cardinality-limited labels (avoid unique IDs)</li> <li>Histograms - Choose appropriate buckets for latency</li> <li>Alerts - Set up alerting for critical metrics</li> <li>Dashboards - Create service-specific dashboards</li> </ol>"},{"location":"examples/metrics/#integration","title":"Integration","text":""},{"location":"examples/metrics/#docker-compose","title":"Docker Compose","text":"<pre><code>services:\n  orchestrix-app:\n    build: .\n    ports:\n      - \"8000:8000\"  # Metrics endpoint\n\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n\n  grafana:\n    image: grafana/grafana:latest\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n</code></pre>"},{"location":"examples/metrics/#prometheus-config","title":"Prometheus Config","text":"<pre><code># prometheus.yml\nscrape_configs:\n  - job_name: 'orchestrix'\n    static_configs:\n      - targets: ['orchestrix-app:8000']\n    scrape_interval: 5s\n</code></pre>"},{"location":"examples/metrics/#learn-more","title":"Learn More","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Dashboards</li> <li>Full Example</li> <li>API Reference</li> </ul>"},{"location":"examples/notifications/","title":"Notifications: Retry Logic and Dead Letter Queue","text":"<p>This example demonstrates async event handlers with robust error handling, retry logic with exponential backoff, and the dead letter queue pattern.</p> <p>\ud83d\udcc2 Source Code: Complete Example: <code>examples/notifications/</code> Main Demo: <code>examples/notifications/example.py</code> Domain Models: <code>examples/notifications/models.py</code></p>"},{"location":"examples/notifications/#overview","title":"Overview","text":"<p>The notifications example demonstrates:</p> <ul> <li>\u2705 Retry Logic - Exponential backoff for transient failures</li> <li>\u2705 Dead Letter Queue - Handle permanent failures</li> <li>\u2705 Multiple Channels - Email, SMS, Push, Webhooks</li> <li>\u2705 Circuit Breaker - Protect against cascading failures</li> <li>\u2705 Async Event Handlers - Non-blocking notification processing</li> </ul>"},{"location":"examples/notifications/#quick-start","title":"Quick Start","text":"<pre><code># Run the notifications example\nuv run python -m examples.notifications.example\n</code></pre>"},{"location":"examples/notifications/#architecture","title":"Architecture","text":"<p>Notification flow with automatic retry and DLQ:</p> <pre><code>Domain Event (UserRegistered, OrderPlaced, PaymentReceived)\n    \u2193\nEvent Handler \u2192 NotificationRequested\n    \u2193\nSendNotification Command\n    \u2193\nNotification Service (can fail)\n    \u2193\n    \u251c\u2500 Success \u2192 NotificationSent \u2705\n    \u251c\u2500 Transient Failure \u2192 Retry (exponential backoff) \ud83d\udd04\n    \u2514\u2500 Max Retries Exceeded \u2192 NotificationMovedToDeadLetter \u274c\n</code></pre>"},{"location":"examples/notifications/#retry-strategy","title":"Retry Strategy","text":"<p>Exponential backoff with configurable parameters:</p> <pre><code>@dataclass\nclass RetryConfig:\n    max_attempts: int = 3\n    initial_delay: float = 1.0  # seconds\n    backoff_multiplier: float = 2.0\n    max_delay: float = 60.0  # seconds\n\n# Retry schedule:\n# Attempt 1: Immediate\n# Attempt 2: 1.0 second delay\n# Attempt 3: 2.0 seconds delay\n# Attempt 4: 4.0 seconds delay (if max_attempts=4)\n</code></pre>"},{"location":"examples/notifications/#dead-letter-queue","title":"Dead Letter Queue","text":"<p>Failed notifications after max retries are moved to DLQ for:</p> <ul> <li>\ud83d\udd0d Manual Investigation - Review failure reasons</li> <li>\ud83d\udea8 Alert Admins - Notify operations team</li> <li>\ud83d\udd04 Manual Retry - Retry with intervention</li> <li>\ud83d\udcca Audit Trail - Track all failures</li> </ul>"},{"location":"examples/notifications/#domain-model","title":"Domain Model","text":""},{"location":"examples/notifications/#commands","title":"Commands","text":""},{"location":"examples/notifications/#sendnotification","title":"SendNotification","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass SendNotification(Command):\n    notification_id: str\n    channel: NotificationChannel  # EMAIL, SMS, PUSH, WEBHOOK\n    recipient: str\n    subject: Optional[str] = None\n    message: str\n    metadata: dict = field(default_factory=dict)\n\nclass NotificationChannel(str, Enum):\n    EMAIL = \"email\"\n    SMS = \"sms\"\n    PUSH = \"push\"\n    WEBHOOK = \"webhook\"\n</code></pre>"},{"location":"examples/notifications/#events","title":"Events","text":"<p>Domain Events (trigger notifications): - <code>UserRegistered</code> - Welcome email - <code>OrderPlaced</code> - Order confirmation - <code>OrderShipped</code> - Shipping notification - <code>PaymentReceived</code> - Payment receipt</p> <p>Notification Events: - <code>NotificationRequested</code> - Notification triggered - <code>NotificationSent</code> - Successfully delivered - <code>NotificationFailed</code> - Delivery failed (with retry info) - <code>NotificationMovedToDeadLetter</code> - Max retries exceeded</p>"},{"location":"examples/notifications/#key-patterns","title":"Key Patterns","text":""},{"location":"examples/notifications/#1-retry-with-exponential-backoff","title":"1. Retry with Exponential Backoff","text":"<p>Automatic retry with increasing delays to handle transient failures:</p> <pre><code>class NotificationHandler:\n    def __init__(self, config: RetryConfig):\n        self.config = config\n        self.retry_attempts = {}\n\n    async def send_notification(self, command: SendNotification):\n        notification_id = command.notification_id\n        attempt = self.retry_attempts.get(notification_id, 1)\n\n        try:\n            # Attempt to send\n            await self.service.send(command)\n\n            # Success - clear retry tracking\n            self.retry_attempts.pop(notification_id, None)\n\n        except TransientError as e:\n            # Retry with backoff\n            if attempt &lt; self.config.max_attempts:\n                delay = self.calculate_delay(attempt)\n                await asyncio.sleep(delay)\n\n                self.retry_attempts[notification_id] = attempt + 1\n                await self.send_notification(command)  # Retry\n            else:\n                # Max retries exceeded - move to DLQ\n                await self.move_to_dlq(notification_id, str(e))\n\n    def calculate_delay(self, attempt: int) -&gt; float:\n        delay = self.config.initial_delay * (\n            self.config.backoff_multiplier ** (attempt - 1)\n        )\n        return min(delay, self.config.max_delay)\n</code></pre>"},{"location":"examples/notifications/#2-dead-letter-queue","title":"2. Dead Letter Queue","text":"<p>Store failed messages for manual intervention:</p> <pre><code>@dataclass\nclass DeadLetterMessage:\n    notification_id: str\n    command: SendNotification\n    failure_reason: str\n    attempts: int\n    first_failure: datetime\n    last_failure: datetime\n\nclass NotificationHandler:\n    dead_letter_queue: list[DeadLetterMessage] = []\n\n    async def move_to_dlq(\n        self,\n        notification_id: str,\n        reason: str,\n    ):\n        message = DeadLetterMessage(\n            notification_id=notification_id,\n            command=self.pending[notification_id],\n            failure_reason=reason,\n            attempts=self.retry_attempts[notification_id],\n            first_failure=self.first_attempts[notification_id],\n            last_failure=datetime.now(),\n        )\n\n        self.dead_letter_queue.append(message)\n\n        # Alert admins\n        await self.send_admin_alert(\n            f\"Notification {notification_id} moved to DLQ: {reason}\"\n        )\n\n        # Log for investigation\n        logger.error(\n            f\"DLQ: {notification_id} failed after \"\n            f\"{message.attempts} attempts\"\n        )\n</code></pre>"},{"location":"examples/notifications/#3-async-event-handlers","title":"3. Async Event Handlers","text":"<p>Multiple handlers can process the same event:</p> <pre><code># Handler 1: Send email notification\n@message_bus.subscribe(OrderPlaced)\nasync def send_email_notification(event: OrderPlaced):\n    await message_bus.send(SendNotification(\n        notification_id=f\"email-{event.order_id}\",\n        channel=NotificationChannel.EMAIL,\n        recipient=event.customer_email,\n        subject=f\"Order Confirmation: {event.order_id}\",\n        message=f\"Your order has been placed...\",\n    ))\n\n# Handler 2: Send SMS notification\n@message_bus.subscribe(OrderPlaced)\nasync def send_sms_notification(event: OrderPlaced):\n    await message_bus.send(SendNotification(\n        notification_id=f\"sms-{event.order_id}\",\n        channel=NotificationChannel.SMS,\n        recipient=event.customer_phone,\n        message=f\"Order {event.order_id} confirmed!\",\n    ))\n\n# Handler 3: Update metrics\n@message_bus.subscribe(OrderPlaced)\nasync def update_metrics(event: OrderPlaced):\n    metrics[\"orders_placed\"].inc()\n</code></pre>"},{"location":"examples/notifications/#4-circuit-breaker","title":"4. Circuit Breaker","text":"<p>Prevent cascading failures when notification service is down:</p> <pre><code>@dataclass\nclass CircuitBreaker:\n    failure_threshold: int = 5\n    timeout: float = 60.0  # seconds\n    state: str = \"closed\"  # closed, open, half-open\n    failure_count: int = 0\n    last_failure: Optional[datetime] = None\n\n    async def call(self, func, *args, **kwargs):\n        if self.state == \"open\":\n            if self.should_attempt_reset():\n                self.state = \"half-open\"\n            else:\n                raise ServiceUnavailable(\"Circuit breaker is open\")\n\n        try:\n            result = await func(*args, **kwargs)\n            self.on_success()\n            return result\n        except Exception as e:\n            self.on_failure()\n            raise\n\n    def on_success(self):\n        self.failure_count = 0\n        self.state = \"closed\"\n\n    def on_failure(self):\n        self.failure_count += 1\n        self.last_failure = datetime.now()\n\n        if self.failure_count &gt;= self.failure_threshold:\n            self.state = \"open\"\n\n    def should_attempt_reset(self) -&gt; bool:\n        if self.last_failure is None:\n            return False\n\n        elapsed = (datetime.now() - self.last_failure).total_seconds()\n        return elapsed &gt;= self.timeout\n</code></pre>"},{"location":"examples/notifications/#usage-example","title":"Usage Example","text":"<pre><code>import asyncio\nfrom datetime import datetime, timezone\n\nfrom orchestrix.infrastructure.memory import InMemoryMessageBus\n\nfrom examples.notifications.handlers import (\n    NotificationService,\n    RetryConfig,\n    register_handlers,\n)\nfrom examples.notifications.models import UserRegistered\n\n\nasync def main():\n    # Setup\n    message_bus = InMemoryMessageBus()\n\n    # Simulate unreliable service (30% failure rate)\n    notification_service = NotificationService(failure_rate=0.3)\n\n    # Configure retry behavior\n    retry_config = RetryConfig(\n        max_attempts=3,\n        initial_delay=1.0,\n        backoff_multiplier=2.0,\n        max_delay=60.0,\n    )\n\n    # Register handlers\n    handler = register_handlers(\n        message_bus,\n        notification_service,\n        retry_config\n    )\n\n    # Trigger notification\n    await message_bus.publish_async(\n        UserRegistered(\n            user_id=\"user-123\",\n            email=\"alice@example.com\",\n            name=\"Alice\",\n            registered_at=datetime.now(timezone.utc),\n        )\n    )\n\n    # Wait for retries to complete\n    await asyncio.sleep(5)\n\n    # Check results\n    print(f\"Sent: {len(handler.sent_notifications)}\")\n    print(f\"Failed (in DLQ): {len(handler.dead_letter_queue)}\")\n\n    # Process dead letter queue\n    for dlq_message in handler.dead_letter_queue:\n        print(f\"DLQ: {dlq_message.notification_id}\")\n        print(f\"  Reason: {dlq_message.failure_reason}\")\n        print(f\"  Attempts: {dlq_message.attempts}\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/notifications/#notification-channels","title":"Notification Channels","text":""},{"location":"examples/notifications/#email","title":"Email","text":"<pre><code>await send_notification(\n    channel=NotificationChannel.EMAIL,\n    recipient=\"user@example.com\",\n    subject=\"Welcome to Our Platform!\",\n    message=\"&lt;html&gt;&lt;body&gt;Welcome Alice...&lt;/body&gt;&lt;/html&gt;\",\n    metadata={\"template\": \"welcome\", \"lang\": \"en\"},\n)\n</code></pre>"},{"location":"examples/notifications/#sms","title":"SMS","text":"<pre><code>await send_notification(\n    channel=NotificationChannel.SMS,\n    recipient=\"+1234567890\",\n    message=\"Your verification code is: 123456\",\n    metadata={\"country_code\": \"US\"},\n)\n</code></pre>"},{"location":"examples/notifications/#push-notifications","title":"Push Notifications","text":"<pre><code>await send_notification(\n    channel=NotificationChannel.PUSH,\n    recipient=\"device-token-abc123\",\n    message=\"You have a new message!\",\n    metadata={\n        \"badge\": 1,\n        \"sound\": \"default\",\n        \"deep_link\": \"/messages/123\",\n    },\n)\n</code></pre>"},{"location":"examples/notifications/#webhooks","title":"Webhooks","text":"<pre><code>await send_notification(\n    channel=NotificationChannel.WEBHOOK,\n    recipient=\"https://api.partner.com/webhook\",\n    message=json.dumps({\"event\": \"order.placed\", \"order_id\": \"123\"}),\n    metadata={\"signature\": \"hmac-sha256...\"},\n)\n</code></pre>"},{"location":"examples/notifications/#testing","title":"Testing","text":""},{"location":"examples/notifications/#test-retry-logic","title":"Test Retry Logic","text":"<pre><code>async def test_retry_with_eventual_success():\n    # Setup service that fails first 2 attempts, succeeds on 3rd\n    service = NotificationService(fail_count=2)\n    config = RetryConfig(max_attempts=3, initial_delay=0.1)\n    handler = NotificationHandler(service, config)\n\n    # Send notification\n    await handler.send_notification(SendNotification(\n        notification_id=\"test-1\",\n        channel=NotificationChannel.EMAIL,\n        recipient=\"test@example.com\",\n        message=\"Test\",\n    ))\n\n    # Wait for retries\n    await asyncio.sleep(0.5)\n\n    # Verify succeeded on 3rd attempt\n    assert len(handler.sent_notifications) == 1\n    assert len(handler.dead_letter_queue) == 0\n</code></pre>"},{"location":"examples/notifications/#test-dead-letter-queue","title":"Test Dead Letter Queue","text":"<pre><code>async def test_move_to_dlq_after_max_retries():\n    # Setup service that always fails\n    service = NotificationService(failure_rate=1.0)\n    config = RetryConfig(max_attempts=3, initial_delay=0.1)\n    handler = NotificationHandler(service, config)\n\n    # Send notification\n    await handler.send_notification(SendNotification(\n        notification_id=\"test-1\",\n        channel=NotificationChannel.EMAIL,\n        recipient=\"test@example.com\",\n        message=\"Test\",\n    ))\n\n    # Wait for retries\n    await asyncio.sleep(1.0)\n\n    # Verify moved to DLQ after 3 attempts\n    assert len(handler.sent_notifications) == 0\n    assert len(handler.dead_letter_queue) == 1\n    assert handler.dead_letter_queue[0].attempts == 3\n</code></pre>"},{"location":"examples/notifications/#test-exponential-backoff","title":"Test Exponential Backoff","text":"<pre><code>async def test_exponential_backoff_timing():\n    config = RetryConfig(\n        initial_delay=1.0,\n        backoff_multiplier=2.0,\n        max_delay=60.0,\n    )\n    handler = NotificationHandler(None, config)\n\n    # Verify delay calculations\n    assert handler.calculate_delay(1) == 1.0   # 1.0 * 2^0\n    assert handler.calculate_delay(2) == 2.0   # 1.0 * 2^1\n    assert handler.calculate_delay(3) == 4.0   # 1.0 * 2^2\n    assert handler.calculate_delay(4) == 8.0   # 1.0 * 2^3\n    assert handler.calculate_delay(10) == 60.0 # Capped at max_delay\n</code></pre>"},{"location":"examples/notifications/#production-considerations","title":"Production Considerations","text":""},{"location":"examples/notifications/#1-rate-limiting","title":"1. Rate Limiting","text":"<p>Prevent notification spam:</p> <pre><code>@dataclass\nclass RateLimiter:\n    max_per_minute: int = 100\n    window: dict = field(default_factory=dict)\n\n    async def check_limit(self, user_id: str) -&gt; bool:\n        now = datetime.now()\n        minute_key = now.replace(second=0, microsecond=0)\n\n        if minute_key not in self.window:\n            self.window = {minute_key: {}}\n\n        count = self.window[minute_key].get(user_id, 0)\n\n        if count &gt;= self.max_per_minute:\n            return False  # Rate limit exceeded\n\n        self.window[minute_key][user_id] = count + 1\n        return True\n</code></pre>"},{"location":"examples/notifications/#2-idempotency","title":"2. Idempotency","text":"<p>Prevent duplicate sends:</p> <pre><code>sent_notifications = set()\n\nasync def send_notification(command: SendNotification):\n    if command.notification_id in sent_notifications:\n        return  # Already sent\n\n    await notification_service.send(command)\n    sent_notifications.add(command.notification_id)\n</code></pre>"},{"location":"examples/notifications/#3-user-preferences","title":"3. User Preferences","text":"<p>Respect notification settings:</p> <pre><code>preferences = await get_user_preferences(user_id)\n\nif not preferences.email_enabled:\n    return  # User disabled email notifications\n\nif preferences.quiet_hours:\n    if is_quiet_hour(datetime.now()):\n        await schedule_for_later(notification)\n        return\n</code></pre>"},{"location":"examples/notifications/#4-monitoring","title":"4. Monitoring","text":"<p>Track notification health:</p> <pre><code>metrics = {\n    \"notifications_sent\": Counter(),\n    \"notifications_failed\": Counter(),\n    \"notifications_in_dlq\": Gauge(),\n    \"retry_attempts\": Histogram(),\n    \"delivery_time\": Histogram(),\n}\n\n# Usage\nwith metrics[\"delivery_time\"].time():\n    await send_notification(command)\n\nmetrics[\"notifications_sent\"].inc()\n</code></pre>"},{"location":"examples/notifications/#5-template-management","title":"5. Template Management","text":"<p>Centralize message templates:</p> <pre><code>templates = {\n    \"welcome\": {\n        \"subject\": \"Welcome to {platform}!\",\n        \"body\": \"Hello {name}, thank you for joining...\",\n    },\n    \"order_confirm\": {\n        \"subject\": \"Order #{order_id} Confirmed\",\n        \"body\": \"Your order has been placed...\",\n    },\n}\n\nmessage = templates[\"welcome\"][\"body\"].format(\n    name=user.name,\n    platform=\"MyApp\",\n)\n</code></pre>"},{"location":"examples/notifications/#related-examples","title":"Related Examples","text":"<ul> <li>E-Commerce - Trigger notifications from order events</li> <li>Banking - Send transaction notifications</li> <li>Lakehouse GDPR - Compliance notifications</li> </ul>"},{"location":"examples/notifications/#learn-more","title":"Learn More","text":"<ul> <li>Async Handlers Guide</li> <li>Error Handling</li> <li>Testing Async Code</li> </ul>"},{"location":"examples/notifications/#source-code","title":"Source Code","text":"<ul> <li><code>handlers.py</code> - Retry logic and DLQ implementation</li> <li><code>models.py</code> - Commands and events</li> <li><code>example.py</code> - Complete demo</li> </ul> <p>Browse Complete Example \u2192</p>"},{"location":"examples/projections/","title":"Projections - Building Read Models","text":"<p>Projections transform event streams into optimized read models for queries.</p>"},{"location":"examples/projections/#overview","title":"Overview","text":"<p>Projections listen to events and build denormalized views optimized for specific queries. This separates write models (aggregates) from read models (projections).</p>"},{"location":"examples/projections/#key-features","title":"Key Features","text":"<ul> <li>Multiple Backends - InMemory, PostgreSQL, custom</li> <li>Automatic Updates - React to events automatically</li> <li>Query Optimization - Denormalized for fast reads</li> <li>Rebuild Support - Replay events to rebuild projections</li> </ul>"},{"location":"examples/projections/#basic-example","title":"Basic Example","text":"<pre><code>from orchestrix.core.eventsourcing.projection import Projection, ProjectionEngine\nfrom orchestrix.infrastructure import InMemoryMessageBus\nfrom dataclasses import dataclass\n\n@dataclass(frozen=True)\nclass OrderCreated(Event):\n    order_id: str\n    customer_name: str\n    total_amount: float\n\n@dataclass(frozen=True)\nclass OrderShipped(Event):\n    order_id: str\n    tracking_number: str\n\nclass OrderSummaryProjection(Projection):\n    \"\"\"Read model for order summaries.\"\"\"\n\n    def __init__(self):\n        self.orders = {}\n\n    async def project(self, event: Event):\n        if isinstance(event, OrderCreated):\n            self.orders[event.order_id] = {\n                'customer': event.customer_name,\n                'total': event.total_amount,\n                'status': 'created'\n            }\n        elif isinstance(event, OrderShipped):\n            if event.order_id in self.orders:\n                self.orders[event.order_id]['status'] = 'shipped'\n                self.orders[event.order_id]['tracking'] = event.tracking_number\n\n    def get_order(self, order_id: str):\n        return self.orders.get(order_id)\n\n    def get_all_orders(self):\n        return list(self.orders.values())\n\n# Setup\nbus = InMemoryMessageBus()\nengine = ProjectionEngine()\nprojection = OrderSummaryProjection()\n\n# Register\nengine.register_projection(projection, [OrderCreated, OrderShipped])\nengine.start(bus)\n\n# Query\nsummary = projection.get_order(\"ORD-001\")\nall_orders = projection.get_all_orders()\n</code></pre>"},{"location":"examples/projections/#postgresql-backend","title":"PostgreSQL Backend","text":"<pre><code>from orchestrix.core.eventsourcing.projection import PostgreSQLProjectionStore\n\nclass OrderProjection(Projection):\n    def __init__(self, store: PostgreSQLProjectionStore):\n        self.store = store\n\n    async def project(self, event: Event):\n        if isinstance(event, OrderCreated):\n            await self.store.execute(\n                \"\"\"\n                INSERT INTO order_summary (order_id, customer, total, status)\n                VALUES ($1, $2, $3, $4)\n                ON CONFLICT (order_id) DO UPDATE\n                SET customer = $2, total = $3, status = $4\n                \"\"\",\n                event.order_id,\n                event.customer_name,\n                event.total_amount,\n                'created'\n            )\n</code></pre>"},{"location":"examples/projections/#running-the-example","title":"Running the Example","text":"<pre><code>cd examples/projections\nuv run example.py\n</code></pre>"},{"location":"examples/projections/#use-cases","title":"Use Cases","text":"<ul> <li>Dashboard Views - Real-time business metrics</li> <li>Search Indexes - Optimized for full-text search</li> <li>Reporting - Analytics and reports</li> <li>Customer Views - Personalized customer portals</li> </ul>"},{"location":"examples/projections/#best-practices","title":"Best Practices","text":"<ol> <li>Idempotency - Handle duplicate events gracefully</li> <li>Versioning - Support projection schema evolution</li> <li>Rebuild Strategy - Plan for rebuilding projections</li> <li>Performance - Index frequently queried fields</li> </ol>"},{"location":"examples/projections/#learn-more","title":"Learn More","text":"<ul> <li>Best Practices</li> <li>Full Example</li> <li>API Reference</li> </ul>"},{"location":"examples/sagas/","title":"Sagas - Long-Running Business Processes","text":"<p>Sagas coordinate long-running business processes across multiple aggregates with automatic compensation on failure.</p>"},{"location":"examples/sagas/#overview","title":"Overview","text":"<p>A saga is a sequence of local transactions where each transaction updates data within a single service. If a step fails, the saga executes compensating transactions to undo the changes made by previous steps.</p>"},{"location":"examples/sagas/#key-features","title":"Key Features","text":"<ul> <li>Compensation Logic - Automatic rollback on failure</li> <li>State Management - Tracks saga progress</li> <li>Event-Driven - Reacts to domain events</li> <li>Type-Safe - Full type annotations</li> </ul>"},{"location":"examples/sagas/#basic-example","title":"Basic Example","text":"<pre><code>from orchestrix.core.execution.saga import Saga, SagaStep\nfrom orchestrix.core.messaging.message import Event\nfrom dataclasses import dataclass\n\n@dataclass(frozen=True)\nclass OrderCreated(Event):\n    order_id: str\n    amount: float\n\n@dataclass(frozen=True)\nclass PaymentProcessed(Event):\n    order_id: str\n    payment_id: str\n\n@dataclass(frozen=True)\nclass InventoryReserved(Event):\n    order_id: str\n    items: list[str]\n\n# Define saga\nclass OrderSaga(Saga):\n    def __init__(self):\n        super().__init__()\n        self.add_step(\n            SagaStep(\n                action=self.process_payment,\n                compensation=self.refund_payment\n            )\n        )\n        self.add_step(\n            SagaStep(\n                action=self.reserve_inventory,\n                compensation=self.release_inventory\n            )\n        )\n\n    async def process_payment(self, order: OrderCreated):\n        # Process payment\n        return PaymentProcessed(\n            order_id=order.order_id,\n            payment_id=\"pay-123\"\n        )\n\n    async def refund_payment(self, payment: PaymentProcessed):\n        # Refund on failure\n        pass\n\n    async def reserve_inventory(self, payment: PaymentProcessed):\n        # Reserve inventory\n        return InventoryReserved(\n            order_id=payment.order_id,\n            items=[\"item-1\", \"item-2\"]\n        )\n\n    async def release_inventory(self, inventory: InventoryReserved):\n        # Release on failure\n        pass\n</code></pre>"},{"location":"examples/sagas/#running-the-example","title":"Running the Example","text":"<pre><code>cd examples/sagas\nuv run example.py\n</code></pre>"},{"location":"examples/sagas/#use-cases","title":"Use Cases","text":"<ul> <li>Distributed Transactions - Coordinate changes across multiple aggregates</li> <li>Order Processing - Payment, inventory, shipping coordination</li> <li>Travel Booking - Flight + hotel + car rental</li> <li>Account Transfers - Debit one account, credit another</li> </ul>"},{"location":"examples/sagas/#best-practices","title":"Best Practices","text":"<ol> <li>Idempotency - Saga steps should be idempotent</li> <li>Compensation Order - Reverse order of execution</li> <li>State Persistence - Store saga state for recovery</li> <li>Timeout Handling - Handle long-running operations</li> </ol>"},{"location":"examples/sagas/#learn-more","title":"Learn More","text":"<ul> <li>Best Practices</li> <li>Full Example</li> <li>API Reference</li> </ul>"},{"location":"examples/tracing/","title":"Distributed Tracing with OpenTelemetry","text":"<p>Distributed tracing provides end-to-end visibility into message flows across services.</p>"},{"location":"examples/tracing/#overview","title":"Overview","text":"<p>Orchestrix integrates with OpenTelemetry to automatically create spans for command/event handling, providing distributed tracing across your event-driven architecture.</p>"},{"location":"examples/tracing/#key-features","title":"Key Features","text":"<ul> <li>Automatic Instrumentation - Traces all message handling</li> <li>Context Propagation - Via CloudEvents metadata</li> <li>Jaeger Integration - Export to Jaeger for visualization</li> <li>Production Ready - Low overhead, high throughput</li> </ul>"},{"location":"examples/tracing/#basic-example","title":"Basic Example","text":"<pre><code>from orchestrix.infrastructure.tracing import init_tracing, TraceConfig\nfrom orchestrix.infrastructure import InMemoryMessageBus\nfrom orchestrix.core.messaging.message import Command, Event\nfrom dataclasses import dataclass\n\n# Initialize tracing\ninit_tracing(\n    TraceConfig(\n        service_name=\"order-service\",\n        jaeger_endpoint=\"http://localhost:14268/api/traces\",\n        environment=\"production\"\n    )\n)\n\n@dataclass(frozen=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_name: str\n\n@dataclass(frozen=True)\nclass OrderCreated(Event):\n    order_id: str\n    customer_name: str\n\n# Setup\nbus = InMemoryMessageBus()\n\ndef handle_create_order(cmd: CreateOrder):\n    # This will be traced automatically\n    print(f\"Creating order {cmd.order_id}\")\n    bus.publish(OrderCreated(\n        order_id=cmd.order_id,\n        customer_name=cmd.customer_name\n    ))\n\ndef handle_order_created(event: OrderCreated):\n    # This will also be traced\n    print(f\"Order created: {event.order_id}\")\n\nbus.subscribe(CreateOrder, handle_create_order)\nbus.subscribe(OrderCreated, handle_order_created)\n\n# Publish command - generates trace\nbus.publish(CreateOrder(\n    order_id=\"ORD-001\",\n    customer_name=\"Alice\"\n))\n</code></pre>"},{"location":"examples/tracing/#running-with-jaeger","title":"Running with Jaeger","text":""},{"location":"examples/tracing/#start-jaeger","title":"Start Jaeger","text":"<pre><code>docker run -d --name jaeger \\\n  -p 6831:6831/udp \\\n  -p 16686:16686 \\\n  -p 14268:14268 \\\n  jaegertracing/all-in-one:latest\n</code></pre>"},{"location":"examples/tracing/#run-example","title":"Run Example","text":"<pre><code>cd examples/tracing\nuv run example.py\n</code></pre>"},{"location":"examples/tracing/#view-traces","title":"View Traces","text":"<p>Open http://localhost:16686 in your browser.</p>"},{"location":"examples/tracing/#trace-context-propagation","title":"Trace Context Propagation","text":"<p>Traces automatically propagate across service boundaries via CloudEvents:</p> <pre><code># Service A\nevent = OrderCreated(\n    order_id=\"ORD-001\",\n    customer_name=\"Alice\"\n)\n# Trace context added to CloudEvents metadata\nbus.publish(event)\n\n# Service B receives event with trace context\n# Continues the same trace automatically\n</code></pre>"},{"location":"examples/tracing/#custom-spans","title":"Custom Spans","text":"<p>Add custom spans for detailed tracking:</p> <pre><code>from orchestrix.infrastructure.tracing import create_span\n\nasync def handle_order(cmd: CreateOrder):\n    with create_span(\"validate-order\") as span:\n        span.set_attribute(\"order_id\", cmd.order_id)\n        # Validation logic\n\n    with create_span(\"save-order\") as span:\n        # Persistence logic\n        pass\n</code></pre>"},{"location":"examples/tracing/#configuration","title":"Configuration","text":"<pre><code>TraceConfig(\n    service_name=\"order-service\",          # Service identifier\n    jaeger_endpoint=\"http://localhost:14268/api/traces\",\n    environment=\"production\",              # Environment tag\n    sample_rate=1.0,                       # Sample 100% of traces\n    max_tag_length=1024                    # Max attribute length\n)\n</code></pre>"},{"location":"examples/tracing/#best-practices","title":"Best Practices","text":"<ol> <li>Service Names - Use descriptive, unique names</li> <li>Sampling - Reduce sample_rate in high-volume production</li> <li>Attributes - Add relevant context to spans</li> <li>Error Handling - Traces capture exceptions automatically</li> </ol>"},{"location":"examples/tracing/#metrics-available","title":"Metrics Available","text":"<ul> <li>Request duration (p50, p95, p99)</li> <li>Error rates</li> <li>Service dependencies</li> <li>Call graphs</li> </ul>"},{"location":"examples/tracing/#learn-more","title":"Learn More","text":"<ul> <li>OpenTelemetry Docs</li> <li>Jaeger Documentation</li> <li>Full Example</li> <li>API Reference</li> </ul>"},{"location":"examples/versioning/","title":"Event Versioning","text":"<p>Event versioning allows you to evolve event schemas over time while maintaining backward compatibility.</p>"},{"location":"examples/versioning/#overview","title":"Overview","text":"<p>As your application evolves, event structures change. Event versioning with upcasters allows old events to be automatically transformed to new schemas when loaded.</p>"},{"location":"examples/versioning/#key-features","title":"Key Features","text":"<ul> <li>Upcasters - Transform old events to new versions</li> <li>Version Detection - Automatic version detection</li> <li>Multiple Versions - Support multiple schema versions</li> <li>Backward Compatible - Old events work with new code</li> </ul>"},{"location":"examples/versioning/#basic-example","title":"Basic Example","text":""},{"location":"examples/versioning/#version-1-initial","title":"Version 1 (Initial)","text":"<pre><code>from dataclasses import dataclass\nfrom orchestrix.core.messaging.message import Event\n\n@dataclass(frozen=True, kw_only=True)\nclass OrderCreatedV1(Event):\n    \"\"\"Initial version - single address field.\"\"\"\n    order_id: str\n    customer_name: str\n    address: str  # Single address field\n    total_amount: float\n</code></pre>"},{"location":"examples/versioning/#version-2-split-address","title":"Version 2 (Split Address)","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass OrderCreatedV2(Event):\n    \"\"\"Version 2 - structured address.\"\"\"\n    order_id: str\n    customer_name: str\n    street: str\n    city: str\n    country: str\n    total_amount: float\n</code></pre>"},{"location":"examples/versioning/#upcaster","title":"Upcaster","text":"<pre><code>from orchestrix.core.eventsourcing.versioning import Upcaster, VersionRegistry\n\nclass OrderCreatedV1ToV2(Upcaster):\n    \"\"\"Upcasts V1 events to V2 format.\"\"\"\n\n    def can_upcast(self, event: Event) -&gt; bool:\n        return isinstance(event, OrderCreatedV1)\n\n    def upcast(self, event: OrderCreatedV1) -&gt; OrderCreatedV2:\n        # Parse single address into components\n        parts = event.address.split(\", \")\n        return OrderCreatedV2(\n            order_id=event.order_id,\n            customer_name=event.customer_name,\n            street=parts[0] if len(parts) &gt; 0 else \"\",\n            city=parts[1] if len(parts) &gt; 1 else \"\",\n            country=parts[2] if len(parts) &gt; 2 else \"\",\n            total_amount=event.total_amount\n        )\n\n# Register upcaster\nregistry = VersionRegistry()\nregistry.register_upcaster(OrderCreatedV1ToV2())\n\n# Load events - old events automatically upcasted\nevents = store.load(\"order-123\")\nfor event in events:\n    # V1 events are automatically converted to V2\n    if isinstance(event, OrderCreatedV2):\n        print(f\"Order in {event.city}, {event.country}\")\n</code></pre>"},{"location":"examples/versioning/#chained-upcasters","title":"Chained Upcasters","text":"<p>Support multiple version transitions:</p> <pre><code># V1 -&gt; V2 -&gt; V3\nclass OrderCreatedV2ToV3(Upcaster):\n    \"\"\"Adds email field.\"\"\"\n\n    def upcast(self, event: OrderCreatedV2) -&gt; OrderCreatedV3:\n        return OrderCreatedV3(\n            order_id=event.order_id,\n            customer_name=event.customer_name,\n            street=event.street,\n            city=event.city,\n            country=event.country,\n            email=\"\",  # Default value for new field\n            total_amount=event.total_amount\n        )\n\n# Register both\nregistry.register_upcaster(OrderCreatedV1ToV2())\nregistry.register_upcaster(OrderCreatedV2ToV3())\n\n# V1 events automatically go through both upcasters\n</code></pre>"},{"location":"examples/versioning/#version-metadata","title":"Version Metadata","text":"<p>Add version information to events:</p> <pre><code>@dataclass(frozen=True, kw_only=True)\nclass OrderCreatedV2(Event):\n    order_id: str\n    customer_name: str\n    street: str\n    city: str\n    country: str\n    total_amount: float\n\n    def __post_init__(self):\n        super().__post_init__()\n        # Add version to metadata\n        object.__setattr__(self, 'version', 2)\n</code></pre>"},{"location":"examples/versioning/#running-the-example","title":"Running the Example","text":"<pre><code>cd examples/versioning\nuv run example.py\n</code></pre>"},{"location":"examples/versioning/#use-cases","title":"Use Cases","text":"<ul> <li>Schema Evolution - Add/remove/rename fields</li> <li>Data Migration - Transform old data formats</li> <li>Backward Compatibility - Support multiple client versions</li> <li>Technical Debt - Gradually migrate to new schemas</li> </ul>"},{"location":"examples/versioning/#best-practices","title":"Best Practices","text":"<ol> <li>Immutable Events - Never change existing event classes</li> <li>Version Numbers - Use explicit version numbers (V1, V2, V3)</li> <li>Default Values - Provide sensible defaults for new fields</li> <li>Testing - Test all upcaster chains thoroughly</li> <li>Documentation - Document version changes in CHANGELOG</li> </ol>"},{"location":"examples/versioning/#strategies","title":"Strategies","text":""},{"location":"examples/versioning/#copy-and-transform","title":"Copy-and-Transform","text":"<p>Create new event class, transform in upcaster:</p> <pre><code># Good: Clear version separation\nclass OrderCreatedV1(Event): ...\nclass OrderCreatedV2(Event): ...\nclass V1ToV2Upcaster(Upcaster): ...\n</code></pre>"},{"location":"examples/versioning/#in-place-migration","title":"In-Place Migration","text":"<p>One-time migration script:</p> <pre><code># For breaking changes\nasync def migrate_events():\n    for aggregate_id in all_aggregates:\n        events = store.load(aggregate_id)\n        new_events = [upcast(e) for e in events]\n        # Save to new store or overwrite\n</code></pre>"},{"location":"examples/versioning/#weak-schema","title":"Weak Schema","text":"<p>Use dict-based events (not recommended):</p> <pre><code># Avoid: Loses type safety\nevent = {\"type\": \"OrderCreated\", \"data\": {...}}\n</code></pre>"},{"location":"examples/versioning/#version-detection","title":"Version Detection","text":"<p>Detect event version automatically:</p> <pre><code>def get_version(event: Event) -&gt; int:\n    if hasattr(event, 'version'):\n        return event.version\n\n    # Fallback: detect by class name\n    if 'V1' in event.__class__.__name__:\n        return 1\n    elif 'V2' in event.__class__.__name__:\n        return 2\n\n    return 1  # Default to V1\n</code></pre>"},{"location":"examples/versioning/#learn-more","title":"Learn More","text":"<ul> <li>Best Practices</li> <li>Full Example</li> <li>API Reference</li> </ul>"},{"location":"getting-started/concepts/","title":"Core Concepts","text":"<p>Orchestrix is built around several key concepts from Domain-Driven Design (DDD) and Event Sourcing.</p>"},{"location":"getting-started/concepts/#messages","title":"Messages","text":"<p>All communication in Orchestrix happens through Messages. Every message is:</p> <ul> <li>Immutable - Implemented with <code>@dataclass(frozen=True)</code></li> <li>CloudEvents-compatible - Has <code>id</code>, <code>type</code>, <code>source</code>, and <code>timestamp</code></li> <li>Type-safe - Full type annotations for IDE support</li> </ul> <pre><code>from orchestrix import Message, Command, Event\n\n# Base message - rarely used directly\n@dataclass(frozen=True, kw_only=True)\nclass MyMessage(Message):\n    data: str\n</code></pre>"},{"location":"getting-started/concepts/#commands","title":"Commands","text":"<p>Commands represent an intention to change state. They:</p> <ul> <li>Express what you want to happen</li> <li>May be rejected (validation, business rules)</li> <li>Are handled by exactly one handler</li> <li>Use imperative naming (CreateOrder, CancelOrder)</li> </ul> <pre><code>from orchestrix import Command\n\n@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_name: str\n    total_amount: float\n</code></pre>"},{"location":"getting-started/concepts/#events","title":"Events","text":"<p>Events represent facts that have occurred. They:</p> <ul> <li>Express what has happened</li> <li>Cannot be rejected (they already happened)</li> <li>May be handled by zero or more handlers</li> <li>Use past-tense naming (OrderCreated, OrderCancelled)</li> </ul> <pre><code>from orchestrix import Event\n\n@dataclass(frozen=True, kw_only=True)\nclass OrderCreated(Event):\n    order_id: str\n    customer_name: str\n    total_amount: float\n</code></pre>"},{"location":"getting-started/concepts/#aggregates","title":"Aggregates","text":"<p>Aggregates are domain objects that:</p> <ul> <li>Enforce business rules</li> <li>Maintain consistency boundaries</li> <li>Emit events when state changes</li> <li>Are reconstructed from their event stream</li> </ul> <pre><code>from dataclasses import dataclass, field\n\n@dataclass\nclass Order:\n    order_id: str\n    customer_name: str\n    total_amount: float\n    status: str = \"pending\"\n    _events: list[Event] = field(default_factory=list, repr=False)\n\n    @classmethod\n    def create(cls, order_id: str, customer_name: str, total_amount: float):\n        order = cls(order_id, customer_name, total_amount)\n        order._events.append(OrderCreated(\n            order_id=order_id,\n            customer_name=customer_name,\n            total_amount=total_amount\n        ))\n        return order\n\n    def cancel(self) -&gt; None:\n        if self.status != \"pending\":\n            raise ValueError(\"Can only cancel pending orders\")\n        self.status = \"cancelled\"\n        self._events.append(OrderCancelled(order_id=self.order_id))\n\n    def collect_events(self) -&gt; list[Event]:\n        events = self._events.copy()\n        self._events.clear()\n        return events\n</code></pre>"},{"location":"getting-started/concepts/#message-bus","title":"Message Bus","text":"<p>The MessageBus routes messages to their handlers:</p> <pre><code>from orchestrix import MessageBus, InMemoryMessageBus\n\nbus = InMemoryMessageBus()\n\n# Subscribe handlers\nbus.subscribe(CreateOrder, create_order_handler)\nbus.subscribe(OrderCreated, send_confirmation_email)\nbus.subscribe(OrderCreated, update_inventory)\n\n# Publish messages\nbus.publish(CreateOrder(...))\n</code></pre>"},{"location":"getting-started/concepts/#event-store","title":"Event Store","text":"<p>The EventStore persists events for aggregate reconstruction:</p> <pre><code>from orchestrix import EventStore, InMemoryEventStore\n\nstore = InMemoryEventStore()\n\n# Save events\nevents = [OrderCreated(...), OrderShipped(...)]\nstore.save(\"ORDER-123\", events)\n\n# Load events\nall_events = store.load(\"ORDER-123\")\n# Reconstruct aggregate from events\n</code></pre>"},{"location":"getting-started/concepts/#modules","title":"Modules","text":"<p>Modules encapsulate domain logic and wire handlers to the bus:</p> <pre><code>from orchestrix import Module, MessageBus, EventStore\n\nclass OrderModule(Module):\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        # Register command handlers\n        bus.subscribe(CreateOrder, CreateOrderHandler(bus, store))\n        bus.subscribe(CancelOrder, CancelOrderHandler(bus, store))\n\n        # Register event handlers (projections, side effects)\n        bus.subscribe(OrderCreated, log_order_created)\n        bus.subscribe(OrderCancelled, refund_payment)\n</code></pre>"},{"location":"getting-started/concepts/#command-handlers","title":"Command Handlers","text":"<p>Command Handlers process commands:</p> <ol> <li>Load aggregate from event store (or create new)</li> <li>Execute business logic on aggregate</li> <li>Collect new events from aggregate</li> <li>Save events to store</li> <li>Publish events to bus</li> </ol> <pre><code>from orchestrix import CommandHandler\n\nclass CreateOrderHandler(CommandHandler[CreateOrder]):\n    def __init__(self, bus: MessageBus, store: EventStore) -&gt; None:\n        self.bus = bus\n        self.store = store\n\n    def handle(self, command: CreateOrder) -&gt; None:\n        # Create aggregate\n        order = Order.create(\n            command.order_id,\n            command.customer_name,\n            command.total_amount\n        )\n\n        # Persist and publish events\n        events = order.collect_events()\n        self.store.save(command.order_id, events)\n        for event in events:\n            self.bus.publish(event)\n</code></pre>"},{"location":"getting-started/concepts/#putting-it-together","title":"Putting It Together","text":"<p>The typical flow is:</p> <ol> <li>Application publishes a Command to the MessageBus</li> <li>MessageBus routes to the appropriate CommandHandler</li> <li>CommandHandler loads/creates an Aggregate</li> <li>Aggregate executes business logic and emits Events</li> <li>Events are saved to EventStore</li> <li>Events are published to MessageBus</li> <li>Event Handlers react to events (projections, notifications, etc.)</li> </ol> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Application \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 publish(Command)\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 MessageBus  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 route\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 CommandHandler \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 Aggregate \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                     \u2502 emit Events\n         \u2502                     \u25bc\n         \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502              \u2502 collect      \u2502\n         \u2502              \u2502 _events      \u2502\n         \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u25bc                     \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502 EventStore     \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502 save(events)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502 publish Events\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Event Handlers  \u2502\n\u2502 (projections,   \u2502\n\u2502  side effects)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/concepts/#next-steps","title":"Next Steps","text":"<ul> <li>Creating Modules - Module design patterns</li> <li>Commands &amp; Events - Message design guidelines</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9 or higher</li> <li>pip or uv package manager</li> </ul>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<p>Using pip:</p> <pre><code>pip install orchestrix\n</code></pre> <p>Using uv (recommended):</p> <pre><code>uv add orchestrix\n</code></pre>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<p>For development or the latest features:</p> <pre><code>git clone https://github.com/stefanposs/orchestrix.git\ncd orchestrix\nuv sync --all-extras --dev\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Check that Orchestrix is installed correctly:</p> <pre><code>import orchestrix\n\nprint(orchestrix.__version__)\n# Output: 0.1.0\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Build your first application</li> <li>Core Concepts - Understand the framework fundamentals</li> </ul>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>This guide will walk you through creating your first Orchestrix application.</p>"},{"location":"getting-started/quick-start/#your-first-module","title":"Your First Module","text":"<p>Let's build a simple task management system using event sourcing:</p>"},{"location":"getting-started/quick-start/#1-define-messages","title":"1. Define Messages","text":"<pre><code>from dataclasses import dataclass\nfrom orchestrix import Command, Event\n\n@dataclass(frozen=True, kw_only=True)\nclass CreateTask(Command):\n    task_id: str\n    title: str\n    description: str\n\n@dataclass(frozen=True, kw_only=True)\nclass TaskCreated(Event):\n    task_id: str\n    title: str\n    description: str\n\n@dataclass(frozen=True, kw_only=True)\nclass CompleteTask(Command):\n    task_id: str\n\n@dataclass(frozen=True, kw_only=True)\nclass TaskCompleted(Event):\n    task_id: str\n</code></pre>"},{"location":"getting-started/quick-start/#2-create-an-aggregate","title":"2. Create an Aggregate","text":"<pre><code>from dataclasses import dataclass, field\n\n@dataclass\nclass Task:\n    \"\"\"Task aggregate root.\"\"\"\n    task_id: str\n    title: str\n    description: str\n    completed: bool = False\n    _events: list[Event] = field(default_factory=list, repr=False)\n\n    @classmethod\n    def create(cls, task_id: str, title: str, description: str) -&gt; \"Task\":\n        \"\"\"Create a new task.\"\"\"\n        task = cls(task_id=task_id, title=title, description=description)\n        task._events.append(TaskCreated(\n            task_id=task_id,\n            title=title,\n            description=description\n        ))\n        return task\n\n    def complete(self) -&gt; None:\n        \"\"\"Mark task as completed.\"\"\"\n        if self.completed:\n            raise ValueError(\"Task already completed\")\n        self.completed = True\n        self._events.append(TaskCompleted(task_id=self.task_id))\n\n    def collect_events(self) -&gt; list[Event]:\n        \"\"\"Collect and clear pending events.\"\"\"\n        events = self._events.copy()\n        self._events.clear()\n        return events\n</code></pre>"},{"location":"getting-started/quick-start/#3-implement-command-handlers","title":"3. Implement Command Handlers","text":"<pre><code>from orchestrix import CommandHandler, MessageBus, EventStore\n\nclass CreateTaskHandler(CommandHandler[CreateTask]):\n    \"\"\"Handle CreateTask command.\"\"\"\n\n    def __init__(self, bus: MessageBus, store: EventStore) -&gt; None:\n        self.bus = bus\n        self.store = store\n\n    def handle(self, command: CreateTask) -&gt; None:\n        # Create aggregate\n        task = Task.create(\n            task_id=command.task_id,\n            title=command.title,\n            description=command.description\n        )\n\n        # Collect and publish events\n        events = task.collect_events()\n        self.store.save(command.task_id, events)\n        for event in events:\n            self.bus.publish(event)\n\nclass CompleteTaskHandler(CommandHandler[CompleteTask]):\n    \"\"\"Handle CompleteTask command.\"\"\"\n\n    def __init__(self, bus: MessageBus, store: EventStore) -&gt; None:\n        self.bus = bus\n        self.store = store\n\n    def handle(self, command: CompleteTask) -&gt; None:\n        # Reconstruct aggregate from events\n        events = self.store.load(command.task_id)\n        task = self._reconstruct_task(events)\n\n        # Execute business logic\n        task.complete()\n\n        # Save new events\n        new_events = task.collect_events()\n        self.store.save(command.task_id, new_events)\n        for event in new_events:\n            self.bus.publish(event)\n\n    def _reconstruct_task(self, events: list[Event]) -&gt; Task:\n        \"\"\"Reconstruct task from event stream.\"\"\"\n        task = None\n        for event in events:\n            if isinstance(event, TaskCreated):\n                task = Task(\n                    task_id=event.task_id,\n                    title=event.title,\n                    description=event.description\n                )\n            elif isinstance(event, TaskCompleted):\n                task.completed = True\n        return task\n</code></pre>"},{"location":"getting-started/quick-start/#4-create-a-module","title":"4. Create a Module","text":"<pre><code>from orchestrix import Module, MessageBus, EventStore\n\nclass TaskModule(Module):\n    \"\"\"Task management module.\"\"\"\n\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        \"\"\"Register handlers with the bus.\"\"\"\n        bus.subscribe(CreateTask, CreateTaskHandler(bus, store))\n        bus.subscribe(CompleteTask, CompleteTaskHandler(bus, store))\n\n        # Optional: Subscribe to events for side effects\n        bus.subscribe(TaskCreated, lambda event: print(f\"\ud83d\udcdd Task created: {event.title}\"))\n        bus.subscribe(TaskCompleted, lambda event: print(f\"\u2705 Task completed: {event.task_id}\"))\n</code></pre>"},{"location":"getting-started/quick-start/#5-wire-everything-together","title":"5. Wire Everything Together","text":"<pre><code>from orchestrix import InMemoryMessageBus, InMemoryEventStore\n\n# Create infrastructure\nbus = InMemoryMessageBus()\nstore = InMemoryEventStore()\n\n# Register module\nmodule = TaskModule()\nmodule.register(bus, store)\n\n# Execute commands\nbus.publish(CreateTask(\n    task_id=\"TASK-001\",\n    title=\"Learn Orchestrix\",\n    description=\"Complete the quick start guide\"\n))\n\nbus.publish(CompleteTask(task_id=\"TASK-001\"))\n</code></pre> <p>Output: <pre><code>\ud83d\udcdd Task created: Learn Orchestrix\n\u2705 Task completed: TASK-001\n</code></pre></p>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<p>Learn More:</p> <ul> <li>Core Concepts - Understand Messages, Commands, and Events</li> <li>Creating Modules - Best practices for module design</li> <li>Event Store Guide - Persist and replay events</li> <li>Best Practices - Production patterns</li> </ul> <p>Explore Examples:</p> <ul> <li>Banking Example - Simple event sourcing with accounts</li> <li>E-Commerce Example - Saga pattern for order processing  </li> <li>Notifications Example - Retry logic and error handling</li> <li>GDPR Lakehouse - Complete compliance example</li> <li>All Examples - Browse all production-ready samples</li> </ul> <p>API Reference:</p> <ul> <li>Core API - Commands, Events, Aggregates</li> <li>Infrastructure API - Message Bus, Event Store</li> </ul>"},{"location":"guide/","title":"Production Documentation Index","text":"<p>Welcome to Orchestrix production documentation! This page helps you navigate the different guides based on your needs.</p>"},{"location":"guide/#documentation-overview","title":"\ud83d\udcda Documentation Overview","text":""},{"location":"guide/#for-new-projects","title":"For New Projects","text":"<p>Start here if you're planning a new Orchestrix deployment:</p> <ol> <li>Production Deployment Guide - (RECOMMENDED)</li> <li>Complete guide for all project sizes (small/medium/large)</li> <li>Infrastructure recommendations based on scale</li> <li>Step-by-step deployment instructions</li> <li>Migration paths between tiers</li> <li>Choose this if: You want comprehensive guidance on the right architecture for your scale</li> </ol>"},{"location":"guide/#for-production-readiness","title":"For Production Readiness","text":"<p>Use these when preparing for production launch:</p> <ol> <li>Production Readiness Guide</li> <li>Detailed production checklist</li> <li>System requirements</li> <li>Environment setup</li> <li>Monitoring and observability</li> <li>Security considerations</li> <li>Choose this if: You need a comprehensive pre-launch checklist</li> </ol>"},{"location":"guide/#for-specific-topics","title":"For Specific Topics","text":"<ol> <li>Best Practices</li> <li>Domain modeling patterns</li> <li>Error handling strategies</li> <li>Event design guidelines</li> <li>Testing approaches</li> <li> <p>Choose this if: You want to improve code quality and architecture</p> </li> <li> <p>Event Store Guide</p> </li> <li>EventStore implementations comparison</li> <li>PostgreSQL vs EventSourcingDB vs InMemory</li> <li>Performance tuning</li> <li>Backup strategies</li> <li> <p>Choose this if: You need deep dive into event persistence</p> </li> <li> <p>Message Bus Guide</p> </li> <li>MessageBus patterns</li> <li>Sync vs Async</li> <li>Error handling</li> <li>Performance optimization</li> <li>Choose this if: You're building complex message routing logic</li> </ol>"},{"location":"guide/#additional-resources","title":"Additional Resources","text":"<ol> <li>Creating Modules</li> <li>Module design patterns</li> <li>Registration best practices</li> <li>Dependency injection</li> <li> <p>Choose this if: You're structuring your application domains</p> </li> <li> <p>Commands &amp; Events</p> </li> <li>Message design patterns</li> <li>Validation strategies</li> <li>CloudEvents compatibility</li> <li>Choose this if: You're designing your domain messages</li> </ol>"},{"location":"guide/#quick-decision-tree","title":"\ud83c\udfaf Quick Decision Tree","text":"<p>\"What documentation do I need?\"</p> <pre><code>Are you starting a new project?\n\u251c\u2500 Yes \u2192 Start with Production Deployment Guide\n\u2502  \u2514\u2500 What's your scale?\n\u2502     \u251c\u2500 &lt; 10k events/month \u2192 Small Projects section\n\u2502     \u251c\u2500 10k-100k events/month \u2192 Medium Projects section\n\u2502     \u2514\u2500 &gt; 100k events/month \u2192 Large Projects section\n\u2502\n\u2514\u2500 No \u2192 Do you have an existing project?\n   \u251c\u2500 Preparing for launch \u2192 Production Readiness Guide\n   \u251c\u2500 Improving code quality \u2192 Best Practices\n   \u251c\u2500 Performance issues \u2192 Event Store Guide + Message Bus Guide\n   \u2514\u2500 Learning patterns \u2192 Creating Modules + Commands &amp; Events\n</code></pre>"},{"location":"guide/#documentation-comparison","title":"\ud83d\udcca Documentation Comparison","text":"Guide Audience Scope Length When to Use Production Deployment DevOps, Architects Infrastructure &amp; scaling Comprehensive Planning deployment Production Readiness DevOps, Engineers Launch checklist Detailed Pre-launch audit Best Practices Developers Code quality Focused Daily development Event Store Guide Developers, DevOps Persistence Technical Storage decisions Message Bus Guide Developers Messaging Technical Routing complexity Creating Modules Developers Architecture Tutorial Domain modeling Commands &amp; Events Developers Messages Tutorial Message design"},{"location":"guide/#recommended-reading-paths","title":"\ud83d\ude80 Recommended Reading Paths","text":""},{"location":"guide/#path-1-complete-beginner","title":"Path 1: Complete Beginner","text":"<ol> <li>Installation</li> <li>Quick Start</li> <li>Core Concepts</li> <li>Creating Modules</li> <li>Commands &amp; Events</li> <li>Examples</li> </ol>"},{"location":"guide/#path-2-production-launch","title":"Path 2: Production Launch","text":"<ol> <li>Production Deployment Guide - Choose your scale</li> <li>Production Readiness Guide - Complete checklist</li> <li>Best Practices - Code quality review</li> <li>Event Store Guide - Storage configuration</li> <li>Examples: Observability - Monitoring setup</li> </ol>"},{"location":"guide/#path-3-scaling-existing-project","title":"Path 3: Scaling Existing Project","text":"<ol> <li>Production Deployment Guide - Review migration paths</li> <li>Event Store Guide - Upgrade storage</li> <li>Message Bus Guide - Consider async patterns</li> <li>Best Practices - Refactoring guidance</li> <li>Examples: Performance - Optimization techniques</li> </ol>"},{"location":"guide/#path-4-architecture-deep-dive","title":"Path 4: Architecture Deep Dive","text":"<ol> <li>Core Concepts</li> <li>Architecture</li> <li>Best Practices</li> <li>Creating Modules</li> <li>Event Store Guide</li> <li>Message Bus Guide</li> </ol>"},{"location":"guide/#tips-for-using-this-documentation","title":"\ud83d\udca1 Tips for Using This Documentation","text":""},{"location":"guide/#for-quick-reference","title":"For Quick Reference","text":"<ul> <li>Use the search bar (top of page) to find specific topics</li> <li>Bookmark the index pages for each section</li> <li>Check code examples for copy-paste templates</li> </ul>"},{"location":"guide/#for-learning","title":"For Learning","text":"<ul> <li>Follow the recommended reading paths above</li> <li>Work through examples hands-on</li> <li>Reference API documentation when stuck</li> </ul>"},{"location":"guide/#for-production","title":"For Production","text":"<ul> <li>Complete the production readiness checklist</li> <li>Review all best practices relevant to your domain</li> <li>Test deployment procedures in staging first</li> </ul>"},{"location":"guide/#see-also","title":"\ud83d\udd17 See Also","text":"<ul> <li>Examples - Working code samples</li> <li>API Reference - Detailed API documentation</li> <li>Architecture - Design decisions</li> <li>Contributing - Join development</li> </ul>"},{"location":"guide/#need-help","title":"\ud83d\udcee Need Help?","text":"<p>Can't find what you're looking for?</p> <ul> <li>\ud83d\udcd6 Search Documentation</li> <li>\ud83d\udc1b Report Issue</li> <li>\ud83d\udcac Discussion Forum</li> <li>\ud83d\udce7 Contact Support</li> </ul>"},{"location":"guide/best-practices/","title":"Best Practices","text":"<p>Production-ready Patterns f\u00fcr Orchestrix - kein Bullshit! \ud83d\ude80</p>"},{"location":"guide/best-practices/#domain-design","title":"Domain Design","text":""},{"location":"guide/best-practices/#bounded-contexts","title":"Bounded Contexts","text":"<p>Jedes Module = ein Bounded Context:</p> <pre><code># \u2705 Gut: Klare Grenzen\nclass OrderModule(Module): pass      # Order Domain\nclass PaymentModule(Module): pass    # Payment Domain\nclass ShippingModule(Module): pass   # Shipping Domain\n\n# \u274c Schlecht: God Module\nclass EverythingModule(Module): pass  # Too broad!\n</code></pre>"},{"location":"guide/best-practices/#aggregate-boundaries","title":"Aggregate Boundaries","text":"<pre><code># \u2705 Gut: Kleine, fokussierte Aggregates\nclass Order:\n    order_id: str\n    customer_id: str  # Referenz!\n    items: list[OrderItem]\n\n# \u274c Schlecht: Zu gro\u00df\nclass Order:\n    order_id: str\n    customer: Customer        # Nested aggregate!\n    items: list[Product]      # Nested aggregates!\n    shipping: ShippingInfo    # Could be separate!\n</code></pre>"},{"location":"guide/best-practices/#event-granularity","title":"Event Granularity","text":"<pre><code># \u2705 Gut: Spezifische Events\nOrderPlaced(order_id, items, total)\nOrderPaid(order_id, payment_id, amount)\nOrderShipped(order_id, tracking_number)\nOrderCancelled(order_id, reason)\n\n# \u274c Schlecht: Generische Events\nOrderUpdated(order_id, field, value)  # Was wurde ge\u00e4ndert?\nOrderChanged(order_id, data)          # Zu vage!\n</code></pre>"},{"location":"guide/best-practices/#error-handling","title":"Error Handling","text":""},{"location":"guide/best-practices/#command-validation","title":"Command Validation","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    order_id: str\n    items: list[dict]\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Validate before processing.\"\"\"\n        if not self.items:\n            raise ValueError(\"Order must have at least one item\")\n        if any(item[\"quantity\"] &lt;= 0 for item in self.items):\n            raise ValueError(\"Quantity must be positive\")\n</code></pre>"},{"location":"guide/best-practices/#handler-error-handling","title":"Handler Error Handling","text":"<pre><code>class CreateOrderHandler(CommandHandler[CreateOrder]):\n    def handle(self, command: CreateOrder) -&gt; None:\n        try:\n            order = Order.create(command.order_id, command.items)\n            events = order.collect_events()\n            self.store.save(command.order_id, events)\n            for event in events:\n                self.bus.publish(event)\n\n        except ValueError as e:\n            # Business rule violation\n            logger.warning(f\"Order creation failed: {e}\")\n            self.bus.publish(OrderCreationFailed(\n                order_id=command.order_id,\n                reason=str(e)\n            ))\n\n        except Exception as e:\n            # Unexpected error\n            logger.error(f\"Unexpected error: {e}\", exc_info=True)\n            raise  # Re-raise for retry logic\n</code></pre>"},{"location":"guide/best-practices/#safe-event-handlers","title":"Safe Event Handlers","text":"<pre><code>def safe_event_handler(handler):\n    \"\"\"Decorator for safe event handlers.\"\"\"\n    def wrapper(event):\n        try:\n            return handler(event)\n        except Exception as e:\n            logger.error(\n                f\"Event handler failed: {handler.__name__}\",\n                exc_info=True,\n                extra={\"event\": event}\n            )\n            # Don't re-raise - other handlers should still run\n    return wrapper\n\n@safe_event_handler\ndef send_email(event: OrderCreated) -&gt; None:\n    email_service.send(...)\n</code></pre>"},{"location":"guide/best-practices/#testing","title":"Testing","text":""},{"location":"guide/best-practices/#unit-tests","title":"Unit Tests","text":"<pre><code>def test_order_creation():\n    # Test aggregate logic in isolation\n    order = Order.create(\"ORD-001\", [{\"sku\": \"A\", \"qty\": 2}])\n\n    events = order.collect_events()\n\n    assert len(events) == 1\n    assert isinstance(events[0], OrderCreated)\n    assert events[0].order_id == \"ORD-001\"\n</code></pre>"},{"location":"guide/best-practices/#integration-tests","title":"Integration Tests","text":"<pre><code>def test_order_module_integration():\n    # Test with real infrastructure\n    bus = InMemoryMessageBus()\n    store = InMemoryEventStore()\n\n    module = OrderModule()\n    module.register(bus, store)\n\n    # Execute command\n    bus.publish(CreateOrder(order_id=\"ORD-001\", ...))\n\n    # Verify events stored\n    events = store.load(\"ORD-001\")\n    assert len(events) == 1\n    assert isinstance(events[0], OrderCreated)\n</code></pre>"},{"location":"guide/best-practices/#test-fixtures","title":"Test Fixtures","text":"<pre><code>@pytest.fixture\ndef bus():\n    return InMemoryMessageBus()\n\n@pytest.fixture\ndef store():\n    return InMemoryEventStore()\n\n@pytest.fixture\ndef order_module(bus, store):\n    module = OrderModule()\n    module.register(bus, store)\n    return module\n\ndef test_with_fixtures(order_module, bus):\n    bus.publish(CreateOrder(...))\n    # Test logic\n</code></pre>"},{"location":"guide/best-practices/#performance","title":"Performance","text":""},{"location":"guide/best-practices/#event-store-optimization","title":"Event Store Optimization","text":"<pre><code># \u274c Schlecht: Load all events every time\nevents = store.load(aggregate_id)  # Could be 10,000 events!\norder = Order.from_events(events)\n\n# \u2705 Besser: Snapshots for large aggregates\nsnapshot = snapshot_store.load(aggregate_id)\nevents_after_snapshot = store.load_after_version(\n    aggregate_id,\n    snapshot.version\n)\norder = snapshot.aggregate\nfor event in events_after_snapshot:\n    order.apply(event)\n</code></pre>"},{"location":"guide/best-practices/#snapshot-pattern","title":"Snapshot Pattern","text":"<pre><code>@dataclass\nclass Snapshot:\n    aggregate_id: str\n    version: int\n    state: dict\n    created_at: str\n\nclass SnapshotStore:\n    def save_snapshot(self, aggregate_id: str, version: int, state: dict):\n        \"\"\"Save aggregate snapshot every N events.\"\"\"\n        if version % 100 == 0:  # Every 100 events\n            self.snapshots[aggregate_id] = Snapshot(\n                aggregate_id=aggregate_id,\n                version=version,\n                state=state,\n                created_at=datetime.utcnow().isoformat()\n            )\n</code></pre>"},{"location":"guide/best-practices/#batch-processing","title":"Batch Processing","text":"<pre><code># \u2705 Batch event publishing\nevents = []\nfor order in orders:\n    events.extend(order.collect_events())\n\n# Save all at once\nfor aggregate_id in set(e.aggregate_id for e in events):\n    aggregate_events = [e for e in events if e.aggregate_id == aggregate_id]\n    store.save(aggregate_id, aggregate_events)\n\n# Publish all\nfor event in events:\n    bus.publish(event)\n</code></pre>"},{"location":"guide/best-practices/#production-readiness","title":"Production Readiness","text":""},{"location":"guide/best-practices/#logging","title":"Logging","text":"<pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\nclass CreateOrderHandler(CommandHandler[CreateOrder]):\n    def handle(self, command: CreateOrder) -&gt; None:\n        logger.info(\n            \"Processing CreateOrder\",\n            extra={\n                \"command_id\": command.id,\n                \"order_id\": command.order_id,\n                \"customer_id\": command.customer_id\n            }\n        )\n\n        try:\n            # Business logic\n            logger.info(f\"Order {command.order_id} created successfully\")\n        except Exception as e:\n            logger.error(\n                f\"Failed to create order {command.order_id}\",\n                exc_info=True\n            )\n            raise\n</code></pre>"},{"location":"guide/best-practices/#monitoring","title":"Monitoring","text":"<pre><code>from prometheus_client import Counter, Histogram\n\ncommands_processed = Counter(\n    'commands_processed_total',\n    'Total commands processed',\n    ['command_type', 'status']\n)\n\ncommand_duration = Histogram(\n    'command_duration_seconds',\n    'Command processing duration',\n    ['command_type']\n)\n\nclass MonitoredHandler(CommandHandler[CreateOrder]):\n    @command_duration.labels(command_type='CreateOrder').time()\n    def handle(self, command: CreateOrder) -&gt; None:\n        try:\n            # Process command\n            commands_processed.labels(\n                command_type='CreateOrder',\n                status='success'\n            ).inc()\n        except Exception:\n            commands_processed.labels(\n                command_type='CreateOrder',\n                status='error'\n            ).inc()\n            raise\n</code></pre>"},{"location":"guide/best-practices/#configuration","title":"Configuration","text":"<pre><code>from pydantic import BaseSettings\n\nclass Settings(BaseSettings):\n    \"\"\"Application settings.\"\"\"\n    database_url: str\n    redis_url: str\n    log_level: str = \"INFO\"\n    enable_snapshots: bool = True\n    snapshot_interval: int = 100\n\n    class Config:\n        env_file = \".env\"\n\nsettings = Settings()\n\n# Use in application\nif settings.enable_snapshots:\n    snapshot_store = SnapshotStore(settings.database_url)\n</code></pre>"},{"location":"guide/best-practices/#security","title":"Security","text":""},{"location":"guide/best-practices/#sensitive-data","title":"Sensitive Data","text":"<pre><code># \u274c Nie sensitive Daten in Events\n@dataclass(frozen=True, kw_only=True)\nclass UserCreated(Event):\n    user_id: str\n    email: str\n    password_hash: str  # \u274c Nicht in Event Stream!\n    credit_card: str    # \u274c NIEMALS!\n\n# \u2705 Nur IDs und non-sensitive Daten\n@dataclass(frozen=True, kw_only=True)\nclass UserCreated(Event):\n    user_id: str\n    email: str\n    # Sensitive data in separate store\n</code></pre>"},{"location":"guide/best-practices/#audit-trail","title":"Audit Trail","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass Command(Message):\n    user_id: str = \"\"  # Who executed?\n    trace_id: str = \"\"  # Request tracking\n\n@dataclass(frozen=True, kw_only=True)\nclass Event(Message):\n    correlation_id: str = \"\"  # Which command?\n    causation_id: str = \"\"    # Which event?\n</code></pre>"},{"location":"guide/best-practices/#deployment","title":"Deployment","text":""},{"location":"guide/best-practices/#docker","title":"Docker","text":"<pre><code>FROM python:3.12-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD [\"python\", \"-m\", \"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\"]\n</code></pre>"},{"location":"guide/best-practices/#health-checks","title":"Health Checks","text":"<pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    try:\n        # Check database connection\n        store.load(\"test\")\n\n        return {\n            \"status\": \"healthy\",\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n    except Exception as e:\n        return {\n            \"status\": \"unhealthy\",\n            \"error\": str(e)\n        }, 503\n</code></pre>"},{"location":"guide/best-practices/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"guide/best-practices/#event-store-als-query-db","title":"\u274c Event Store als Query DB","text":"<pre><code># \u274c Schlecht: Query event store\nevents = store.load_all()\norders = [e for e in events if isinstance(e, OrderCreated)]\n# Langsam und ineffizient!\n\n# \u2705 Gut: Separate Read Model\nclass OrderReadModel:\n    def __init__(self):\n        self.orders = {}\n\n    def on_order_created(self, event: OrderCreated):\n        self.orders[event.order_id] = {\n            \"id\": event.order_id,\n            \"customer\": event.customer_id,\n            \"status\": \"pending\"\n        }\n\n    def find_by_customer(self, customer_id: str):\n        return [o for o in self.orders.values() \n                if o[\"customer\"] == customer_id]\n</code></pre>"},{"location":"guide/best-practices/#commands-zwischen-modules","title":"\u274c Commands zwischen Modules","text":"<pre><code># \u274c Schlecht\nclass InventoryModule(Module):\n    def on_order_created(self, event: OrderCreated):\n        # DON'T: Send command to other module!\n        self.bus.publish(ReserveInventory(...))\n\n# \u2705 Gut: Events only\nclass InventoryModule(Module):\n    def on_order_created(self, event: OrderCreated):\n        # Emit own event\n        self.bus.publish(InventoryReserved(...))\n</code></pre>"},{"location":"guide/best-practices/#mutable-aggregates","title":"\u274c Mutable Aggregates","text":"<pre><code># \u274c Schlecht\ndef handle_cancel_order(command: CancelOrder):\n    order = get_order(command.order_id)  # From cache\n    order.cancel()  # Mutates shared state!\n\n# \u2705 Gut\ndef handle_cancel_order(command: CancelOrder):\n    events = store.load(command.order_id)\n    order = Order.from_events(events)  # Fresh instance\n    order.cancel()\n</code></pre>"},{"location":"guide/best-practices/#next-steps","title":"Next Steps","text":"<ul> <li>Testing - Comprehensive Test Strategies</li> <li>Architecture - System Design</li> <li>Contributing - Contribute to Orchestrix</li> </ul>"},{"location":"guide/commands-events/","title":"Commands &amp; Events","text":"<p>Commands und Events sind die beiden Haupt-Message-Typen in Orchestrix. Verstehe den Unterschied!</p>"},{"location":"guide/commands-events/#commands-vs-events","title":"Commands vs Events","text":"Aspekt Command Event Bedeutung Intention (was soll passieren) Fakt (was ist passiert) Zeitform Imperativ (CreateOrder) Vergangenheit (OrderCreated) Handler Genau 1 Handler 0 bis N Handler Validierung Kann rejected werden Ist bereits passiert Quelle Application/User Domain Logic"},{"location":"guide/commands-events/#commands","title":"Commands","text":""},{"location":"guide/commands-events/#definition","title":"Definition","text":"<p>Ein Command repr\u00e4sentiert eine Intention, State zu \u00e4ndern.</p> <pre><code>from dataclasses import dataclass\nfrom orchestrix import Command\n\n@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    \"\"\"Command to create a new order.\"\"\"\n    order_id: str\n    customer_id: str\n    items: list[dict]\n    shipping_address: str\n</code></pre>"},{"location":"guide/commands-events/#naming-convention","title":"Naming Convention","text":"<ul> <li>Imperativ: CreateX, UpdateX, DeleteX, CancelX</li> <li>Spezifisch: Was genau soll passieren?</li> <li>Domain Language: Begriffe aus der Business-Dom\u00e4ne</li> </ul> <pre><code># \u2705 Gut\nclass PlaceOrder(Command): pass\nclass CancelSubscription(Command): pass\nclass ApproveInvoice(Command): pass\n\n# \u274c Schlecht\nclass OrderCommand(Command): pass  # Zu generisch\nclass DoSomething(Command): pass   # Nicht aussagekr\u00e4ftig\nclass Process(Command): pass       # Was wird processed?\n</code></pre>"},{"location":"guide/commands-events/#command-design","title":"Command Design","text":"<pre><code>@dataclass(frozen=True, kw_only=True)\nclass RegisterUser(Command):\n    \"\"\"Register a new user account.\n\n    Business Rules:\n    - Email must be unique\n    - Password min 8 characters\n    - Username alphanumeric only\n    \"\"\"\n    user_id: str\n    email: str\n    username: str\n    password: str\n    terms_accepted: bool = False\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Validate command data.\"\"\"\n        if not self.terms_accepted:\n            raise ValueError(\"Terms must be accepted\")\n        if len(self.password) &lt; 8:\n            raise ValueError(\"Password too short\")\n</code></pre>"},{"location":"guide/commands-events/#events","title":"Events","text":""},{"location":"guide/commands-events/#definition_1","title":"Definition","text":"<p>Ein Event repr\u00e4sentiert einen Fakt, der bereits passiert ist.</p> <pre><code>from dataclasses import dataclass\nfrom orchestrix import Event\n\n@dataclass(frozen=True, kw_only=True)\nclass OrderCreated(Event):\n    \"\"\"Event emitted when an order is successfully created.\"\"\"\n    order_id: str\n    customer_id: str\n    total_amount: float\n    created_at: str\n</code></pre>"},{"location":"guide/commands-events/#naming-convention_1","title":"Naming Convention","text":"<ul> <li>Vergangenheit: XCreated, XUpdated, XDeleted, XCancelled</li> <li>Fakt: Was ist tats\u00e4chlich passiert?</li> <li>Domain Events: Business-relevante Ereignisse</li> </ul> <pre><code># \u2705 Gut\nclass OrderPlaced(Event): pass\nclass SubscriptionCancelled(Event): pass\nclass InvoiceApproved(Event): pass\nclass PaymentReceived(Event): pass\n\n# \u274c Schlecht\nclass OrderEvent(Event): pass     # Zu generisch\nclass OrderChange(Event): pass    # Was hat sich ge\u00e4ndert?\nclass Updated(Event): pass        # Was wurde updated?\n</code></pre>"},{"location":"guide/commands-events/#event-design","title":"Event Design","text":"<p>Events sollten immutable und serializable sein:</p> <pre><code>@dataclass(frozen=True, kw_only=True)\nclass UserRegistered(Event):\n    \"\"\"User successfully registered.\n\n    Downstream consumers:\n    - Email service: Send welcome email\n    - Analytics: Track new user\n    - Billing: Create customer account\n    \"\"\"\n    user_id: str\n    email: str\n    username: str\n    registered_at: str\n    referral_code: str | None = None\n\n    # \u274c Keine mutable Objects!\n    # settings: dict  # Besser: Eigenes dataclass\n\n    # \u2705 Immutable data\n    # settings: UserSettings  # Eigenes frozen dataclass\n</code></pre>"},{"location":"guide/commands-events/#message-flow","title":"Message Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Client    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502 publish(Command)\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   MessageBus     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502 route to handler\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 CommandHandler   \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  Aggregate  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                         \u2502\n       \u2502                         \u2502 emit Events\n       \u2502                         \u25bc\n       \u2502                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                  \u2502 OrderCreated \u2502\n       \u2502                  \u2502 ItemAdded    \u2502\n       \u2502                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                         \u2502\n       \u2502 save &amp; publish          \u2502\n       \u25bc                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502   EventStore     \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502 publish Events\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Event Handlers         \u2502\n\u2502   - EmailService         \u2502\n\u2502   - Analytics            \u2502\n\u2502   - InventoryService     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guide/commands-events/#best-practices","title":"Best Practices","text":""},{"location":"guide/commands-events/#commands_1","title":"Commands","text":"<pre><code># \u2705 Spezifisch und klar\n@dataclass(frozen=True, kw_only=True)\nclass CancelOrder(Command):\n    order_id: str\n    cancellation_reason: str\n    refund_method: str\n\n# \u2705 Validation im Command\n@dataclass(frozen=True, kw_only=True)\nclass UpdatePrice(Command):\n    product_id: str\n    new_price: float\n\n    def __post_init__(self) -&gt; None:\n        if self.new_price &lt; 0:\n            raise ValueError(\"Price cannot be negative\")\n\n# \u274c Zu generisch\n@dataclass(frozen=True, kw_only=True)\nclass OrderCommand(Command):\n    action: str  # \"create\" | \"cancel\" | \"update\"\n    data: dict   # Untyped!\n</code></pre>"},{"location":"guide/commands-events/#events_1","title":"Events","text":"<pre><code># \u2705 Reich an Information\n@dataclass(frozen=True, kw_only=True)\nclass OrderShipped(Event):\n    order_id: str\n    tracking_number: str\n    carrier: str\n    estimated_delivery: str\n    shipped_at: str\n\n# \u2705 Mehrere kleine Events statt eines gro\u00dfen\n@dataclass(frozen=True, kw_only=True)\nclass OrderPlaced(Event):\n    order_id: str\n    ...\n\n@dataclass(frozen=True, kw_only=True)\nclass PaymentReceived(Event):\n    order_id: str\n    payment_id: str\n    ...\n\n# \u274c Zu wenig Information\n@dataclass(frozen=True, kw_only=True)\nclass OrderUpdated(Event):\n    order_id: str\n    # Was wurde updated? Wann? Von wem?\n</code></pre>"},{"location":"guide/commands-events/#event-versioning","title":"Event Versioning","text":"<p>Events m\u00fcssen backward-compatible bleiben:</p> <pre><code># Version 1\n@dataclass(frozen=True, kw_only=True)\nclass UserCreated(Event):\n    user_id: str\n    email: str\n\n# Version 2 - \u2705 Backward compatible\n@dataclass(frozen=True, kw_only=True)\nclass UserCreated(Event):\n    user_id: str\n    email: str\n    username: str = \"\"  # Default f\u00fcr alte Events\n    created_at: str = \"\"\n\n# Version 2 - \u274c BREAKING CHANGE\n@dataclass(frozen=True, kw_only=True)\nclass UserCreated(Event):\n    user_id: str\n    username: str  # email entfernt - bricht alte Events!\n</code></pre>"},{"location":"guide/commands-events/#practical-example","title":"Practical Example","text":"<pre><code># Commands\n@dataclass(frozen=True, kw_only=True)\nclass PlaceOrder(Command):\n    order_id: str\n    customer_id: str\n    items: list[dict]\n\n@dataclass(frozen=True, kw_only=True)\nclass PayOrder(Command):\n    order_id: str\n    payment_method: str\n    amount: float\n\n@dataclass(frozen=True, kw_only=True)\nclass ShipOrder(Command):\n    order_id: str\n    carrier: str\n\n# Events\n@dataclass(frozen=True, kw_only=True)\nclass OrderPlaced(Event):\n    order_id: str\n    customer_id: str\n    total_amount: float\n\n@dataclass(frozen=True, kw_only=True)\nclass OrderPaid(Event):\n    order_id: str\n    payment_id: str\n    amount: float\n\n@dataclass(frozen=True, kw_only=True)\nclass OrderShipped(Event):\n    order_id: str\n    tracking_number: str\n    carrier: str\n\n# Flow\nbus.publish(PlaceOrder(...))  # \u2192 OrderPlaced\nbus.publish(PayOrder(...))    # \u2192 OrderPaid\nbus.publish(ShipOrder(...))   # \u2192 OrderShipped\n</code></pre>"},{"location":"guide/commands-events/#next-steps","title":"Next Steps","text":"<ul> <li>Message Bus - Routing &amp; Subscription</li> <li>Event Store - Persistence Patterns</li> <li>Best Practices - Production Guidelines</li> </ul>"},{"location":"guide/creating-modules/","title":"Creating Modules","text":"<p>Modules sind das Herzst\u00fcck von Orchestrix. Sie kapseln Domain-Logik und registrieren Handler beim Message Bus.</p>"},{"location":"guide/creating-modules/#was-ist-ein-module","title":"Was ist ein Module?","text":"<p>Ein Module ist eine Sammlung von:</p> <ul> <li>Commands und Events (Domain Messages)</li> <li>Aggregates (Domain Models)</li> <li>Command Handlers (Business Logic)</li> <li>Event Handlers (Projections, Side Effects)</li> </ul>"},{"location":"guide/creating-modules/#basic-module-structure","title":"Basic Module Structure","text":"<pre><code>from orchestrix import Module, MessageBus, EventStore\n\nclass OrderModule(Module):\n    \"\"\"Order management domain module.\"\"\"\n\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        \"\"\"Register all handlers with infrastructure.\"\"\"\n        # Command handlers\n        bus.subscribe(CreateOrder, CreateOrderHandler(bus, store))\n        bus.subscribe(CancelOrder, CancelOrderHandler(bus, store))\n        bus.subscribe(ShipOrder, ShipOrderHandler(bus, store))\n\n        # Event handlers\n        bus.subscribe(OrderCreated, self._send_confirmation_email)\n        bus.subscribe(OrderShipped, self._update_inventory)\n        bus.subscribe(OrderCancelled, self._process_refund)\n\n    def _send_confirmation_email(self, event: OrderCreated) -&gt; None:\n        \"\"\"Send order confirmation email.\"\"\"\n        print(f\"\ud83d\udce7 Sending confirmation email for order {event.order_id}\")\n\n    def _update_inventory(self, event: OrderShipped) -&gt; None:\n        \"\"\"Update inventory after shipping.\"\"\"\n        print(f\"\ud83d\udce6 Updating inventory for order {event.order_id}\")\n\n    def _process_refund(self, event: OrderCancelled) -&gt; None:\n        \"\"\"Process refund for cancelled order.\"\"\"\n        print(f\"\ud83d\udcb0 Processing refund for order {event.order_id}\")\n</code></pre>"},{"location":"guide/creating-modules/#module-organization","title":"Module Organization","text":""},{"location":"guide/creating-modules/#1-file-structure","title":"1. File Structure","text":"<p>Empfohlene Struktur f\u00fcr gr\u00f6\u00dfere Projekte:</p> <pre><code>my_app/\n\u251c\u2500\u2500 domains/\n\u2502   \u251c\u2500\u2500 orders/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 module.py          # OrderModule\n\u2502   \u2502   \u251c\u2500\u2500 messages.py        # Commands &amp; Events\n\u2502   \u2502   \u251c\u2500\u2500 aggregates.py      # Order aggregate\n\u2502   \u2502   \u2514\u2500\u2500 handlers.py        # Command/Event handlers\n\u2502   \u251c\u2500\u2500 inventory/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 module.py\n\u2502   \u2502   \u251c\u2500\u2500 messages.py\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 shipping/\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 main.py                    # Application setup\n</code></pre>"},{"location":"guide/creating-modules/#2-separate-messages","title":"2. Separate Messages","text":"<pre><code># domains/orders/messages.py\nfrom dataclasses import dataclass\nfrom orchestrix import Command, Event\n\n@dataclass(frozen=True, kw_only=True)\nclass CreateOrder(Command):\n    order_id: str\n    customer_id: str\n    items: list[dict]\n\n@dataclass(frozen=True, kw_only=True)\nclass OrderCreated(Event):\n    order_id: str\n    customer_id: str\n    total_amount: float\n</code></pre>"},{"location":"guide/creating-modules/#3-separate-handlers","title":"3. Separate Handlers","text":"<pre><code># domains/orders/handlers.py\nfrom orchestrix import CommandHandler, MessageBus, EventStore\n\nclass CreateOrderHandler(CommandHandler[CreateOrder]):\n    def __init__(self, bus: MessageBus, store: EventStore) -&gt; None:\n        self.bus = bus\n        self.store = store\n\n    def handle(self, command: CreateOrder) -&gt; None:\n        # Implementation\n        pass\n</code></pre>"},{"location":"guide/creating-modules/#4-module-definition","title":"4. Module Definition","text":"<pre><code># domains/orders/module.py\nfrom orchestrix import Module, MessageBus, EventStore\nfrom .messages import CreateOrder, OrderCreated\nfrom .handlers import CreateOrderHandler\n\nclass OrderModule(Module):\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        bus.subscribe(CreateOrder, CreateOrderHandler(bus, store))\n</code></pre>"},{"location":"guide/creating-modules/#cross-module-communication","title":"Cross-Module Communication","text":"<p>Module kommunizieren nur \u00fcber Events (nie direkt):</p> <pre><code># \u2705 Gut: Event-basierte Kommunikation\nclass OrderModule(Module):\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        bus.subscribe(OrderCreated, CreateOrderHandler(bus, store))\n\nclass InventoryModule(Module):\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        # Reagiert auf OrderCreated Event\n        bus.subscribe(OrderCreated, self._reserve_inventory)\n\n    def _reserve_inventory(self, event: OrderCreated) -&gt; None:\n        # Reserve inventory when order is created\n        pass\n\nclass ShippingModule(Module):\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        # Reagiert auch auf OrderCreated Event\n        bus.subscribe(OrderCreated, self._calculate_shipping)\n\n    def _calculate_shipping(self, event: OrderCreated) -&gt; None:\n        # Calculate shipping costs\n        pass\n</code></pre>"},{"location":"guide/creating-modules/#module-testing","title":"Module Testing","text":"<pre><code>import pytest\nfrom orchestrix import InMemoryMessageBus, InMemoryEventStore\n\ndef test_order_module():\n    # Arrange\n    bus = InMemoryMessageBus()\n    store = InMemoryEventStore()\n    module = OrderModule()\n    module.register(bus, store)\n\n    # Act\n    bus.publish(CreateOrder(\n        order_id=\"ORD-001\",\n        customer_id=\"CUST-123\",\n        items=[{\"sku\": \"ITEM-1\", \"qty\": 2}]\n    ))\n\n    # Assert\n    events = store.load(\"ORD-001\")\n    assert len(events) == 1\n    assert isinstance(events[0], OrderCreated)\n</code></pre>"},{"location":"guide/creating-modules/#best-practices","title":"Best Practices","text":""},{"location":"guide/creating-modules/#do","title":"\u2705 DO","text":"<ul> <li>Kleine, fokussierte Module - Ein Module = Eine Domain</li> <li>Event-basierte Kommunikation - Module wissen nichts voneinander</li> <li>Klare Grenzen - Jedes Module hat eigene Messages</li> <li>Unabh\u00e4ngige Tests - Module einzeln testbar</li> </ul>"},{"location":"guide/creating-modules/#dont","title":"\u274c DON'T","text":"<ul> <li>Keine direkten Abh\u00e4ngigkeiten zwischen Modules</li> <li>Keine geteilten Aggregates zwischen Modules</li> <li>Keine Commands zwischen Modules - nur Events</li> <li>Keine zirkul\u00e4ren Imports zwischen Modules</li> </ul>"},{"location":"guide/creating-modules/#module-lifecycle","title":"Module Lifecycle","text":"<pre><code># 1. Create infrastructure\nbus = InMemoryMessageBus()\nstore = InMemoryEventStore()\n\n# 2. Register modules (Reihenfolge egal!)\nOrderModule().register(bus, store)\nInventoryModule().register(bus, store)\nShippingModule().register(bus, store)\nPaymentModule().register(bus, store)\n\n# 3. Start publishing commands\nbus.publish(CreateOrder(...))\n</code></pre>"},{"location":"guide/creating-modules/#advanced-module-dependencies","title":"Advanced: Module Dependencies","text":"<p>Wenn ein Module externe Services braucht:</p> <pre><code>class NotificationModule(Module):\n    def __init__(self, email_service: EmailService, sms_service: SmsService):\n        self.email_service = email_service\n        self.sms_service = sms_service\n\n    def register(self, bus: MessageBus, store: EventStore) -&gt; None:\n        bus.subscribe(OrderCreated, self._send_notifications)\n\n    def _send_notifications(self, event: OrderCreated) -&gt; None:\n        self.email_service.send(event.customer_email, \"Order confirmed!\")\n        self.sms_service.send(event.customer_phone, \"Order confirmed!\")\n\n# Setup\nemail_service = EmailService(config)\nsms_service = SmsService(config)\nNotificationModule(email_service, sms_service).register(bus, store)\n</code></pre>"},{"location":"guide/creating-modules/#next-steps","title":"Next Steps","text":"<ul> <li>Commands &amp; Events - Message Design Guidelines</li> <li>Message Bus - Bus Patterns</li> <li>Best Practices - Production Tips</li> </ul>"},{"location":"guide/event-store/","title":"Event Store","text":"<p>Der Event Store speichert alle Events eines Aggregates - die \"Source of Truth\" f\u00fcr Event Sourcing.</p>"},{"location":"guide/event-store/#was-ist-ein-event-store","title":"Was ist ein Event Store?","text":"<p>Ein Event Store:</p> <ul> <li>Speichert Events pro Aggregate</li> <li>L\u00e4dt Events in chronologischer Reihenfolge</li> <li>Erm\u00f6glicht Aggregate Reconstruction</li> <li>Ist append-only (keine Updates/Deletes!)</li> </ul>"},{"location":"guide/event-store/#basic-usage","title":"Basic Usage","text":"<pre><code>from orchestrix import InMemoryEventStore\n\n# Create store\nstore = InMemoryEventStore()\n\n# Save events\nevents = [\n    OrderCreated(order_id=\"ORD-001\", ...),\n    ItemAdded(order_id=\"ORD-001\", ...),\n    OrderPaid(order_id=\"ORD-001\", ...)\n]\nstore.save(\"ORD-001\", events)\n\n# Load events\nall_events = store.load(\"ORD-001\")\n# \u2192 [OrderCreated, ItemAdded, OrderPaid]\n</code></pre>"},{"location":"guide/event-store/#inmemoryeventstore","title":"InMemoryEventStore","text":"<p>Die Standard-Implementierung f\u00fcr Development &amp; Testing:</p> <pre><code>from collections import defaultdict\nfrom orchestrix import EventStore, Event\n\nclass InMemoryEventStore(EventStore):\n    \"\"\"In-memory event store using defaultdict.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self._events: dict[str, list[Event]] = defaultdict(list)\n\n    def save(self, aggregate_id: str, events: list[Event]) -&gt; None:\n        \"\"\"Append events to aggregate stream.\"\"\"\n        self._events[aggregate_id].extend(events)\n\n    def load(self, aggregate_id: str) -&gt; list[Event]:\n        \"\"\"Load all events for aggregate.\"\"\"\n        return list(self._events[aggregate_id])\n</code></pre>"},{"location":"guide/event-store/#features","title":"Features","text":"<ul> <li>\u2705 Append-only - Events werden nur hinzugef\u00fcgt</li> <li>\u2705 Chronologisch - Events in Reihenfolge</li> <li>\u2705 Einfach - Keine Dependencies</li> <li>\u26a0\ufe0f In-Memory - Daten gehen bei Restart verloren</li> </ul>"},{"location":"guide/event-store/#event-sourcing-pattern","title":"Event Sourcing Pattern","text":""},{"location":"guide/event-store/#1-command-events","title":"1. Command \u2192 Events","text":"<p>Command Handler erstellt Aggregate und sammelt Events:</p> <pre><code>class CreateOrderHandler(CommandHandler[CreateOrder]):\n    def handle(self, command: CreateOrder) -&gt; None:\n        # Create aggregate\n        order = Order.create(\n            order_id=command.order_id,\n            customer_id=command.customer_id,\n            items=command.items\n        )\n\n        # Collect emitted events\n        events = order.collect_events()\n        # \u2192 [OrderCreated, ItemAdded, ItemAdded, ...]\n\n        # Save to event store\n        self.store.save(command.order_id, events)\n\n        # Publish to bus\n        for event in events:\n            self.bus.publish(event)\n</code></pre>"},{"location":"guide/event-store/#2-aggregate-reconstruction","title":"2. Aggregate Reconstruction","text":"<p>Lade Aggregate aus Event Stream:</p> <pre><code>class CancelOrderHandler(CommandHandler[CancelOrder]):\n    def handle(self, command: CancelOrder) -&gt; None:\n        # Load all events for aggregate\n        events = self.store.load(command.order_id)\n\n        # Reconstruct aggregate from events\n        order = self._reconstruct_order(events)\n\n        # Execute business logic\n        order.cancel()\n\n        # Save new events\n        new_events = order.collect_events()\n        self.store.save(command.order_id, new_events)\n\n        for event in new_events:\n            self.bus.publish(event)\n\n    def _reconstruct_order(self, events: list[Event]) -&gt; Order:\n        \"\"\"Replay events to rebuild aggregate state.\"\"\"\n        order = None\n\n        for event in events:\n            if isinstance(event, OrderCreated):\n                order = Order(\n                    order_id=event.order_id,\n                    customer_id=event.customer_id,\n                    status=\"pending\"\n                )\n            elif isinstance(event, ItemAdded):\n                order.items.append(event.item)\n            elif isinstance(event, OrderPaid):\n                order.status = \"paid\"\n            elif isinstance(event, OrderShipped):\n                order.status = \"shipped\"\n\n        return order\n</code></pre>"},{"location":"guide/event-store/#3-complete-example","title":"3. Complete Example","text":"<pre><code>from dataclasses import dataclass, field\n\n@dataclass\nclass Order:\n    \"\"\"Order aggregate root.\"\"\"\n    order_id: str\n    customer_id: str\n    items: list = field(default_factory=list)\n    status: str = \"draft\"\n    _events: list[Event] = field(default_factory=list, repr=False)\n\n    @classmethod\n    def create(cls, order_id: str, customer_id: str, items: list):\n        \"\"\"Create new order.\"\"\"\n        order = cls(order_id=order_id, customer_id=customer_id)\n        order._events.append(OrderCreated(\n            order_id=order_id,\n            customer_id=customer_id\n        ))\n        for item in items:\n            order.add_item(item)\n        return order\n\n    def add_item(self, item: dict) -&gt; None:\n        \"\"\"Add item to order.\"\"\"\n        self.items.append(item)\n        self._events.append(ItemAdded(\n            order_id=self.order_id,\n            item=item\n        ))\n\n    def cancel(self) -&gt; None:\n        \"\"\"Cancel order.\"\"\"\n        if self.status == \"shipped\":\n            raise ValueError(\"Cannot cancel shipped order\")\n        self.status = \"cancelled\"\n        self._events.append(OrderCancelled(\n            order_id=self.order_id\n        ))\n\n    def collect_events(self) -&gt; list[Event]:\n        \"\"\"Get and clear pending events.\"\"\"\n        events = self._events.copy()\n        self._events.clear()\n        return events\n\n    @classmethod\n    def from_events(cls, events: list[Event]) -&gt; \"Order\":\n        \"\"\"Reconstruct from event stream.\"\"\"\n        order = None\n        for event in events:\n            if isinstance(event, OrderCreated):\n                order = cls(\n                    order_id=event.order_id,\n                    customer_id=event.customer_id\n                )\n            elif isinstance(event, ItemAdded):\n                order.items.append(event.item)\n            elif isinstance(event, OrderCancelled):\n                order.status = \"cancelled\"\n        return order\n</code></pre>"},{"location":"guide/event-store/#event-store-benefits","title":"Event Store Benefits","text":""},{"location":"guide/event-store/#1-complete-audit-trail","title":"1. Complete Audit Trail","text":"<pre><code># Jedes Event ist dokumentiert\nevents = store.load(\"ORD-001\")\nfor event in events:\n    print(f\"{event.timestamp}: {event.type}\")\n\n# Output:\n# 2026-01-03T10:00:00: OrderCreated\n# 2026-01-03T10:01:00: ItemAdded\n# 2026-01-03T10:02:00: ItemAdded\n# 2026-01-03T10:05:00: OrderPaid\n# 2026-01-03T10:30:00: OrderShipped\n</code></pre>"},{"location":"guide/event-store/#2-time-travel","title":"2. Time Travel","text":"<pre><code>def get_order_at_time(order_id: str, timestamp: str) -&gt; Order:\n    \"\"\"Get order state at specific point in time.\"\"\"\n    events = store.load(order_id)\n\n    # Filter events up to timestamp\n    past_events = [\n        e for e in events\n        if e.timestamp &lt;= timestamp\n    ]\n\n    return Order.from_events(past_events)\n\n# Was the state at 10:03?\norder = get_order_at_time(\"ORD-001\", \"2026-01-03T10:03:00\")\nprint(order.status)  # \u2192 \"pending\" (before payment)\n</code></pre>"},{"location":"guide/event-store/#3-event-replay","title":"3. Event Replay","text":"<pre><code>def replay_all_events(store: EventStore, bus: MessageBus):\n    \"\"\"Replay all events (rebuild projections).\"\"\"\n    for aggregate_id in store.get_all_aggregate_ids():\n        events = store.load(aggregate_id)\n        for event in events:\n            bus.publish(event)\n</code></pre>"},{"location":"guide/event-store/#4-debugging","title":"4. Debugging","text":"<pre><code># Debug: What happened to this order?\nevents = store.load(\"ORD-123\")\nfor i, event in enumerate(events, 1):\n    print(f\"{i}. {event.__class__.__name__}\")\n    print(f\"   Time: {event.timestamp}\")\n    print(f\"   Data: {event}\")\n</code></pre>"},{"location":"guide/event-store/#persistence-strategies","title":"Persistence Strategies","text":""},{"location":"guide/event-store/#strategy-1-json-file-store","title":"Strategy 1: JSON File Store","text":"<pre><code>import json\nfrom pathlib import Path\n\nclass FileEventStore(EventStore):\n    \"\"\"Event store using JSON files.\"\"\"\n\n    def __init__(self, base_path: str = \"./events\"):\n        self.base_path = Path(base_path)\n        self.base_path.mkdir(exist_ok=True)\n\n    def save(self, aggregate_id: str, events: list[Event]) -&gt; None:\n        file_path = self.base_path / f\"{aggregate_id}.jsonl\"\n\n        with file_path.open(\"a\") as f:\n            for event in events:\n                json_event = {\n                    \"type\": event.__class__.__name__,\n                    \"data\": asdict(event)\n                }\n                f.write(json.dumps(json_event) + \"\\n\")\n\n    def load(self, aggregate_id: str) -&gt; list[Event]:\n        file_path = self.base_path / f\"{aggregate_id}.jsonl\"\n\n        if not file_path.exists():\n            return []\n\n        events = []\n        with file_path.open(\"r\") as f:\n            for line in f:\n                json_event = json.loads(line)\n                # Deserialize event\n                event_class = globals()[json_event[\"type\"]]\n                events.append(event_class(**json_event[\"data\"]))\n\n        return events\n</code></pre>"},{"location":"guide/event-store/#strategy-2-sqlite-store","title":"Strategy 2: SQLite Store","text":"<pre><code>import sqlite3\nimport json\n\nclass SQLiteEventStore(EventStore):\n    \"\"\"Event store using SQLite.\"\"\"\n\n    def __init__(self, db_path: str = \"events.db\"):\n        self.conn = sqlite3.connect(db_path)\n        self._create_table()\n\n    def _create_table(self):\n        self.conn.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS events (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                aggregate_id TEXT NOT NULL,\n                event_type TEXT NOT NULL,\n                event_data TEXT NOT NULL,\n                timestamp TEXT NOT NULL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        \"\"\")\n        self.conn.commit()\n\n    def save(self, aggregate_id: str, events: list[Event]) -&gt; None:\n        for event in events:\n            self.conn.execute(\"\"\"\n                INSERT INTO events (aggregate_id, event_type, event_data, timestamp)\n                VALUES (?, ?, ?, ?)\n            \"\"\", (\n                aggregate_id,\n                event.__class__.__name__,\n                json.dumps(asdict(event)),\n                event.timestamp\n            ))\n        self.conn.commit()\n\n    def load(self, aggregate_id: str) -&gt; list[Event]:\n        cursor = self.conn.execute(\"\"\"\n            SELECT event_type, event_data\n            FROM events\n            WHERE aggregate_id = ?\n            ORDER BY id ASC\n        \"\"\", (aggregate_id,))\n\n        events = []\n        for event_type, event_data in cursor:\n            event_class = globals()[event_type]\n            events.append(event_class(**json.loads(event_data)))\n\n        return events\n</code></pre>"},{"location":"guide/event-store/#strategy-3-postgresql-store-production","title":"Strategy 3: PostgreSQL Store (Production)","text":"<pre><code>import psycopg2\nfrom psycopg2.extras import Json\n\nclass PostgreSQLEventStore(EventStore):\n    \"\"\"Production-grade PostgreSQL event store.\"\"\"\n\n    def __init__(self, connection_string: str):\n        self.conn = psycopg2.connect(connection_string)\n        self._create_table()\n\n    def _create_table(self):\n        with self.conn.cursor() as cur:\n            cur.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS events (\n                    id BIGSERIAL PRIMARY KEY,\n                    aggregate_id TEXT NOT NULL,\n                    version INTEGER NOT NULL,\n                    event_type TEXT NOT NULL,\n                    event_data JSONB NOT NULL,\n                    timestamp TIMESTAMPTZ NOT NULL,\n                    created_at TIMESTAMPTZ DEFAULT NOW(),\n                    UNIQUE(aggregate_id, version)\n                )\n            \"\"\")\n            cur.execute(\"\"\"\n                CREATE INDEX IF NOT EXISTS idx_events_aggregate_id\n                ON events(aggregate_id)\n            \"\"\")\n        self.conn.commit()\n</code></pre>"},{"location":"guide/event-store/#best-practices","title":"Best Practices","text":""},{"location":"guide/event-store/#do","title":"\u2705 DO","text":"<ul> <li>Append-Only - Niemals Events l\u00f6schen oder \u00e4ndern</li> <li>Immutable Events - Events sind unver\u00e4nderlich</li> <li>Versionierung - Track Event Version f\u00fcr Optimistic Locking</li> <li>Snapshots - F\u00fcr lange Event Streams (&gt;1000 Events)</li> </ul>"},{"location":"guide/event-store/#dont","title":"\u274c DON'T","text":"<ul> <li>Keine Updates - Events werden nie ge\u00e4ndert</li> <li>Keine Deletes - Events werden nie gel\u00f6scht</li> <li>Keine Sensitive Data - PII geh\u00f6rt nicht in Events</li> <li>Keine gro\u00dfen Payloads - Referenzen statt gro\u00dfe Objekte</li> </ul>"},{"location":"guide/event-store/#next-steps","title":"Next Steps","text":"<ul> <li>Best Practices - Production Guidelines</li> <li>Testing - Test Strategies</li> <li>Architecture - System Design</li> </ul>"},{"location":"guide/message-bus/","title":"Message Bus","text":"<p>Der Message Bus ist das Herzst\u00fcck der Event-Driven Architecture - er routet alle Messages zu ihren Handlers.</p>"},{"location":"guide/message-bus/#was-ist-ein-message-bus","title":"Was ist ein Message Bus?","text":"<p>Ein Message Bus:</p> <ul> <li>Nimmt Messages entgegen (Commands &amp; Events)</li> <li>Routet sie zu registrierten Handlers</li> <li>Entkoppelt Publisher von Subscribern</li> <li>Erm\u00f6glicht 1-zu-N Kommunikation</li> </ul>"},{"location":"guide/message-bus/#basic-usage","title":"Basic Usage","text":"<pre><code>from orchestrix import InMemoryMessageBus, Command, Event\n\n# Create bus\nbus = InMemoryMessageBus()\n\n# Subscribe handlers\nbus.subscribe(CreateOrder, create_order_handler)\nbus.subscribe(OrderCreated, send_email_handler)\nbus.subscribe(OrderCreated, update_inventory_handler)\n\n# Publish messages\nbus.publish(CreateOrder(order_id=\"ORD-001\", ...))\n</code></pre>"},{"location":"guide/message-bus/#inmemorymessagebus","title":"InMemoryMessageBus","text":"<p>Der <code>InMemoryMessageBus</code> ist die Standard-Implementierung - perfekt f\u00fcr:</p> <ul> <li>\u2705 Entwicklung &amp; Testing</li> <li>\u2705 Einfache Applikationen</li> <li>\u2705 Monolithen</li> <li>\u2705 Schnelle Prototypen</li> </ul> <pre><code>from orchestrix import InMemoryMessageBus\n\nbus = InMemoryMessageBus()\n\n# Subscribe: Message Type \u2192 Handler\nbus.subscribe(CreateOrder, create_order_handler)\n\n# Publish: Alle Handler werden synchron aufgerufen\nbus.publish(CreateOrder(order_id=\"ORD-001\", ...))\n</code></pre>"},{"location":"guide/message-bus/#wie-es-funktioniert","title":"Wie es funktioniert","text":"<pre><code>from collections import defaultdict\nfrom orchestrix import Message, MessageBus\n\nclass InMemoryMessageBus(MessageBus):\n    def __init__(self) -&gt; None:\n        self._handlers: dict[type[Message], list] = defaultdict(list)\n\n    def subscribe(self, message_type: type[Message], handler) -&gt; None:\n        \"\"\"Register a handler for a message type.\"\"\"\n        self._handlers[message_type].append(handler)\n\n    def publish(self, message: Message) -&gt; None:\n        \"\"\"Publish to all registered handlers.\"\"\"\n        for handler in self._handlers[type(message)]:\n            if callable(handler):\n                handler(message)\n            elif hasattr(handler, \"handle\"):\n                handler.handle(message)\n</code></pre>"},{"location":"guide/message-bus/#handler-types","title":"Handler Types","text":""},{"location":"guide/message-bus/#1-function-handler","title":"1. Function Handler","text":"<pre><code>def handle_order_created(event: OrderCreated) -&gt; None:\n    print(f\"Order {event.order_id} created!\")\n\nbus.subscribe(OrderCreated, handle_order_created)\n</code></pre>"},{"location":"guide/message-bus/#2-lambda-handler","title":"2. Lambda Handler","text":"<pre><code>bus.subscribe(\n    OrderCreated,\n    lambda e: print(f\"Order {e.order_id} created!\")\n)\n</code></pre>"},{"location":"guide/message-bus/#3-class-based-handler","title":"3. Class-based Handler","text":"<pre><code>from orchestrix import CommandHandler\n\nclass CreateOrderHandler(CommandHandler[CreateOrder]):\n    def __init__(self, bus: MessageBus, store: EventStore):\n        self.bus = bus\n        self.store = store\n\n    def handle(self, command: CreateOrder) -&gt; None:\n        # Business logic here\n        order = Order.create(command.order_id, ...)\n        events = order.collect_events()\n        self.store.save(command.order_id, events)\n        for event in events:\n            self.bus.publish(event)\n\nbus.subscribe(CreateOrder, CreateOrderHandler(bus, store))\n</code></pre>"},{"location":"guide/message-bus/#4-method-handler","title":"4. Method Handler","text":"<pre><code>class OrderService:\n    def __init__(self, db):\n        self.db = db\n\n    def on_order_created(self, event: OrderCreated) -&gt; None:\n        self.db.save_order(event)\n\nservice = OrderService(db)\nbus.subscribe(OrderCreated, service.on_order_created)\n</code></pre>"},{"location":"guide/message-bus/#subscription-patterns","title":"Subscription Patterns","text":""},{"location":"guide/message-bus/#one-handler-per-command","title":"One Handler per Command","text":"<p>Commands sollten genau einen Handler haben:</p> <pre><code># \u2705 Gut: 1 Command \u2192 1 Handler\nbus.subscribe(CreateOrder, CreateOrderHandler(bus, store))\nbus.subscribe(CancelOrder, CancelOrderHandler(bus, store))\n\n# \u274c Vermeiden: Multiple Handler f\u00fcr Commands\nbus.subscribe(CreateOrder, handler1)\nbus.subscribe(CreateOrder, handler2)  # Wer ist verantwortlich?\n</code></pre>"},{"location":"guide/message-bus/#multiple-handlers-per-event","title":"Multiple Handlers per Event","text":"<p>Events k\u00f6nnen mehrere Handler haben:</p> <pre><code># \u2705 Gut: 1 Event \u2192 N Handler\nbus.subscribe(OrderCreated, send_confirmation_email)\nbus.subscribe(OrderCreated, update_inventory)\nbus.subscribe(OrderCreated, send_to_analytics)\nbus.subscribe(OrderCreated, notify_warehouse)\n</code></pre>"},{"location":"guide/message-bus/#error-handling","title":"Error Handling","text":""},{"location":"guide/message-bus/#current-behavior","title":"Current Behavior","text":"<p>Der <code>InMemoryMessageBus</code> hat keine eingebaute Error Handling:</p> <pre><code>def failing_handler(event: OrderCreated) -&gt; None:\n    raise ValueError(\"Something went wrong!\")\n\nbus.subscribe(OrderCreated, failing_handler)\nbus.subscribe(OrderCreated, working_handler)  # Wird nicht aufgerufen!\n\nbus.publish(OrderCreated(...))  # Raises ValueError\n</code></pre>"},{"location":"guide/message-bus/#robust-handler-pattern","title":"Robust Handler Pattern","text":"<p>Wrap deine Handler f\u00fcr besseres Error Handling:</p> <pre><code>def safe_handler(handler):\n    \"\"\"Decorator f\u00fcr safe handlers.\"\"\"\n    def wrapper(message):\n        try:\n            return handler(message)\n        except Exception as e:\n            print(f\"\u274c Error in handler: {e}\")\n            # Log to monitoring system\n            # Send to dead letter queue\n    return wrapper\n\n@safe_handler\ndef send_email(event: OrderCreated) -&gt; None:\n    # Can fail without breaking other handlers\n    email_service.send(...)\n\nbus.subscribe(OrderCreated, send_email)\n</code></pre>"},{"location":"guide/message-bus/#testing-with-message-bus","title":"Testing with Message Bus","text":"<pre><code>import pytest\nfrom orchestrix import InMemoryMessageBus\n\ndef test_order_creation():\n    # Arrange\n    bus = InMemoryMessageBus()\n    events_received = []\n\n    bus.subscribe(OrderCreated, lambda e: events_received.append(e))\n\n    # Act\n    bus.publish(OrderCreated(order_id=\"ORD-001\", ...))\n\n    # Assert\n    assert len(events_received) == 1\n    assert events_received[0].order_id == \"ORD-001\"\n</code></pre>"},{"location":"guide/message-bus/#test-spy-pattern","title":"Test Spy Pattern","text":"<pre><code>class MessageSpy:\n    \"\"\"Collect all published messages for testing.\"\"\"\n\n    def __init__(self):\n        self.messages = []\n\n    def record(self, message):\n        self.messages.append(message)\n\n    def get_by_type(self, message_type):\n        return [m for m in self.messages if isinstance(m, message_type)]\n\n# Usage in tests\nspy = MessageSpy()\nbus.subscribe(OrderCreated, spy.record)\nbus.subscribe(OrderShipped, spy.record)\n\n# ... run test code ...\n\ncreated_events = spy.get_by_type(OrderCreated)\nassert len(created_events) == 1\n</code></pre>"},{"location":"guide/message-bus/#advanced-custom-bus-implementation","title":"Advanced: Custom Bus Implementation","text":"<p>Du kannst eigene Bus-Implementierungen erstellen:</p> <pre><code>from orchestrix import MessageBus, Message\n\nclass AsyncMessageBus(MessageBus):\n    \"\"\"Async message bus using asyncio.\"\"\"\n\n    def __init__(self):\n        self._handlers = defaultdict(list)\n\n    def subscribe(self, message_type: type[Message], handler) -&gt; None:\n        self._handlers[message_type].append(handler)\n\n    async def publish_async(self, message: Message) -&gt; None:\n        \"\"\"Publish message asynchronously.\"\"\"\n        tasks = []\n        for handler in self._handlers[type(message)]:\n            if asyncio.iscoroutinefunction(handler):\n                tasks.append(handler(message))\n            else:\n                tasks.append(asyncio.to_thread(handler, message))\n\n        await asyncio.gather(*tasks, return_exceptions=True)\n</code></pre>"},{"location":"guide/message-bus/#future-alternative-buses","title":"Future: Alternative Buses","text":"<p>Orchestrix ist designed f\u00fcr pluggable Buses:</p>"},{"location":"guide/message-bus/#redis-message-bus","title":"Redis Message Bus","text":"<pre><code>class RedisMessageBus(MessageBus):\n    \"\"\"Distributed message bus using Redis Pub/Sub.\"\"\"\n\n    def __init__(self, redis_url: str):\n        self.redis = redis.from_url(redis_url)\n        self._handlers = defaultdict(list)\n\n    def subscribe(self, message_type, handler):\n        channel = message_type.__name__\n        self._handlers[channel].append(handler)\n        # Subscribe to Redis channel\n        pubsub = self.redis.pubsub()\n        pubsub.subscribe(channel)\n\n    def publish(self, message: Message):\n        channel = type(message).__name__\n        # Serialize and publish to Redis\n        self.redis.publish(channel, serialize(message))\n</code></pre>"},{"location":"guide/message-bus/#rabbitmq-message-bus","title":"RabbitMQ Message Bus","text":"<pre><code>class RabbitMQMessageBus(MessageBus):\n    \"\"\"Enterprise message bus using RabbitMQ.\"\"\"\n\n    def __init__(self, connection_string: str):\n        self.connection = pika.BlockingConnection(\n            pika.URLParameters(connection_string)\n        )\n        self.channel = self.connection.channel()\n</code></pre>"},{"location":"guide/message-bus/#best-practices","title":"Best Practices","text":""},{"location":"guide/message-bus/#do","title":"\u2705 DO","text":"<ul> <li>Synchrone Handler f\u00fcr kritische Business Logic</li> <li>Idempotente Handler - k\u00f6nnen mehrfach aufgerufen werden</li> <li>Kleine Handler - Single Responsibility</li> <li>Error Handling - Wrapper f\u00fcr robuste Handler</li> </ul>"},{"location":"guide/message-bus/#dont","title":"\u274c DON'T","text":"<ul> <li>Lange laufende Tasks im Handler - use async/queue</li> <li>Handler mit Side Effects ohne Error Handling</li> <li>Multiple Command Handlers - unclear responsibility</li> <li>Handler die auf Handler warten - Deadlock Risk</li> </ul>"},{"location":"guide/message-bus/#next-steps","title":"Next Steps","text":"<ul> <li>Event Store - Persistence Patterns</li> <li>Best Practices - Production Guidelines</li> <li>Testing - Test Strategies</li> </ul>"},{"location":"guide/production-deployment/","title":"Production Deployment Guide","text":"<p>Complete guide for deploying Orchestrix applications from development to large-scale production.</p>"},{"location":"guide/production-deployment/#overview","title":"Overview","text":"<p>This guide helps you choose the right deployment architecture based on your project scale, event volume, and operational requirements.</p>"},{"location":"guide/production-deployment/#project-scale-definitions","title":"\ud83d\udcca Project Scale Definitions","text":"Scale Event Volume Concurrent Users Infrastructure Team Size Small &lt; 10k events/month &lt; 100 Minimal 1-3 developers Medium 10k-100k events/month 100-1,000 Standard 3-10 developers Large &gt; 100k events/month 1,000+ Enterprise 10+ developers"},{"location":"guide/production-deployment/#small-projects","title":"\ud83d\ude80 Small Projects","text":"<p>Perfect for: - MVPs and prototypes - Internal tools - Startups validating product-market fit - Development and testing</p>"},{"location":"guide/production-deployment/#infrastructure","title":"Infrastructure","text":"<pre><code>from orchestrix.infrastructure import (\n    InMemoryMessageBus,\n    InMemoryEventStore\n)\n\n# Simple setup - no external dependencies\nbus = InMemoryMessageBus()\nstore = InMemoryEventStore()\n</code></pre>"},{"location":"guide/production-deployment/#deployment","title":"Deployment","text":"<p>Option 1: Single Process (Simplest)</p> <pre><code># Single gunicorn/uvicorn worker\ngunicorn app:app --workers 1 --bind 0.0.0.0:8000\n</code></pre> <p>Option 2: Docker Container</p> <pre><code>FROM python:3.12-slim\n\nWORKDIR /app\nCOPY . /app\n\nRUN pip install orchestrix\n\nCMD [\"python\", \"main.py\"]\n</code></pre> <pre><code>docker build -t myapp .\ndocker run -p 8000:8000 myapp\n</code></pre>"},{"location":"guide/production-deployment/#limitations","title":"Limitations","text":"<p>\u26a0\ufe0f Important Constraints: - Events stored in memory (lost on restart) - Single process only (no horizontal scaling) - No persistence (use PostgreSQL for production) - Limited to server memory</p>"},{"location":"guide/production-deployment/#when-to-upgrade","title":"When to Upgrade","text":"<p>Move to Medium when: - Event volume exceeds 10k/month - Need persistence across restarts - Multiple users accessing concurrently - Audit trail required for compliance</p>"},{"location":"guide/production-deployment/#medium-projects","title":"\ud83d\udcc8 Medium Projects","text":"<p>Perfect for: - Production SaaS applications - B2B platforms - E-commerce sites - Financial applications</p>"},{"location":"guide/production-deployment/#infrastructure_1","title":"Infrastructure","text":"<pre><code>from orchestrix.infrastructure import (\n    InMemoryMessageBus,\n    PostgresEventStore,\n    ConnectionPool\n)\nfrom orchestrix.core import AggregateRepository\n\n# PostgreSQL for persistence\npool = ConnectionPool(\n    host=\"localhost\",\n    port=5432,\n    database=\"myapp\",\n    user=\"myapp\",\n    password=\"secure_password\",\n    min_size=5,\n    max_size=20\n)\n\n# In-memory bus for simplicity\nbus = InMemoryMessageBus()\n\n# PostgreSQL store for persistence\nstore = PostgresEventStore(pool)\n\n# Aggregate repository with snapshots\nrepository = AggregateRepository(\n    store=store,\n    snapshot_frequency=50  # Snapshot every 50 events\n)\n</code></pre>"},{"location":"guide/production-deployment/#database-setup","title":"Database Setup","text":"<p>1. Create PostgreSQL Database</p> <pre><code># Create database\ncreatedb myapp\n\n# Or via Docker\ndocker run -d \\\n  --name myapp-postgres \\\n  -e POSTGRES_DB=myapp \\\n  -e POSTGRES_USER=myapp \\\n  -e POSTGRES_PASSWORD=secure_password \\\n  -p 5432:5432 \\\n  postgres:16\n</code></pre> <p>2. Run Migrations</p> <pre><code>-- migrations/001_create_events_table.sql\nCREATE TABLE IF NOT EXISTS events (\n    id BIGSERIAL PRIMARY KEY,\n    aggregate_id VARCHAR(255) NOT NULL,\n    event_type VARCHAR(255) NOT NULL,\n    event_data JSONB NOT NULL,\n    metadata JSONB DEFAULT '{}'::jsonb,\n    version INTEGER NOT NULL,\n    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    UNIQUE (aggregate_id, version)\n);\n\nCREATE INDEX idx_events_aggregate_id ON events(aggregate_id);\nCREATE INDEX idx_events_type ON events(event_type);\nCREATE INDEX idx_events_timestamp ON events(timestamp);\n\n-- Snapshots table (optional, for performance)\nCREATE TABLE IF NOT EXISTS snapshots (\n    aggregate_id VARCHAR(255) PRIMARY KEY,\n    aggregate_type VARCHAR(255) NOT NULL,\n    snapshot_data JSONB NOT NULL,\n    version INTEGER NOT NULL,\n    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n</code></pre>"},{"location":"guide/production-deployment/#deployment_1","title":"Deployment","text":"<p>Docker Compose</p> <pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  postgres:\n    image: postgres:16\n    environment:\n      POSTGRES_DB: myapp\n      POSTGRES_USER: myapp\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    ports:\n      - \"5432:5432\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U myapp\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  app:\n    build: .\n    environment:\n      DATABASE_URL: postgresql://myapp:${DB_PASSWORD}@postgres:5432/myapp\n      WORKERS: 4\n    depends_on:\n      postgres:\n        condition: service_healthy\n    ports:\n      - \"8000:8000\"\n    restart: unless-stopped\n\nvolumes:\n  postgres_data:\n</code></pre> <p>Kubernetes Deployment</p> <pre><code># deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: app\n        image: myapp:latest\n        env:\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: myapp-secrets\n              key: database-url\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8000\n          initialDelaySeconds: 10\n          periodSeconds: 5\n</code></pre>"},{"location":"guide/production-deployment/#observability","title":"Observability","text":"<p>Basic Monitoring</p> <pre><code>from orchestrix.infrastructure import PrometheusMetrics\n\n# Enable Prometheus metrics\nmetrics = PrometheusMetrics()\nbus.add_observability_hook(metrics)\nstore.add_observability_hook(metrics)\n\n# Expose metrics endpoint\nfrom prometheus_client import make_asgi_app\n\n# In your FastAPI/Starlette app\napp.mount(\"/metrics\", make_asgi_app())\n</code></pre> <p>Health Checks</p> <pre><code>from fastapi import FastAPI, Response\n\napp = FastAPI()\n\n@app.get(\"/health\")\nasync def health():\n    \"\"\"Liveness probe.\"\"\"\n    return {\"status\": \"healthy\"}\n\n@app.get(\"/ready\")\nasync def ready():\n    \"\"\"Readiness probe - check database.\"\"\"\n    try:\n        # Simple query to verify DB connection\n        await pool.execute(\"SELECT 1\")\n        return {\"status\": \"ready\"}\n    except Exception as e:\n        return Response(\n            content={\"status\": \"not ready\", \"error\": str(e)},\n            status_code=503\n        )\n</code></pre>"},{"location":"guide/production-deployment/#performance-tuning","title":"Performance Tuning","text":"<p>Connection Pooling</p> <pre><code># Tune pool size based on workload\npool = ConnectionPool(\n    host=\"localhost\",\n    port=5432,\n    database=\"myapp\",\n    user=\"myapp\",\n    password=\"secure_password\",\n    min_size=5,      # Keep 5 connections ready\n    max_size=20,     # Allow up to 20 connections\n    timeout=30,      # Connection timeout\n    max_queries=1000 # Recycle connection after 1k queries\n)\n</code></pre> <p>Snapshots</p> <pre><code># Enable snapshots for aggregates with many events\nfrom orchestrix.core import SnapshotStrategy\n\nrepository = AggregateRepository(\n    store=store,\n    snapshot_frequency=50  # Snapshot every 50 events\n)\n\n# Manual snapshot\nawait repository.save_snapshot(aggregate_id, aggregate)\n\n# Load with snapshot\naggregate = await repository.load(aggregate_id, Order)\n</code></pre> <p>Batch Processing</p> <pre><code># Process events in batches\nfrom orchestrix.core import ProjectionEngine\n\nengine = ProjectionEngine(\n    store=store,\n    batch_size=100  # Process 100 events at a time\n)\n\n# Run projection\nawait engine.run(OrderSummaryProjection())\n</code></pre>"},{"location":"guide/production-deployment/#when-to-upgrade_1","title":"When to Upgrade","text":"<p>Move to Large when: - Event volume exceeds 100k/month - Need multi-region deployment - Require advanced observability - Team size grows beyond 10 developers - Compliance requires enhanced audit trails</p>"},{"location":"guide/production-deployment/#large-projects","title":"\ud83c\udfe2 Large Projects","text":"<p>Perfect for: - Enterprise applications - Multi-tenant SaaS platforms - High-traffic e-commerce - Financial institutions - Healthcare systems</p>"},{"location":"guide/production-deployment/#infrastructure_2","title":"Infrastructure","text":"<pre><code>from orchestrix.infrastructure import (\n    AsyncInMemoryMessageBus,\n    EventSourcingDBStore,  # Or PostgreSQL cluster\n    ConnectionPool,\n    OpenTelemetryTracing,\n    PrometheusMetrics\n)\nfrom orchestrix.core import (\n    AggregateRepository,\n    ProjectionEngine,\n    DeadLetterQueue,\n    RetryPolicy\n)\n\n# Full observability stack\ntracing = OpenTelemetryTracing(\n    service_name=\"myapp\",\n    jaeger_endpoint=\"http://jaeger:14268/api/traces\"\n)\nmetrics = PrometheusMetrics(namespace=\"myapp\")\n\n# Async bus for high throughput\nbus = AsyncInMemoryMessageBus()\nbus.add_observability_hook(tracing)\nbus.add_observability_hook(metrics)\n\n# EventSourcingDB or PostgreSQL cluster\nstore = EventSourcingDBStore(\n    endpoint=\"https://eventsourcingdb.example.com\",\n    api_key=\"your-api-key\"\n)\nstore.add_observability_hook(tracing)\nstore.add_observability_hook(metrics)\n\n# Dead letter queue for failed messages\ndlq = DeadLetterQueue(\n    store=store,\n    max_retries=3,\n    backoff_strategy=\"exponential\"\n)\n\n# Repository with advanced features\nrepository = AggregateRepository(\n    store=store,\n    snapshot_frequency=50,\n    cache_ttl=300,  # 5-minute cache\n    optimistic_locking=True\n)\n</code></pre>"},{"location":"guide/production-deployment/#database-setup_1","title":"Database Setup","text":"<p>Option 1: EventSourcingDB (Recommended)</p> <pre><code># Docker deployment\ndocker run -d \\\n  --name eventsourcingdb \\\n  -p 2113:2113 \\\n  -e EVENTSOURCINGDB_LICENSE_KEY=${LICENSE_KEY} \\\n  eventsourcingdb/eventsourcingdb:latest\n\n# Kubernetes with Helm\nhelm repo add eventsourcingdb https://charts.eventsourcingdb.com\nhelm install myapp-events eventsourcingdb/eventsourcingdb \\\n  --set license.key=${LICENSE_KEY} \\\n  --set resources.requests.memory=4Gi \\\n  --set persistence.size=100Gi\n</code></pre> <p>Option 2: PostgreSQL Cluster</p> <pre><code># PostgreSQL with Patroni for HA\napiVersion: postgresql.cnpg.io/v1\nkind: Cluster\nmetadata:\n  name: myapp-postgres\nspec:\n  instances: 3\n  primaryUpdateStrategy: unsupervised\n  postgresql:\n    parameters:\n      max_connections: \"200\"\n      shared_buffers: \"256MB\"\n      effective_cache_size: \"1GB\"\n      work_mem: \"16MB\"\n  storage:\n    size: 100Gi\n    storageClass: fast-ssd\n  monitoring:\n    enabled: true\n  backup:\n    retentionPolicy: \"30d\"\n    barmanObjectStore:\n      destinationPath: s3://myapp-backups/postgres\n      s3Credentials:\n        accessKeyId:\n          name: aws-credentials\n          key: ACCESS_KEY_ID\n        secretAccessKey:\n          name: aws-credentials\n          key: SECRET_ACCESS_KEY\n</code></pre>"},{"location":"guide/production-deployment/#deployment_2","title":"Deployment","text":"<p>Multi-Region Kubernetes</p> <pre><code># Global load balancer\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-global\n  annotations:\n    cloud.google.com/load-balancer-type: \"External\"\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 443\n    targetPort: 8000\n  selector:\n    app: myapp\n\n---\n# Deployment with autoscaling\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: app\n        image: myapp:latest\n        env:\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: myapp-secrets\n              key: database-url\n        - name: JAEGER_ENDPOINT\n          value: \"http://jaeger-collector:14268/api/traces\"\n        - name: OTEL_EXPORTER_OTLP_ENDPOINT\n          value: \"http://otel-collector:4317\"\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 60\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8000\n          initialDelaySeconds: 20\n          periodSeconds: 5\n\n---\n# Horizontal Pod Autoscaler\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 10\n  maxReplicas: 100\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n</code></pre>"},{"location":"guide/production-deployment/#observability-stack","title":"Observability Stack","text":"<p>OpenTelemetry Collector</p> <pre><code># otel-collector-config.yaml\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4317\n      http:\n        endpoint: 0.0.0.0:4318\n\nprocessors:\n  batch:\n    timeout: 10s\n    send_batch_size: 1024\n\n  resource:\n    attributes:\n    - key: service.name\n      value: myapp\n      action: upsert\n\nexporters:\n  jaeger:\n    endpoint: jaeger:14250\n    tls:\n      insecure: true\n\n  prometheus:\n    endpoint: \"0.0.0.0:8889\"\n\n  logging:\n    loglevel: info\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [batch, resource]\n      exporters: [jaeger]\n\n    metrics:\n      receivers: [otlp]\n      processors: [batch, resource]\n      exporters: [prometheus]\n</code></pre> <p>Prometheus Setup</p> <pre><code># prometheus-config.yaml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'myapp'\n    kubernetes_sd_configs:\n    - role: pod\n    relabel_configs:\n    - source_labels: [__meta_kubernetes_pod_label_app]\n      action: keep\n      regex: myapp\n    - source_labels: [__meta_kubernetes_pod_ip]\n      target_label: __address__\n      replacement: '${1}:8000'\n    - source_labels: [__meta_kubernetes_pod_name]\n      target_label: pod\n\n  - job_name: 'otel-collector'\n    static_configs:\n    - targets: ['otel-collector:8889']\n</code></pre> <p>Grafana Dashboards</p> <pre><code># Export metrics for Grafana\nfrom orchestrix.infrastructure import PrometheusMetrics\n\nmetrics = PrometheusMetrics(\n    namespace=\"myapp\",\n    subsystem=\"orchestrix\"\n)\n\n# Metrics exposed:\n# - myapp_orchestrix_commands_total\n# - myapp_orchestrix_events_total\n# - myapp_orchestrix_command_duration_seconds\n# - myapp_orchestrix_event_handler_duration_seconds\n# - myapp_orchestrix_aggregate_load_duration_seconds\n# - myapp_orchestrix_event_store_save_duration_seconds\n</code></pre>"},{"location":"guide/production-deployment/#advanced-features","title":"Advanced Features","text":"<p>Event Replay</p> <pre><code>from orchestrix.core import EventReplay\n\nreplay = EventReplay(store=store, bus=bus)\n\n# Replay all events for aggregate\nawait replay.replay_aggregate(\"ORD-123\")\n\n# Replay events in time range\nawait replay.replay_time_range(\n    start=datetime(2024, 1, 1),\n    end=datetime(2024, 1, 31)\n)\n\n# Replay specific event types\nawait replay.replay_event_types([OrderCreated, OrderPaid])\n</code></pre> <p>Event Encryption</p> <pre><code>from orchestrix.core import EncryptedEventStore\nfrom cryptography.fernet import Fernet\n\n# Generate encryption key (store in secrets manager)\nkey = Fernet.generate_key()\n\n# Wrap store with encryption\nencrypted_store = EncryptedEventStore(\n    store=store,\n    encryption_key=key,\n    # Optionally encrypt only sensitive fields\n    encrypted_fields=[\"customer_email\", \"payment_method\"]\n)\n</code></pre> <p>Multi-Tenancy</p> <pre><code>from orchestrix.core import TenantAwareEventStore\n\n# Tenant-isolated event store\ntenant_store = TenantAwareEventStore(\n    store=store,\n    tenant_resolver=lambda: get_current_tenant_id()\n)\n\n# Each tenant gets isolated event streams\nawait tenant_store.save(\n    aggregate_id=\"ORD-123\",\n    events=[OrderCreated(...)],\n    tenant_id=\"tenant-1\"\n)\n</code></pre> <p>Circuit Breaker</p> <pre><code>from orchestrix.core import CircuitBreaker\n\nbreaker = CircuitBreaker(\n    failure_threshold=5,\n    timeout=60,\n    recovery_timeout=30\n)\n\n# Wrap external service calls\n@breaker.protect\nasync def call_external_service():\n    # Call payment gateway, email service, etc.\n    pass\n</code></pre>"},{"location":"guide/production-deployment/#performance-optimization","title":"Performance Optimization","text":"<p>Read Model Caching</p> <pre><code>from orchestrix.core import CachedProjection\nimport redis.asyncio as redis\n\n# Redis cache for projections\nredis_client = await redis.from_url(\"redis://localhost:6379\")\n\ncached_projection = CachedProjection(\n    projection=OrderSummaryProjection(),\n    cache=redis_client,\n    ttl=300  # 5-minute TTL\n)\n\n# Reads hit cache, writes invalidate\nsummary = await cached_projection.get(\"ORD-123\")\n</code></pre> <p>Batch Event Processing</p> <pre><code>from orchestrix.core import BatchProcessor\n\nprocessor = BatchProcessor(\n    store=store,\n    batch_size=1000,\n    max_concurrency=10\n)\n\n# Process events in parallel batches\nawait processor.process(\n    projection=OrderAnalyticsProjection(),\n    start_position=0\n)\n</code></pre> <p>Aggregate Caching</p> <pre><code># Cache frequently accessed aggregates\nrepository = AggregateRepository(\n    store=store,\n    cache=redis_client,\n    cache_ttl=300,\n    snapshot_frequency=50\n)\n\n# First load: slow (from events)\norder = await repository.load(\"ORD-123\", Order)\n\n# Second load: fast (from cache)\norder = await repository.load(\"ORD-123\", Order)\n</code></pre>"},{"location":"guide/production-deployment/#security","title":"Security","text":"<p>Authentication &amp; Authorization</p> <pre><code>from orchestrix.core import SecurityContext\n\n# Attach user context to commands\ncontext = SecurityContext(\n    user_id=\"user-123\",\n    roles=[\"admin\"],\n    permissions=[\"orders:read\", \"orders:write\"]\n)\n\n# Commands include security context\ncommand = CreateOrder(\n    order_id=\"ORD-123\",\n    customer_name=\"Alice\",\n    security_context=context\n)\n\n# Verify permissions in handler\nclass CreateOrderHandler(CommandHandler[CreateOrder]):\n    def handle(self, command: CreateOrder) -&gt; None:\n        if \"orders:write\" not in command.security_context.permissions:\n            raise PermissionDenied(\"Insufficient permissions\")\n\n        # Proceed with command handling\n        ...\n</code></pre> <p>Event Encryption</p> <pre><code># Encrypt sensitive event data\nencrypted_store = EncryptedEventStore(\n    store=store,\n    encryption_key=get_encryption_key(),\n    encrypted_fields=[\"ssn\", \"credit_card\", \"address\"]\n)\n</code></pre> <p>Audit Logging</p> <pre><code>from orchestrix.infrastructure import AuditLogger\n\naudit = AuditLogger(\n    destination=\"s3://audit-logs/\",\n    format=\"json\",\n    include_metadata=True\n)\n\nbus.add_observability_hook(audit)\n\n# All commands/events logged with:\n# - timestamp\n# - user_id\n# - command/event type\n# - aggregate_id\n# - full payload\n</code></pre>"},{"location":"guide/production-deployment/#disaster-recovery","title":"Disaster Recovery","text":"<p>Backup Strategy</p> <pre><code># PostgreSQL continuous backup\npg_basebackup -h postgres -U myapp -D /backups/$(date +%Y%m%d)\n\n# EventSourcingDB snapshot\ncurl -X POST http://eventsourcingdb:2113/admin/backup \\\n  -H \"Authorization: Bearer ${API_KEY}\"\n</code></pre> <p>Event Store Replication</p> <pre><code># Replicate events to secondary region\nfrom orchestrix.core import EventReplicator\n\nreplicator = EventReplicator(\n    source_store=primary_store,\n    target_store=secondary_store,\n    lag_monitoring=True\n)\n\n# Continuous replication\nawait replicator.start()\n</code></pre> <p>Point-in-Time Recovery</p> <pre><code># Restore aggregate to specific point in time\nfrom orchestrix.core import PointInTimeRecovery\n\nrecovery = PointInTimeRecovery(store=store)\n\n# Restore to January 15th, 2024\norder = await recovery.restore(\n    aggregate_id=\"ORD-123\",\n    timestamp=datetime(2024, 1, 15, 12, 0, 0)\n)\n</code></pre>"},{"location":"guide/production-deployment/#migration-path","title":"\ud83d\udd04 Migration Path","text":""},{"location":"guide/production-deployment/#small-medium","title":"Small \u2192 Medium","text":"<p>1. Add PostgreSQL</p> <pre><code># Install PostgreSQL dependency\npip install orchestrix[postgres]\n</code></pre> <pre><code># Update infrastructure\nfrom orchestrix.infrastructure import PostgresEventStore, ConnectionPool\n\npool = ConnectionPool(...)\nstore = PostgresEventStore(pool)\n</code></pre> <p>2. Run Migrations</p> <pre><code># Create tables\npsql -d myapp -f migrations/001_create_events_table.sql\n</code></pre> <p>3. Deploy with Database</p> <pre><code># Update docker-compose.yml to include postgres\ndocker-compose up -d\n</code></pre>"},{"location":"guide/production-deployment/#medium-large","title":"Medium \u2192 Large","text":"<p>1. Add Observability</p> <pre><code>pip install orchestrix[observability]\n</code></pre> <pre><code># Add tracing and metrics\nfrom orchestrix.infrastructure import OpenTelemetryTracing, PrometheusMetrics\n\ntracing = OpenTelemetryTracing(...)\nmetrics = PrometheusMetrics(...)\n\nbus.add_observability_hook(tracing)\nbus.add_observability_hook(metrics)\n</code></pre> <p>2. Deploy Observability Stack</p> <pre><code># Deploy Jaeger, Prometheus, Grafana\nkubectl apply -f k8s/observability/\n</code></pre> <p>3. Enable Advanced Features</p> <pre><code># Add dead letter queue\ndlq = DeadLetterQueue(...)\n\n# Add circuit breaker\nbreaker = CircuitBreaker(...)\n\n# Enable caching\nrepository = AggregateRepository(cache=redis_client, ...)\n</code></pre>"},{"location":"guide/production-deployment/#configuration-management","title":"\ud83d\udcdd Configuration Management","text":""},{"location":"guide/production-deployment/#environment-variables","title":"Environment Variables","text":"<pre><code># .env.production\nDATABASE_URL=postgresql://user:pass@postgres:5432/myapp\nREDIS_URL=redis://redis:6379/0\nJAEGER_ENDPOINT=http://jaeger:14268/api/traces\nOTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317\n\n# Application settings\nSNAPSHOT_FREQUENCY=50\nCONNECTION_POOL_MIN=10\nCONNECTION_POOL_MAX=50\nBATCH_SIZE=1000\nCACHE_TTL=300\n\n# Security\nENCRYPTION_KEY=${ENCRYPTION_KEY}\nJWT_SECRET=${JWT_SECRET}\n</code></pre>"},{"location":"guide/production-deployment/#configuration-file","title":"Configuration File","text":"<pre><code># config.py\nfrom pydantic_settings import BaseSettings\n\nclass Settings(BaseSettings):\n    database_url: str\n    redis_url: str\n    jaeger_endpoint: str\n\n    snapshot_frequency: int = 50\n    connection_pool_min: int = 10\n    connection_pool_max: int = 50\n    batch_size: int = 1000\n    cache_ttl: int = 300\n\n    encryption_key: str\n    jwt_secret: str\n\n    class Config:\n        env_file = \".env.production\"\n\nsettings = Settings()\n</code></pre>"},{"location":"guide/production-deployment/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"guide/production-deployment/#dos","title":"Do's \u2705","text":"<ul> <li>Start small, scale when needed</li> <li>Use PostgreSQL for production (not InMemory)</li> <li>Enable observability early (metrics, tracing, logs)</li> <li>Implement health checks for Kubernetes</li> <li>Use connection pooling</li> <li>Enable snapshots for large aggregates</li> <li>Test disaster recovery procedures</li> <li>Monitor event store performance</li> <li>Cache frequently accessed data</li> <li>Use circuit breakers for external services</li> </ul>"},{"location":"guide/production-deployment/#donts","title":"Don'ts \u274c","text":"<ul> <li>Don't use InMemoryEventStore in production</li> <li>Don't deploy without health checks</li> <li>Don't skip database migrations</li> <li>Don't ignore backup strategy</li> <li>Don't hardcode secrets in code</li> <li>Don't deploy without monitoring</li> <li>Don't skip load testing</li> <li>Don't ignore security (encryption, audit logs)</li> <li>Don't over-optimize prematurely</li> <li>Don't deploy without rollback plan</li> </ul>"},{"location":"guide/production-deployment/#see-also","title":"\ud83d\udd17 See Also","text":"<ul> <li>Production Readiness Guide - Complete production checklist</li> <li>Best Practices - Domain modeling and error handling</li> <li>Tracing Examples - Observability examples</li> <li>Metrics Examples - Prometheus metrics setup</li> </ul>"},{"location":"guide/production-ready/","title":"Production Readiness Guide","text":""},{"location":"guide/production-ready/#overview","title":"Overview","text":"<p>This guide provides comprehensive guidance for deploying and operating Orchestrix in production environments. Orchestrix is a protocol-based event sourcing and CQRS platform designed for building scalable, maintainable domain-driven systems.</p>"},{"location":"guide/production-ready/#architecture-design","title":"Architecture &amp; Design","text":""},{"location":"guide/production-ready/#core-principles","title":"Core Principles","text":"<ul> <li>Event Sourcing: All state changes are captured as immutable events</li> <li>CQRS: Commands modify state, queries read snapshots/views</li> <li>Protocol-Based Design: Leverages Python Protocols for loose coupling</li> <li>CloudEvents Compatible: Events use CloudEvents specification for interoperability</li> <li>Async-First: Full support for async/await throughout the stack</li> </ul>"},{"location":"guide/production-ready/#key-components","title":"Key Components","text":"<ol> <li>AggregateRoot: Domain model with event handlers</li> <li>AggregateRepository: Persistence layer with automatic event replay</li> <li>MessageBus: Publish/subscribe for domain and integration events</li> <li>EventStore: Pluggable persistence (InMemory, PostgreSQL, EventSourcingDB)</li> <li>Snapshot: Performance optimization for large event streams</li> <li>Observability Hooks: Metrics, tracing, and error tracking</li> </ol>"},{"location":"guide/production-ready/#deployment","title":"Deployment","text":""},{"location":"guide/production-ready/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.12+ (3.13 recommended)</li> <li>Database: PostgreSQL 14+ (for production event store)</li> <li>Memory: 512MB minimum, 2GB+ recommended</li> <li>CPU: Single core minimum, multi-core recommended for async workloads</li> </ul>"},{"location":"guide/production-ready/#environment-setup","title":"Environment Setup","text":"<pre><code># 1. Clone repository\ngit clone &lt;repo-url&gt;\ncd orchestrix\n\n# 2. Create virtual environment\npython3.13 -m venv venv\nsource venv/bin/activate  # macOS/Linux\n# or\nvenv\\Scripts\\activate  # Windows\n\n# 3. Install dependencies\nuv pip install -e \".[postgres]\"  # with PostgreSQL support\n# or\nuv pip install -e .  # minimal\n\n# 4. Configure environment variables\ncp .env.example .env\n# Edit .env with your settings\n</code></pre>"},{"location":"guide/production-ready/#environment-variables","title":"Environment Variables","text":"<pre><code># Database Configuration\nDATABASE_URL=postgresql://user:password@localhost/orchestrix\nDATABASE_POOL_SIZE=20\nDATABASE_TIMEOUT=30\n\n# Event Store Configuration\nEVENT_STORE_TYPE=postgres  # inmemory, postgres, eventsourcingdb\nSNAPSHOT_INTERVAL=100  # Save snapshot every N events\n\n# Observability\nLOG_LEVEL=INFO\nMETRICS_ENABLED=true\nTRACING_ENABLED=false\nJAEGER_ENDPOINT=http://localhost:6831\n\n# Application\nDEBUG=false\nENVIRONMENT=production\n</code></pre>"},{"location":"guide/production-ready/#docker-deployment","title":"Docker Deployment","text":"<pre><code>FROM python:3.13-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    postgresql-client \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nCOPY . .\nRUN pip install -e \".[postgres]\"\n\n# Run application\nCMD [\"python\", \"-m\", \"orchestrix.main\"]\n</code></pre> <p>Docker Compose Example:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    build: .\n    environment:\n      DATABASE_URL: postgresql://user:password@postgres:5432/orchestrix\n    depends_on:\n      - postgres\n    ports:\n      - \"8000:8000\"\n\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_DB: orchestrix\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\nvolumes:\n  postgres_data:\n</code></pre>"},{"location":"guide/production-ready/#configuration","title":"Configuration","text":""},{"location":"guide/production-ready/#event-store-selection","title":"Event Store Selection","text":""},{"location":"guide/production-ready/#inmemory-developmenttesting","title":"InMemory (Development/Testing)","text":"<pre><code>from orchestrix.infrastructure import InMemoryEventStore\n\nstore = InMemoryEventStore()  # All events in RAM\n</code></pre> <p>Pros: Fast, no external dependencies Cons: No persistence, data lost on restart, not thread-safe</p>"},{"location":"guide/production-ready/#postgresql-production","title":"PostgreSQL (Production)","text":"<pre><code>from orchestrix.infrastructure import PostgresEventStore\n\nstore = PostgresEventStore(\n    connection_string=\"postgresql://localhost/orchestrix\",\n    pool_size=20\n)\n</code></pre> <p>Pros: ACID compliance, scalable, production-ready Cons: Network latency, requires external database</p> <p>Setup: <pre><code>-- Create database\nCREATE DATABASE orchestrix;\n\n-- Create events table (auto-migrated by Orchestrix)\n-- Run: orchestrix migrate\n</code></pre></p>"},{"location":"guide/production-ready/#eventsourcingdb-event-store-database","title":"EventSourcingDB (Event Store Database)","text":"<pre><code>from orchestrix.infrastructure import EventSourcingDBStore\n\nstore = EventSourcingDBStore(\n    url=\"http://localhost:2113\",\n    stream_name=\"orchestrix\"\n)\n</code></pre> <p>Pros: Purpose-built for event sourcing, excellent tooling Cons: Requires separate service, more complex operations</p>"},{"location":"guide/production-ready/#snapshot-configuration","title":"Snapshot Configuration","text":"<p>Enable snapshots to improve load performance:</p> <pre><code>from orchestrix.core import AggregateRepository\nfrom orchestrix.infrastructure import InMemoryEventStore, InMemorySnapshotStore\n\nrepository = AggregateRepository(\n    event_store=InMemoryEventStore(),\n    snapshot_store=InMemorySnapshotStore(),\n    snapshot_interval=100  # Save snapshot every 100 events\n)\n</code></pre> <p>Guidelines: - Use snapshots for aggregates with &gt;50 events in typical load - Set interval based on event size and replay performance - Monitor event load times to tune interval</p>"},{"location":"guide/production-ready/#observability","title":"Observability","text":""},{"location":"guide/production-ready/#logging","title":"Logging","text":"<p>Orchestrix uses Python's standard logging with structured context:</p> <pre><code>from orchestrix.core.common.logging import get_logger\n\nlogger = get_logger(__name__)\n\n# Structured logging with context\nlogger.info(\n    \"Aggregate loaded\",\n    extra={\n        \"aggregate_id\": \"user-123\",\n        \"version\": 42,\n        \"event_count\": 15\n    }\n)\n</code></pre> <p>Configuration: <pre><code>import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\n</code></pre></p>"},{"location":"guide/production-ready/#metrics-tracing","title":"Metrics &amp; Tracing","text":"<p>Orchestrix provides extensible observability hooks:</p> <pre><code>from orchestrix.core.common.observability import init_observability\n\n# Initialize with custom providers (e.g., Prometheus, Jaeger)\nobservability = init_observability(\n    metrics_provider=MyPrometheusProvider(),\n    tracing_provider=MyJaegerProvider()\n)\n\n# Hooks automatically called during operations\n# - record_event_stored()\n# - record_event_loaded()\n# - record_event_replayed()\n# - record_snapshot_saved/loaded()\n# - record_aggregate_error()\n</code></pre> <p>Example: Prometheus Integration:</p> <pre><code>from prometheus_client import Counter, Histogram\nfrom orchestrix.core.common.observability import MetricsProvider\n\nclass PrometheusMetrics(MetricsProvider):\n    def __init__(self):\n        self.events_stored = Counter(\n            'orchestrix_events_stored_total',\n            'Events stored',\n            ['aggregate_id']\n        )\n        self.event_load_time = Histogram(\n            'orchestrix_event_load_time_seconds',\n            'Time to load events'\n        )\n\n    def counter(self, name, value=1.0, labels=None):\n        if 'events_stored' in name:\n            self.events_stored.labels(**labels).inc(value)\n\n    # ... implement other methods\n</code></pre>"},{"location":"guide/production-ready/#health-checks","title":"Health Checks","text":"<pre><code>async def health_check(repository: AggregateRepository) -&gt; dict:\n    \"\"\"Check system health.\"\"\"\n    try:\n        # Verify event store connectivity\n        test_id = \"health-check\"\n\n        # Try loading (may not exist)\n        try:\n            await repository.load_async(MyAggregate, test_id)\n        except:\n            pass  # Expected if test aggregate doesn't exist\n\n        return {\n            \"status\": \"healthy\",\n            \"event_store\": \"connected\",\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n    except Exception as e:\n        return {\n            \"status\": \"unhealthy\",\n            \"error\": str(e)\n        }\n</code></pre>"},{"location":"guide/production-ready/#error-handling","title":"Error Handling","text":""},{"location":"guide/production-ready/#common-issues-solutions","title":"Common Issues &amp; Solutions","text":""},{"location":"guide/production-ready/#1-event-store-connection-failed","title":"1. Event Store Connection Failed","text":"<pre><code>Error: Unable to connect to PostgreSQL\nSolution:\n1. Verify DATABASE_URL is correct\n2. Check PostgreSQL is running: psql -U user -d orchestrix\n3. Verify credentials and firewall rules\n4. Check connection pool limits\n</code></pre>"},{"location":"guide/production-ready/#2-snapshot-inconsistency","title":"2. Snapshot Inconsistency","text":"<pre><code>Error: Snapshot version mismatch\nSolution:\n1. Clear snapshots: TRUNCATE snapshots;\n2. Rebuild from events: orchestrix rebuild-snapshots\n3. Verify event ordering in database\n</code></pre>"},{"location":"guide/production-ready/#3-memory-growth-in-event-store","title":"3. Memory Growth in Event Store","text":"<pre><code>Issue: InMemory store consuming too much memory\nSolution:\n1. Switch to PostgreSQL for production\n2. Implement snapshots to reduce event streams\n3. Archive old events periodically\n</code></pre>"},{"location":"guide/production-ready/#4-slow-event-replay","title":"4. Slow Event Replay","text":"<pre><code>Symptoms: Slow aggregate loading, high CPU\nSolutions:\n1. Enable/optimize snapshots (reduce replay chain)\n2. Check database indexing on event_id, aggregate_id\n3. Monitor event size - large payloads slow replay\n4. Use read replicas for high-traffic services\n</code></pre>"},{"location":"guide/production-ready/#error-tracking","title":"Error Tracking","text":"<p>Use the observability hooks to track errors:</p> <pre><code>from orchestrix.core.common.observability import get_observability\n\nobservability = get_observability()\n\n# Register error callback\ndef on_error(aggregate_id: str, error: str):\n    sentry.capture_exception(error)\n    alert.notify(f\"Error processing {aggregate_id}: {error}\")\n\nobservability.on_aggregate_error(on_error)\n</code></pre>"},{"location":"guide/production-ready/#database-maintenance","title":"Database Maintenance","text":""},{"location":"guide/production-ready/#postgresql","title":"PostgreSQL","text":"<pre><code>-- Create indexes for performance\nCREATE INDEX idx_events_aggregate_id ON events(aggregate_id);\nCREATE INDEX idx_events_timestamp ON events(timestamp);\nCREATE INDEX idx_snapshots_aggregate_id ON snapshots(aggregate_id);\n\n-- Monitor event growth\nSELECT COUNT(*) as total_events,\n       COUNT(DISTINCT aggregate_id) as aggregates\nFROM events;\n\n-- Archive old events (optional)\n-- Keep recent events hot, archive older ones\nCREATE TABLE events_archive AS \nSELECT * FROM events \nWHERE timestamp &lt; NOW() - INTERVAL '1 year';\n\nDELETE FROM events \nWHERE timestamp &lt; NOW() - INTERVAL '1 year';\n\n-- Vacuum to reclaim space\nVACUUM ANALYZE;\n</code></pre>"},{"location":"guide/production-ready/#backup-recovery","title":"Backup &amp; Recovery","text":"<pre><code># Backup PostgreSQL\npg_dump -U user orchestrix &gt; orchestrix_backup.sql\n\n# Restore from backup\npsql -U user orchestrix &lt; orchestrix_backup.sql\n\n# Backup snapshot tables\npg_dump -U user orchestrix -t snapshots &gt; snapshots_backup.sql\n\n# Point-in-time recovery\npg_restore --recovery-target-time='2024-01-03 15:30:00' ...\n</code></pre>"},{"location":"guide/production-ready/#performance-tuning","title":"Performance Tuning","text":""},{"location":"guide/production-ready/#connection-pooling","title":"Connection Pooling","text":"<pre><code>from orchestrix.infrastructure import PostgresEventStore\n\nstore = PostgresEventStore(\n    connection_string=\"postgresql://localhost/orchestrix\",\n    pool_size=20,  # Connections in pool\n    pool_recycle=3600,  # Recycle after 1 hour\n    pool_timeout=30,  # Wait 30s for available connection\n    max_overflow=10  # Allow temporary overflow\n)\n</code></pre> <p>Guidelines: - pool_size = (CPU cores \u00d7 2) + 1 - Increase for high concurrency, decrease for limited connections - Monitor connection usage: <code>SELECT count(*) FROM pg_stat_activity;</code></p>"},{"location":"guide/production-ready/#event-batch-processing","title":"Event Batch Processing","text":"<pre><code>async def process_events_batch(\n    repository: AggregateRepository,\n    aggregate_ids: list[str],\n    batch_size: int = 100\n):\n    \"\"\"Process multiple aggregates efficiently.\"\"\"\n    for i in range(0, len(aggregate_ids), batch_size):\n        batch = aggregate_ids[i:i + batch_size]\n\n        # Process in parallel\n        tasks = [\n            repository.load_async(MyAggregate, agg_id)\n            for agg_id in batch\n        ]\n\n        aggregates = await asyncio.gather(*tasks)\n\n        # Process results\n        for aggregate in aggregates:\n            await handle_aggregate(aggregate)\n</code></pre>"},{"location":"guide/production-ready/#caching-strategy","title":"Caching Strategy","text":"<pre><code>from functools import lru_cache\n\nclass CachedRepository:\n    def __init__(self, repository: AggregateRepository):\n        self.repository = repository\n        self._cache = {}\n        self._cache_ttl = 300  # 5 minutes\n\n    async def load_with_cache(self, agg_type, agg_id):\n        \"\"\"Load with caching.\"\"\"\n        cache_key = f\"{agg_type.__name__}:{agg_id}\"\n\n        if cache_key in self._cache:\n            return self._cache[cache_key]\n\n        aggregate = await self.repository.load_async(agg_type, agg_id)\n        self._cache[cache_key] = aggregate\n\n        return aggregate\n</code></pre>"},{"location":"guide/production-ready/#security","title":"Security","text":""},{"location":"guide/production-ready/#input-validation","title":"Input Validation","text":"<p>All command inputs should be validated:</p> <pre><code>from orchestrix.core import AggregateRoot\nfrom pydantic import BaseModel, validator\n\nclass CreateUserCommand(BaseModel):\n    email: str\n    name: str\n\n    @validator('email')\n    def validate_email(cls, v):\n        if '@' not in v:\n            raise ValueError('Invalid email')\n        return v\n\nclass UserAggregate(AggregateRoot):\n    def create_user(self, cmd: CreateUserCommand):\n        # Command already validated by Pydantic\n        self.emit(\"UserCreated\", email=cmd.email, name=cmd.name)\n</code></pre>"},{"location":"guide/production-ready/#database-security","title":"Database Security","text":"<pre><code># Use parameterized queries (automatic with ORM)\n# Never concatenate user input into SQL\n\n# Example: WRONG \u274c\n# query = f\"SELECT * FROM events WHERE id = {user_input}\"\n\n# Example: RIGHT \u2705\n# query = \"SELECT * FROM events WHERE id = %s\"\n# execute(query, (user_input,))\n\n# PostgreSQL-specific\n- Use different roles for read/write\n- Restrict snapshot storage to read-only replicas\n- Enable SSL/TLS for connections\n- Use secrets management (Vault, AWS Secrets Manager)\n</code></pre>"},{"location":"guide/production-ready/#event-content","title":"Event Content","text":"<pre><code># Sensitive data in events\n# - Store only what's necessary\n# - Use references instead of full data\n# - Implement event encryption for sensitive domains\n\nclass BankTransferAggregate(AggregateRoot):\n    def transfer(self, amount: float, from_account: str, to_account: str):\n        # \u2705 GOOD: Hash account numbers\n        self.emit(\"MoneyTransferred\", \n                 amount=amount,\n                 from_hash=hash(from_account),\n                 to_hash=hash(to_account))\n\n        # \u274c BAD: Store full account details\n        # self.emit(\"MoneyTransferred\",\n        #          amount=amount,\n        #          from_account=from_account,\n        #          to_account=to_account)\n</code></pre>"},{"location":"guide/production-ready/#scaling","title":"Scaling","text":""},{"location":"guide/production-ready/#horizontal-scaling","title":"Horizontal Scaling","text":"<pre><code># Application instances behind load balancer\n# - All read from shared PostgreSQL event store\n# - Snapshots ensure fast loading regardless of instance\n# - Message bus handles distributed events\n\n# Load balancer config (nginx example):\nupstream orchestrix {\n    server app1:8000;\n    server app2:8000;\n    server app3:8000;\n}\n\nserver {\n    listen 80;\n    location / {\n        proxy_pass http://orchestrix;\n    }\n}\n</code></pre>"},{"location":"guide/production-ready/#event-store-scaling","title":"Event Store Scaling","text":"<pre><code>PostgreSQL Scaling Options:\n1. Vertical: More CPU, memory, storage (simple, limited)\n2. Read replicas: Secondary servers for reads\n3. Sharding: Split events by aggregate_id range\n4. EventSourcingDB: Purpose-built for event sourcing\n</code></pre>"},{"location":"guide/production-ready/#async-processing","title":"Async Processing","text":"<pre><code># Offload long-running operations\nasync def submit_payment(aggregate: BankTransferAggregate):\n    # Emit event\n    aggregate.process_payment()\n\n    # Save\n    await repository.save_async(aggregate)\n\n    # Async notification (don't wait)\n    asyncio.create_task(notify_user(aggregate.id))\n</code></pre>"},{"location":"guide/production-ready/#monitoring-checklist","title":"Monitoring Checklist","text":"<ul> <li>[ ] Event store connectivity (health checks)</li> <li>[ ] Event processing latency (P50, P95, P99)</li> <li>[ ] Snapshot hit rate (should be &gt;80% with proper tuning)</li> <li>[ ] Database connection pool utilization</li> <li>[ ] Error rates and error types</li> <li>[ ] Memory usage (watch for event accumulation)</li> <li>[ ] Query performance (slow queries log)</li> <li>[ ] Backup completion and restoration tests</li> </ul>"},{"location":"guide/production-ready/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"guide/production-ready/#disaster-recovery","title":"Disaster Recovery","text":"<pre><code># 1. Stop application\ndocker-compose down\n\n# 2. Restore database from backup\npsql orchestrix &lt; backup.sql\n\n# 3. Verify data integrity\nSELECT COUNT(*) FROM events;\n\n# 4. Restart application\ndocker-compose up -d\n\n# 5. Verify operation\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"guide/production-ready/#rollback-strategy","title":"Rollback Strategy","text":"<p>Event sourcing provides built-in versioning:</p> <pre><code># Load specific event version\nevents = await store.load(\"aggregate-id\")\n# Filter: events up to specific timestamp or version\n\n# Rebuild aggregate at point in time\naggregate = await repository.load_at_version(\n    AggregateType, \n    \"aggregate-id\",\n    version=42\n)\n</code></pre>"},{"location":"guide/production-ready/#production-deployment-checklist","title":"Production Deployment Checklist","text":"<ul> <li>[ ] PostgreSQL database configured with backups</li> <li>[ ] Connection pooling configured appropriately</li> <li>[ ] Observability hooks wired to monitoring system</li> <li>[ ] Health checks implemented and monitored</li> <li>[ ] Error tracking (Sentry, DataDog, etc) configured</li> <li>[ ] Logging configured with centralized collection (ELK, Splunk)</li> <li>[ ] Database indexing applied</li> <li>[ ] Snapshot intervals tuned for workload</li> <li>[ ] Load testing completed (expected throughput verified)</li> <li>[ ] Disaster recovery plan documented and tested</li> <li>[ ] Security review completed (input validation, secrets)</li> <li>[ ] Runbook created for common issues</li> <li>[ ] Team trained on operation and troubleshooting</li> </ul>"},{"location":"guide/production-ready/#support-resources","title":"Support &amp; Resources","text":"<ul> <li>Documentation: See assets/ folder for API and architecture details</li> <li>Examples: See examples/ for complete working applications</li> <li>Issues: Report bugs and feature requests on GitHub</li> <li>Community: Discussions and best practices</li> </ul> <p>Last Updated: January 2025 Version: 1.0</p>"}]}